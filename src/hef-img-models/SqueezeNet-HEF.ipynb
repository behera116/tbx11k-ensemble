{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/behera116/keras-squeezenet-fixes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f25c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import cv2\n",
    "import os\n",
    "from skimage import exposure\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seaborn import heatmap\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from ast import literal_eval\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20f8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "TARGET_SIZE = (224,224)\n",
    "INPUT_SHAPE = (224,224,3)\n",
    "EPOCHS = 60\n",
    "\n",
    "CLASS_MODE = 'categorical'\n",
    "LOSS_METRIC = 'categorical_crossentropy'\n",
    "\n",
    "MODEL_SAVED_FILE = './weights/squeezenet_hef.hdf5'\n",
    "TRAIN_IMAGE_FOLDER = '/home/TBX11K/HEF/train'\n",
    "VALIDATION_IMAGE_FOLDER = '/home/TBX11K/HEF/val'\n",
    "\n",
    "SEED = 42\n",
    "IMAGE_SHAPE = (224,224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ac7e7",
   "metadata": {},
   "source": [
    "### SqueezeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661e4d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 15:55:39.652919: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-08-16 15:55:39.652979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1021 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 111, 111, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu_conv1 (Activation)        (None, 111, 111, 64  0           ['conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 55, 55, 64)   0           ['relu_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " fire2/squeeze1x1 (Conv2D)      (None, 55, 55, 16)   1040        ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " fire2/relu_squeeze1x1 (Activat  (None, 55, 55, 16)  0           ['fire2/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire2/expand1x1 (Conv2D)       (None, 55, 55, 64)   1088        ['fire2/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire2/expand3x3 (Conv2D)       (None, 55, 55, 64)   9280        ['fire2/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire2/relu_expand1x1 (Activati  (None, 55, 55, 64)  0           ['fire2/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire2/relu_expand3x3 (Activati  (None, 55, 55, 64)  0           ['fire2/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire2/concat (Concatenate)     (None, 55, 55, 128)  0           ['fire2/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire2/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire3/squeeze1x1 (Conv2D)      (None, 55, 55, 16)   2064        ['fire2/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire3/relu_squeeze1x1 (Activat  (None, 55, 55, 16)  0           ['fire3/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire3/expand1x1 (Conv2D)       (None, 55, 55, 64)   1088        ['fire3/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire3/expand3x3 (Conv2D)       (None, 55, 55, 64)   9280        ['fire3/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire3/relu_expand1x1 (Activati  (None, 55, 55, 64)  0           ['fire3/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire3/relu_expand3x3 (Activati  (None, 55, 55, 64)  0           ['fire3/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire3/concat (Concatenate)     (None, 55, 55, 128)  0           ['fire3/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire3/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " pool3 (MaxPooling2D)           (None, 27, 27, 128)  0           ['fire3/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire4/squeeze1x1 (Conv2D)      (None, 27, 27, 32)   4128        ['pool3[0][0]']                  \n",
      "                                                                                                  \n",
      " fire4/relu_squeeze1x1 (Activat  (None, 27, 27, 32)  0           ['fire4/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire4/expand1x1 (Conv2D)       (None, 27, 27, 128)  4224        ['fire4/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire4/expand3x3 (Conv2D)       (None, 27, 27, 128)  36992       ['fire4/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire4/relu_expand1x1 (Activati  (None, 27, 27, 128)  0          ['fire4/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire4/relu_expand3x3 (Activati  (None, 27, 27, 128)  0          ['fire4/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire4/concat (Concatenate)     (None, 27, 27, 256)  0           ['fire4/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire4/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire5/squeeze1x1 (Conv2D)      (None, 27, 27, 32)   8224        ['fire4/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire5/relu_squeeze1x1 (Activat  (None, 27, 27, 32)  0           ['fire5/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire5/expand1x1 (Conv2D)       (None, 27, 27, 128)  4224        ['fire5/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire5/expand3x3 (Conv2D)       (None, 27, 27, 128)  36992       ['fire5/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire5/relu_expand1x1 (Activati  (None, 27, 27, 128)  0          ['fire5/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire5/relu_expand3x3 (Activati  (None, 27, 27, 128)  0          ['fire5/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire5/concat (Concatenate)     (None, 27, 27, 256)  0           ['fire5/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire5/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " pool5 (MaxPooling2D)           (None, 13, 13, 256)  0           ['fire5/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire6/squeeze1x1 (Conv2D)      (None, 13, 13, 48)   12336       ['pool5[0][0]']                  \n",
      "                                                                                                  \n",
      " fire6/relu_squeeze1x1 (Activat  (None, 13, 13, 48)  0           ['fire6/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire6/expand1x1 (Conv2D)       (None, 13, 13, 192)  9408        ['fire6/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire6/expand3x3 (Conv2D)       (None, 13, 13, 192)  83136       ['fire6/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire6/relu_expand1x1 (Activati  (None, 13, 13, 192)  0          ['fire6/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire6/relu_expand3x3 (Activati  (None, 13, 13, 192)  0          ['fire6/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire6/concat (Concatenate)     (None, 13, 13, 384)  0           ['fire6/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire6/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire7/squeeze1x1 (Conv2D)      (None, 13, 13, 48)   18480       ['fire6/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire7/relu_squeeze1x1 (Activat  (None, 13, 13, 48)  0           ['fire7/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire7/expand1x1 (Conv2D)       (None, 13, 13, 192)  9408        ['fire7/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire7/expand3x3 (Conv2D)       (None, 13, 13, 192)  83136       ['fire7/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire7/relu_expand1x1 (Activati  (None, 13, 13, 192)  0          ['fire7/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire7/relu_expand3x3 (Activati  (None, 13, 13, 192)  0          ['fire7/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire7/concat (Concatenate)     (None, 13, 13, 384)  0           ['fire7/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire7/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire8/squeeze1x1 (Conv2D)      (None, 13, 13, 64)   24640       ['fire7/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire8/relu_squeeze1x1 (Activat  (None, 13, 13, 64)  0           ['fire8/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire8/expand1x1 (Conv2D)       (None, 13, 13, 256)  16640       ['fire8/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire8/expand3x3 (Conv2D)       (None, 13, 13, 256)  147712      ['fire8/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire8/relu_expand1x1 (Activati  (None, 13, 13, 256)  0          ['fire8/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire8/relu_expand3x3 (Activati  (None, 13, 13, 256)  0          ['fire8/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire8/concat (Concatenate)     (None, 13, 13, 512)  0           ['fire8/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire8/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire9/squeeze1x1 (Conv2D)      (None, 13, 13, 64)   32832       ['fire8/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire9/relu_squeeze1x1 (Activat  (None, 13, 13, 64)  0           ['fire9/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire9/expand1x1 (Conv2D)       (None, 13, 13, 256)  16640       ['fire9/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire9/expand3x3 (Conv2D)       (None, 13, 13, 256)  147712      ['fire9/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire9/relu_expand1x1 (Activati  (None, 13, 13, 256)  0          ['fire9/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire9/relu_expand3x3 (Activati  (None, 13, 13, 256)  0          ['fire9/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire9/concat (Concatenate)     (None, 13, 13, 512)  0           ['fire9/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire9/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " drop9 (Dropout)                (None, 13, 13, 512)  0           ['fire9/concat[0][0]']           \n",
      "                                                                                                  \n",
      " conv10 (Conv2D)                (None, 13, 13, 1000  513000      ['drop9[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu_conv10 (Activation)       (None, 13, 13, 1000  0           ['conv10[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 1000)        0           ['relu_conv10[0][0]']            \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1000)         0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            3003        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,238,499\n",
      "Trainable params: 1,238,499\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load pretrained efficientnet model fine-tuned on our dataset\n",
    "from tensorflow import keras\n",
    "squeezenet_model = keras.models.load_model('./weights/squeezenet_adam_dropout.hdf5')\n",
    "squeezenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bc514",
   "metadata": {},
   "source": [
    "#### Keras Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92230e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs-\"+dt.datetime.now().strftime(\"%m%d%Y%H%M%S\"),\n",
    "                            histogram_freq=0,\n",
    "                            write_graph=False,\n",
    "                            update_freq='epoch')\n",
    "\n",
    "def epoch_end(epoch, logs):\n",
    "    message = \"End of epoch \"+str(epoch)+\". Learning rate: \"+str(K.eval(squeezenet_model.optimizer.lr))\n",
    "    os.system('echo '+message)\n",
    "\n",
    "def epoch_begin(epoch, logs):\n",
    "    print(\"Learning rate: \", K.eval(squeezenet_model.optimizer.lr))\n",
    "    \n",
    "def train_begin(logs):\n",
    "    os.system(\"echo Beginning training\")\n",
    "    \n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVED_FILE,\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             save_weights_only=False,\n",
    "                             save_freq='epoch')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta = 1e-4, \n",
    "                          patience=30,\n",
    "                          verbose=1,\n",
    "                          mode='min',\n",
    "                          baseline=None,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                             factor=np.sqrt(.1),\n",
    "                             patience=10,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             min_delta=.0001,\n",
    "                             cooldown=0,\n",
    "                             min_lr=0.0000001)\n",
    "\n",
    "lambdacb = LambdaCallback(on_epoch_begin=epoch_begin,\n",
    "                          on_epoch_end=epoch_end,\n",
    "                          on_batch_begin=None,\n",
    "                          on_batch_end=None,\n",
    "                          on_train_begin=train_begin,\n",
    "                          on_train_end=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6c5ad",
   "metadata": {},
   "source": [
    "#### Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12936550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9130 images belonging to 3 classes.\n",
      "Found 2032 images belonging to 3 classes.\n",
      "train class indices: {'health': 0, 'sick': 1, 'tb': 2}\n",
      "class weights: {0: 0.972310969116081, 1: 1.0144444444444445, 2: 1.0144444444444445}\n",
      "samples for train class labels: dict_items([(0, 3130), (1, 3000), (2, 3000)])\n",
      "\n",
      "\n",
      "validation class indices: {'health': 0, 'sick': 1, 'tb': 2}\n",
      "samples for validation class labels: dict_items([(0, 923), (1, 800), (2, 309)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "#train data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.2,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=20,\n",
    "    brightness_range = [0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        class_mode= CLASS_MODE)\n",
    "\n",
    "#validation imagedatagenerator\n",
    "test_datagen = ImageDataGenerator()\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        VALIDATION_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        class_mode=CLASS_MODE)\n",
    "from collections import Counter\n",
    "print('train class indices:',train_generator.class_indices)\n",
    "counter = Counter(train_generator.classes)\n",
    "\n",
    "total_train = 0\n",
    "num_classes = 0\n",
    "for cls_idx,item in counter.items():\n",
    "    total_train += item\n",
    "    num_classes += 1\n",
    "\n",
    "class_weights = {}\n",
    "for cls_idx,weight in counter.items():\n",
    "    cls_weight = total_train/(weight*num_classes)\n",
    "    class_weights[cls_idx] = cls_weight\n",
    "\n",
    "print('class weights:',class_weights)\n",
    "print('samples for train class labels:',counter.items())\n",
    "print('\\n')\n",
    "\n",
    "print('validation class indices:',validation_generator.class_indices)\n",
    "counter = Counter(validation_generator.classes)\n",
    "print('samples for validation class labels:',counter.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5a367",
   "metadata": {},
   "source": [
    "#### SqueezeNet Compilation and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e949ac29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "squeezenet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d6ecf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-05\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 15:56:04.737744: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.8953 - AUC: 0.9752 - precision: 0.9072 - recall: 0.8837\n",
      "Epoch 00001: val_loss improved from inf to 0.69484, saving model to ./weights/squeezenet_hef.hdf5\n",
      "End of epoch 0. Learning rate: 1e-05\n",
      "286/286 [==============================] - 129s 433ms/step - loss: 0.2999 - accuracy: 0.8953 - AUC: 0.9752 - precision: 0.9072 - recall: 0.8837 - val_loss: 0.6948 - val_accuracy: 0.7869 - val_AUC: 0.9114 - val_precision: 0.7981 - val_recall: 0.7761\n",
      "Learning rate:  1e-05\n",
      "Epoch 2/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9122 - AUC: 0.9812 - precision: 0.9228 - recall: 0.9002\n",
      "Epoch 00002: val_loss did not improve from 0.69484\n",
      "End of epoch 1. Learning rate: 1e-05\n",
      "286/286 [==============================] - 128s 447ms/step - loss: 0.2583 - accuracy: 0.9122 - AUC: 0.9812 - precision: 0.9228 - recall: 0.9002 - val_loss: 0.7703 - val_accuracy: 0.7544 - val_AUC: 0.8985 - val_precision: 0.7662 - val_recall: 0.7352\n",
      "Learning rate:  1e-05\n",
      "Epoch 3/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9138 - AUC: 0.9826 - precision: 0.9221 - recall: 0.9058\n",
      "Epoch 00003: val_loss did not improve from 0.69484\n",
      "End of epoch 2. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 400ms/step - loss: 0.2453 - accuracy: 0.9138 - AUC: 0.9826 - precision: 0.9221 - recall: 0.9058 - val_loss: 0.8492 - val_accuracy: 0.7013 - val_AUC: 0.8787 - val_precision: 0.7152 - val_recall: 0.6885\n",
      "Learning rate:  1e-05\n",
      "Epoch 4/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.9197 - AUC: 0.9847 - precision: 0.9272 - recall: 0.9111\n",
      "Epoch 00004: val_loss improved from 0.69484 to 0.69326, saving model to ./weights/squeezenet_hef.hdf5\n",
      "End of epoch 3. Learning rate: 1e-05\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 0.2298 - accuracy: 0.9197 - AUC: 0.9847 - precision: 0.9272 - recall: 0.9111 - val_loss: 0.6933 - val_accuracy: 0.7470 - val_AUC: 0.9073 - val_precision: 0.7559 - val_recall: 0.7362\n",
      "Learning rate:  1e-05\n",
      "Epoch 5/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9252 - AUC: 0.9868 - precision: 0.9327 - recall: 0.9173\n",
      "Epoch 00005: val_loss did not improve from 0.69326\n",
      "End of epoch 4. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.2121 - accuracy: 0.9252 - AUC: 0.9868 - precision: 0.9327 - recall: 0.9173 - val_loss: 0.8455 - val_accuracy: 0.7077 - val_AUC: 0.8855 - val_precision: 0.7162 - val_recall: 0.7018\n",
      "Learning rate:  1e-05\n",
      "Epoch 6/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.9310 - AUC: 0.9888 - precision: 0.9359 - recall: 0.9234\n",
      "Epoch 00006: val_loss did not improve from 0.69326\n",
      "End of epoch 5. Learning rate: 1e-05\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 0.1955 - accuracy: 0.9310 - AUC: 0.9888 - precision: 0.9359 - recall: 0.9234 - val_loss: 0.7414 - val_accuracy: 0.7205 - val_AUC: 0.8974 - val_precision: 0.7297 - val_recall: 0.7136\n",
      "Learning rate:  1e-05\n",
      "Epoch 7/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9312 - AUC: 0.9880 - precision: 0.9383 - recall: 0.9248\n",
      "Epoch 00007: val_loss did not improve from 0.69326\n",
      "End of epoch 6. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 398ms/step - loss: 0.2003 - accuracy: 0.9312 - AUC: 0.9880 - precision: 0.9383 - recall: 0.9248 - val_loss: 0.7202 - val_accuracy: 0.7328 - val_AUC: 0.9029 - val_precision: 0.7399 - val_recall: 0.7224\n",
      "Learning rate:  1e-05\n",
      "Epoch 8/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9344 - AUC: 0.9898 - precision: 0.9404 - recall: 0.9274\n",
      "Epoch 00008: val_loss did not improve from 0.69326\n",
      "End of epoch 7. Learning rate: 1e-05\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 0.1860 - accuracy: 0.9344 - AUC: 0.9898 - precision: 0.9404 - recall: 0.9274 - val_loss: 0.7442 - val_accuracy: 0.7224 - val_AUC: 0.8986 - val_precision: 0.7320 - val_recall: 0.7136\n",
      "Learning rate:  1e-05\n",
      "Epoch 9/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9346 - AUC: 0.9901 - precision: 0.9414 - recall: 0.9297\n",
      "Epoch 00009: val_loss did not improve from 0.69326\n",
      "End of epoch 8. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.1835 - accuracy: 0.9346 - AUC: 0.9901 - precision: 0.9414 - recall: 0.9297 - val_loss: 0.6978 - val_accuracy: 0.7382 - val_AUC: 0.9072 - val_precision: 0.7428 - val_recall: 0.7249\n",
      "Learning rate:  1e-05\n",
      "Epoch 10/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9379 - AUC: 0.9910 - precision: 0.9434 - recall: 0.9337\n",
      "Epoch 00010: val_loss did not improve from 0.69326\n",
      "End of epoch 9. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.1741 - accuracy: 0.9379 - AUC: 0.9910 - precision: 0.9434 - recall: 0.9337 - val_loss: 0.7086 - val_accuracy: 0.7382 - val_AUC: 0.9055 - val_precision: 0.7458 - val_recall: 0.7293\n",
      "Learning rate:  1e-05\n",
      "Epoch 11/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9414 - AUC: 0.9913 - precision: 0.9455 - recall: 0.9372\n",
      "Epoch 00011: val_loss improved from 0.69326 to 0.64442, saving model to ./weights/squeezenet_hef.hdf5\n",
      "End of epoch 10. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.1692 - accuracy: 0.9414 - AUC: 0.9913 - precision: 0.9455 - recall: 0.9372 - val_loss: 0.6444 - val_accuracy: 0.7544 - val_AUC: 0.9175 - val_precision: 0.7598 - val_recall: 0.7505\n",
      "Learning rate:  1e-05\n",
      "Epoch 12/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9392 - AUC: 0.9910 - precision: 0.9454 - recall: 0.9332\n",
      "Epoch 00012: val_loss did not improve from 0.64442\n",
      "End of epoch 11. Learning rate: 1e-05\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 0.1732 - accuracy: 0.9392 - AUC: 0.9910 - precision: 0.9454 - recall: 0.9332 - val_loss: 0.7865 - val_accuracy: 0.7062 - val_AUC: 0.8887 - val_precision: 0.7118 - val_recall: 0.6954\n",
      "Learning rate:  1e-05\n",
      "Epoch 13/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9396 - AUC: 0.9914 - precision: 0.9457 - recall: 0.9347\n",
      "Epoch 00013: val_loss did not improve from 0.64442\n",
      "End of epoch 12. Learning rate: 1e-05\n",
      "286/286 [==============================] - 115s 401ms/step - loss: 0.1681 - accuracy: 0.9396 - AUC: 0.9914 - precision: 0.9457 - recall: 0.9347 - val_loss: 0.8837 - val_accuracy: 0.6801 - val_AUC: 0.8767 - val_precision: 0.6883 - val_recall: 0.6747\n",
      "Learning rate:  1e-05\n",
      "Epoch 14/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9429 - AUC: 0.9921 - precision: 0.9465 - recall: 0.9386\n",
      "Epoch 00014: val_loss did not improve from 0.64442\n",
      "End of epoch 13. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 397ms/step - loss: 0.1616 - accuracy: 0.9429 - AUC: 0.9921 - precision: 0.9465 - recall: 0.9386 - val_loss: 0.6814 - val_accuracy: 0.7530 - val_AUC: 0.9136 - val_precision: 0.7584 - val_recall: 0.7446\n",
      "Learning rate:  1e-05\n",
      "Epoch 15/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1594 - accuracy: 0.9407 - AUC: 0.9923 - precision: 0.9462 - recall: 0.9358\n",
      "Epoch 00015: val_loss did not improve from 0.64442\n",
      "End of epoch 14. Learning rate: 1e-05\n",
      "286/286 [==============================] - 116s 407ms/step - loss: 0.1594 - accuracy: 0.9407 - AUC: 0.9923 - precision: 0.9462 - recall: 0.9358 - val_loss: 0.7510 - val_accuracy: 0.7274 - val_AUC: 0.9007 - val_precision: 0.7319 - val_recall: 0.7215\n",
      "Learning rate:  1e-05\n",
      "Epoch 16/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.9448 - AUC: 0.9933 - precision: 0.9490 - recall: 0.9411\n",
      "Epoch 00016: val_loss did not improve from 0.64442\n",
      "End of epoch 15. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 400ms/step - loss: 0.1483 - accuracy: 0.9448 - AUC: 0.9933 - precision: 0.9490 - recall: 0.9411 - val_loss: 0.8236 - val_accuracy: 0.7008 - val_AUC: 0.8862 - val_precision: 0.7043 - val_recall: 0.6939\n",
      "Learning rate:  1e-05\n",
      "Epoch 17/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9442 - AUC: 0.9927 - precision: 0.9487 - recall: 0.9398\n",
      "Epoch 00017: val_loss did not improve from 0.64442\n",
      "End of epoch 16. Learning rate: 1e-05\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.1562 - accuracy: 0.9442 - AUC: 0.9927 - precision: 0.9487 - recall: 0.9398 - val_loss: 0.8364 - val_accuracy: 0.6914 - val_AUC: 0.8793 - val_precision: 0.6980 - val_recall: 0.6836\n",
      "Learning rate:  1e-05\n",
      "Epoch 18/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9499 - AUC: 0.9938 - precision: 0.9541 - recall: 0.9458\n",
      "Epoch 00018: val_loss did not improve from 0.64442\n",
      "End of epoch 17. Learning rate: 1e-05\n",
      "286/286 [==============================] - 109s 379ms/step - loss: 0.1442 - accuracy: 0.9499 - AUC: 0.9938 - precision: 0.9541 - recall: 0.9458 - val_loss: 0.7750 - val_accuracy: 0.7195 - val_AUC: 0.8927 - val_precision: 0.7264 - val_recall: 0.7082\n",
      "Learning rate:  1e-05\n",
      "Epoch 19/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9451 - AUC: 0.9931 - precision: 0.9490 - recall: 0.9414\n",
      "Epoch 00019: val_loss did not improve from 0.64442\n",
      "End of epoch 18. Learning rate: 1e-05\n",
      "286/286 [==============================] - 109s 381ms/step - loss: 0.1513 - accuracy: 0.9451 - AUC: 0.9931 - precision: 0.9490 - recall: 0.9414 - val_loss: 0.9077 - val_accuracy: 0.6777 - val_AUC: 0.8684 - val_precision: 0.6797 - val_recall: 0.6683\n",
      "Learning rate:  1e-05\n",
      "Epoch 20/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9456 - AUC: 0.9930 - precision: 0.9505 - recall: 0.9410\n",
      "Epoch 00020: val_loss did not improve from 0.64442\n",
      "End of epoch 19. Learning rate: 1e-05\n",
      "286/286 [==============================] - 109s 380ms/step - loss: 0.1517 - accuracy: 0.9456 - AUC: 0.9930 - precision: 0.9505 - recall: 0.9410 - val_loss: 0.9373 - val_accuracy: 0.6658 - val_AUC: 0.8633 - val_precision: 0.6683 - val_recall: 0.6594\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "epochs = 20\n",
    "history = squeezenet_model.fit(train_generator, \n",
    "                                steps_per_epoch=len(train_generator), \n",
    "                                validation_data=validation_generator, \n",
    "                                epochs=epochs,\n",
    "                                verbose = 1,\n",
    "                                class_weight = class_weights,\n",
    "                                callbacks=[checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd86915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAK7CAYAAAA9V8z1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAADCvUlEQVR4nOzdd3iUVfbA8e9JrwQIndClSw+gIApWsIAgKthAVOx11dXVVVbX1d3156prWbGBbcHKooIoCiJiISCI9CIl1FDSSE/u74/7Jkz6JJlkJpPzeZ55MvPW82aSOXPve4sYY1BKKaWUbwrwdgBKKaWUKp8maqWUUsqHaaJWSimlfJgmaqWUUsqHaaJWSimlfJgmaqWUUsqHaaJWfkdEForIFE9v600islNEzq6F4y4Vkeud51eKyJfubFuN87QXkXQRCaxurEo1VJqolU9wPsQLHwUikuny+sqqHMsYM8YYM9vT2/oiEXlARJaVsbyZiOSIyMnuHssY864x5lwPxVXsi4UxZrcxJsoYk++J4yvVkGiiVj7B+RCPMsZEAbuBi1yWvVu4nYgEeS9Kn/QOMExEOpVYPglYZ4z5zQsxNRj696jqgiZq5dNEZKSIJIrIH0XkAPCmiDQRkc9EJElEjjnP41z2ca3OnSoiy0XkaWfb30VkTDW37SQiy0QkTUQWi8iLIvJOOXG7E+PjIvK9c7wvRaSZy/qrRWSXiBwRkYfK+/0YYxKBb4CrS6y6BnirsjhKxDxVRJa7vD5HRDaJSIqIvACIy7ouIvKNE99hEXlXRBo7694G2gOfOjUi94tIRxExhYlNRNqIyHwROSoi20TkBpdjzxCR90XkLed3s15E4sv7HYjIcyKyR0RSRWSViIxwWRcoIn8Ske3OsVaJSDtnXW8R+cqJ4aCI/MlZPktE/upyjJEikujyeqfz9/grcFxEgpyajcJzbBCR8SVivEFENrqsHygi94nIRyW2e15EnivvWlXDpIla1QetgKZAB2A69u/2Ted1eyATeKGC/YcCm4FmwD+A10VEqrHte8DPQCwwg9LJ0ZU7MV4BXAu0AEKAewFEpBfwsnP8Ns75ykyujtmusYhId6C/E29Vf1eFx2gGfAw8jP1dbAeGu24CPOnE1xNoh/2dYIy5muK1Iv8o4xRzgERn/4nA30TkTJf1Y51tGgPzK4l5pXO9TZ1r/kBEwpx19wCTgfOBRsA0IENEooHFwBdODCcBX1dwjpImAxcAjY0xedjfzwggBvgL8I6ItAYQkUuxv5trnBjGAkewtSGjXb7gBGFrQt6qQhyqITDG6EMfPvUAdgJnO89HAjlAWAXb9weOubxeClzvPJ8KbHNZFwEYoFVVtsUmuTwgwmX9O8A7bl5TWTE+7PL6FuAL5/kjwByXdZHO7+Dsco4dAaQCw5zXTwD/q+bvarnz/BrgR5ftBJtYry/nuBcDv5T1HjqvOzq/yyBsUs8Hol3WPwnMcp7PABa7rOsFZFbh7+cY0M95vhkYV8Y2k13jLbFuFvBXl9cjgcQS1zatkhjWFJ4XWATcWc52C4EbnOcXAhtq+v+jD/97aIla1QdJxpiswhciEiEirzhVw6nAMqCxlN+i+EDhE2NMhvM0qorbtgGOuiwD2FNewG7GeMDleYZLTG1cj22MOY4tgZXJiekD4Bqn9H8lTqmsGr+rQiVjMK6vRaSliMwRkb3Ocd/BlrzdUfi7THNZtgto6/K65O8mTMq5Hywi9zrVyikikowt1RbG0g5b2i2pvOXuKvbei8g1IrJGRJKdGE52IwawtSFXOc+vAt6uQUzKT2miVvVBySne/gB0B4YaYxoBpzvLy6vO9oT9QFMRiXBZ1q6C7WsS437XYzvnjK1kn9nAZcA5QDTwaQ3jKBmDUPx6/4Z9X/o4x72qxDErmpZvH/Z3Ge2yrD2wt5KYSnHuR9+PvfYmxpjGQIpLLHuALmXsugfoXM5hj2NrKQq1KmObousTkQ7Aq8BtQKwTw29uxAAwD+grtnX+hcC75WynGjBN1Ko+isbea00WkabAo7V9QmPMLiABmCEiISJyKnBRLcX4IXChiJwmIiHAY1T+v/odkAzMxFab59Qwjs+B3iIywSnJ3kHxhBUNpAMpItIWuK/E/gcpJxEaY/YAK4AnRSRMRPoC12FL5VUVjb0lkQQEicgj2PvAhV4DHheRrmL1FZFY4DOgtYjcJSKhIhItIkOdfdYA54tIUxFpBdxVSQyR2MSdBCAi12JL1K4x3Csig5wYTnKSO05N0Yc47R+MMbur8TtQfk4TtaqPngXCgcPAj9gGQXXhSuBUbDX0X4G5QHY52z5LNWM0xqwHbsV+eO/H3nNNrGQfg63u7kDxxkjVisMYcxi4FHgKe71dge9dNvkLMBBbev0c2/DM1ZPAw05V8L1lnGIy9r71PuAT4FFjzGJ3YithEfaatmCrz7MoXi39DPA+8CX2Pv7rQLhT7X4O9svWAWArMMrZ521gLfZe9JfY97lcxpgNwP8BP2C/oPTB5XdljPkA227gPSANW4pu6nKI2c4+Wu2tyiT2/1spVVUiMhfYZIyp9RK98l8i0h7YhG3gmOrteJTv0RK1Um4SkcFi+w8HiMhoYBy2dKRUtYhIALYL2RxN0qo8OqqOUu5rha3ijcVWRd9sjPnFuyGp+kpEIrFV5buA0V4OR/kwrfpWSimlfJhWfSullFI+zOeqvps1a2Y6duzo7TCUUkqpOrNq1arDxpjmZa3zuUTdsWNHEhISvB2GUkopVWdEZFd567TqWymllPJhmqiVUkopH6aJWimllPJhmqiVUkopH+ZWohaR0SKyWUS2icgDZazvICJfi8ivIrJUROJc1uU707+tEZH5ngxeKaWU8neVtvp25q19ETuAfSKwUkTmOwPRF3oaeMsYM1tEzsQOyH+1sy7TGNPfs2ErpZRSDYM73bOGANuMMTsARGQOdoxj10TdCzteLcASdPxjpZRSlcjKzef3w8fZeiid7YfSCQ0OoEPTSDrERtAhNoLosGBvh+gT3EnUbSk+bVwiMLTENmuBCcBzwHggWkRijTFHgDARScDOGfuUMWZeyROIyHRgOkD79u2reg1KKaV8WGZOPtuT0tl6KI2tB9PZeiidbYfS2XXkOAXOKNYiUHJE69jIENrHRtAxNpL2TSPo2CyC9k0j6RgbQdPIEESk7i/GCzw14Mm9wAsiMhVYBuwF8p11HYwxe0WkM/CNiKwzxmx33dkYMxM74T3x8fE6+LhSStVDaVm5bDt0IhFvPZjG1kPp7E3OLErCQQFCx2aR9GgVzUV9W3NSy2i6toiiU7NIcvML2H00g11HCh/H2XUkg59/P8q8NXuLJfKo0KCikneH2Eg6NHV+xkbQqlEYAQH+k8TdSdR7gXYur+OcZUWMMfuwJWpEJAq4xBiT7Kzb6/zcISJLgQFAsUStlFLKMwoKDEeO57AvOZN9yZmkZeURGCAEBYr9GSAEBgQ4P+XEz8BylgcEEBgoxZbnFRh+P3zcSca2pLztUDr7U7KK4ggJDKBz80gGtG/CZfHt6Noiiq4to+gQG0lwYNntmMOCA+ndJobebWJKrcvKzSfxWGZR8t515Di7jmawcX8aX204SG7+iSweEhRgS+CxETSPDqWgAPKNoaDAkFdgip7nFxgKjLPMeZ5f4PIwFG2X77qfMTxxcR9O69rM829gGdxJ1CuBriLSCZugJwFXuG4gIs2Ao8aYAuBB4A1neRMgwxiT7WwzHPiHB+NXSqk6YYwhJTOXpLRsUjJziQwNolF4MDHhwUSGBNZZNWxGTh77krOKEvG+5Ez2Oq/3p2SyLyWLnLyCOokFIDw4kJNaRHFq51i6tIhyEnI07ZqEE1ROQq6OMOc8J7WIKrUuv8CwLznTJvCjx4uVxtfsSSEwAAJFCAwUAkUICLA/AwNOPAJcXgcFBBAaVLgdBAYE2GO4bNcovO5G4K70TMaYPBG5DVgEBAJvGGPWi8hjQIIxZj4wEnhSRAy26vtWZ/eewCsiUoDtCvZUidbiSql6Ijsvn0Op2RxKyyI1M4/oMJuoGoUF0yg8iPDguktWnpSVm09SWjZJ6dkcSrU/k9JcH1lF611Lba4ChGK/i0ZhxZ/HhAfb9YXrSmwb4ST6/ALDobSsouS7v0Qi3peSSXJGbqlzt2wURpvG4fSJa8x5ve1z+wgjJjyYggLIKyggv+BE6dH+LCAv35S9vPC1sz63cP98gwh0jI3kpBZRtG0c7vVq5sAAoV3TCNo1jeA06qaUW5d8bj7q+Ph4o5NyKFV3cvIKSErP5mBqFodSsziY6jxPK1yWzcG0rFIJoqSgAHESUFDppOWUPMtb1ygsmLDggKJEb4yhwFC6atKl+rFkdWXx7WxVZ36BIT07r3jiTbfJ95DzOi0rr9S1iNiGTM2jw2geHUrzqFD703nEhAeTkZ1HalYuqZmFP3NJycwlNSuP1MzcYusycvJLnaPk7y4qLIi0rDzyC4p/JjcKCyqWeNs0Dqet87p1TBgtG4WVW5Ws6g8RWWWMiS9rnc/NnqWU8oycvAIOp2e7JFybhA+lFU/GR4/nlNo3MEBoER1Ki0ZhdIiNYHCnJrSMtkmhRaNQGoUHczw7r1iSSs1yEpXLsgOpWUXrsnIrro4NcqoV8woKKKil8kNUaFBR4u3ZqhGndy2egJtHhdIiOpSmkSEerbbNzS8gzSWBl/w9FSb1mPBgm4Abh9HWScTaRUlpolaqHjHGkJyR61JNm1WqtFhYfVtWCThAoHl0KC0bhRHXJIJBHZrQIjqMlo1Ci5Jwy0ZhNI0I8Xh1ZnZevkuyynOS1YkklZaVi4Fi9xCDAgvvCUKAnGjQVLg+wKXRk+s9xsL7jwEBQmRIIC2iw2gWHUJEiHc+8oIDA2gaGULTyBCvnF/Vb5qolaqGwqrZwp8Fzi2kghLLjTEYZ71x1htD0TLX13kFBRzLyCmWeA8Vq67N5nA590nDggNoHh1Ki+gwujSP4pTOscVKia1ibBKOjQwl0Ev3E0ODAgmNCqRZVKhXzq9UfaWJWilHdl4+h9NzOJx2IikeLkqQOSSlZ9t16WXf1/S0AIHYqBP3R7u1jHaScWip+6ZRoUH1siGXUqpymqhVvVZZidUAqZm5LgnXSbpOwj3s8jO1nOQbHWbvazaLCqVn60acHm3v0QaKECAUVREHiCBiE2yAnFgWICAuP0VclmNfi1O92yQipCj5erP0q5TyHZqoVZ0zxnA4PYetB9PY4oxctPVgOr8fOU5ufgEFBTbBFiVbl6Rbssq5uqJDTyTfHq2iaX5SM5o5JdRmUaE0K0qWIYQFB3rq0pVSqso0Uata45qQtx5Kt0nZGcXomEtDp0ZhQXRrGc2o7s2L+uIWljoFW2IVXEujJ9aVKqE6r4XC1xAdFmyTb1RIUSLW5KuUqi80UasaK0rIzoD7lSXk0Se3pmuLKLq1jKZbyyiaR4fq/VWllCqHJmrlNmMMh9Ky2e4Mun+i2rq8hNyKri2i6dYymq4to2ihCVkppapME7UqJTe/gF1HMtieZGfA2Z6Uzvak4+w4lE5a9okGV9ElEnLXlraUrAlZKaU8RxN1A5aalcuOpOMnkvGhdLYlpbP7SAZ5Li21WjUKo0uLSCYMbEuXFlF0aW4HxteErJRStU8TtZ8zxnAgNcsm40O2ZFxYUj6Ull20XeEcsd1aRDPm5FZ0aW4TcpcWUUSF6p+JUkp5i34C+4nC+8dbDqax+YBtzLX5oJ0jNr1EdXWX5lGc3q25k4ztDDjtmkbowP5KKeWDNFHXQ0fSs9nitKrefMD2Rd5yMJ2UzBMNumIjQ+jWMppLBrblpJbRRQm5eZRWVyulVH2iidqHpWTmOoOCpDvJ2D4Op5+Y7ahRWBDdW0VzQd/WdG95okGXjqeslFL+QRN1HTLGkJ1XQEZOPsez8ziek8fx7HwynJ8pmTm2H/KhdLYcSONAalbRvpEhgXRtGc2ZPVo4/Y+j6d5KW1grpZS/00RdDTuS0lm9O7kowRb7WZiEs/NsQs7JIyPb+ZmTX2pS+JJCgwLo2jKKYV1i6dbKDgjSrWU0bWLCPT7toFJKKd+niboKNu5P5YUl21iwbj/GJd8GCESGBBERGkhkSBCRoUFEhATSPDqUDiERxdYV/QwJLNqu8GejMDtpvE7EoJRSqpAmajes3ZPMv7/ZxuKNB4kKDeKWkV24ZGAcMeHBRIYGERoUoNXPSimlaoUm6gr8/PtRXliyjWVbkogJD+bus7sxdVhHYiKCvR2aUkqpBkITdQnGGL7fdoTnv9nKz78fpVlUCA+M6cFVp3TQgT+UUkrVOc08DmMM32w6xL+/2caaPcm0ahTGoxf1YtLg9oSH6JSISimlvMOtRC0io4HngEDgNWPMUyXWdwDeAJoDR4GrjDGJzropwMPOpn81xsz2UOweUVBg+GL9Af79zTY27k8lrkk4fxvfh0sGtSU0SBO0Ukop76o0UYtIIPAicA6QCKwUkfnGmA0umz0NvGWMmS0iZwJPAleLSFPgUSAeMMAqZ99jnr6QqsrLL+DTX/fx4pLtbDuUTudmkTx9aT/G9W+jQ2kqpZTyGe6UqIcA24wxOwBEZA4wDnBN1L2Ae5znS4B5zvPzgK+MMUedfb8CRgP/rXHk1ZSTV8DHqxN5ael2dh/NoHvLaP49eQDn92mt3aKUUkr5HHcSdVtgj8vrRGBoiW3WAhOw1ePjgWgRiS1n37YlTyAi04HpAO3bt3c39irJys1n7so9vPLtdvalZNE3LoaHLxjE2T1b6kAiSimlfJanGpPdC7wgIlOBZcBeIN/dnY0xM4GZAPHx8RUP3VVFx7PzeO+n3cz8bgdJadnEd2jCk5f05fSuzbTvs1JKKZ/nTqLeC7RzeR3nLCtijNmHLVEjIlHAJcaYZBHZC4wsse/SGsRbJUlp2Zz7r285lpHL8JNieX7SAE7p3FQTtFJKqXrDnUS9EugqIp2wCXoScIXrBiLSDDhqjCkAHsS2AAdYBPxNRJo4r8911teJ5tGhXHVKB0Z2b8GgDk0q30EppZTyMZUmamNMnojchk26gcAbxpj1IvIYkGCMmY8tNT8pIgZb9X2rs+9REXkcm+wBHitsWFZX/nBu97o8nVJKKeVRYoxHbwnXWHx8vElISPB2GEoppVSdEZFVxpj4stZph2GllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh7mVqEVktIhsFpFtIvJAGevbi8gSEflFRH4VkfOd5R1FJFNE1jiP/3j6ApRSSil/FlTZBiISCLwInAMkAitFZL4xZoPLZg8D7xtjXhaRXsACoKOzbrsxpr9Ho1ZKKaUaCHdK1EOAbcaYHcaYHGAOMK7ENgZo5DyPAfZ5LkSllFKq4XInUbcF9ri8TnSWuZoBXCUiidjS9O0u6zo5VeLfisiImgSrlFJKNTSeakw2GZhljIkDzgfeFpEAYD/Q3hgzALgHeE9EGpXcWUSmi0iCiCQkJSV5KCSllFKq/nMnUe8F2rm8jnOWuboOeB/AGPMDEAY0M8ZkG2OOOMtXAduBbiVPYIyZaYyJN8bEN2/evOpXoZRSSvkpdxL1SqCriHQSkRBgEjC/xDa7gbMARKQnNlEniUhzpzEaItIZ6Ars8FTwSimllL+rtNW3MSZPRG4DFgGBwBvGmPUi8hiQYIyZD/wBeFVE7sY2LJtqjDEicjrwmIjkAgXATcaYo7V2NUoppZSfEWOMt2MoJj4+3iQkJHg7DKWUUqrOiMgqY0x8Wet0ZDKllFLKh2miVkoppXyYJmqllFLKh2miVkoppXxYpa2+lVJKVU9ubi6JiYlkZWV5OxTlI8LCwoiLiyM4ONjtfTRRK6VULUlMTCQ6OpqOHTsiIt4OR3mZMYYjR46QmJhIp06d3N5Pq76VUqqWZGVlERsbq0laASAixMbGVrmGRRO1UkrVIk3SylV1/h40USullFI+TBO1Ukr5qSNHjtC/f3/69+9Pq1ataNu2bdHrnJycCvdNSEjgjjvuqPQcw4YN81S4qhzamEwppfxUbGwsa9asAWDGjBlERUVx7733Fq3Py8sjKKjsNBAfH098fJkjWhazYsUKj8Ral/Lz8wkMDPR2GG7TRK2UUnXgL5+uZ8O+VI8es1ebRjx6Ue8q7TN16lTCwsL45ZdfGD58OJMmTeLOO+8kKyuL8PBw3nzzTbp3787SpUt5+umn+eyzz5gxYwa7d+9mx44d7N69m7vuuquotB0VFUV6ejpLly5lxowZNGvWjN9++41BgwbxzjvvICIsWLCAe+65h8jISIYPH86OHTv47LPPisW1c+dOrr76ao4fPw7ACy+8UFRa//vf/84777xDQEAAY8aM4amnnmLbtm3cdNNNJCUlERgYyAcffMCePXuKYga47bbbiI+PZ+rUqXTs2JHLL7+cr776ivvvv5+0tDRmzpxJTk4OJ510Em+//TYREREcPHiQm266iR077ESPL7/8Ml988QVNmzblrrvuAuChhx6iRYsW3HnnndV+76pCE7VSSjUwiYmJrFixgsDAQFJTU/nuu+8ICgpi8eLF/OlPf+Kjjz4qtc+mTZtYsmQJaWlpdO/enZtvvrlUX+BffvmF9evX06ZNG4YPH873339PfHw8N954I8uWLaNTp05Mnjy5zJhatGjBV199RVhYGFu3bmXy5MkkJCSwcOFC/ve///HTTz8RERHB0aN2AsYrr7ySBx54gPHjx5OVlUVBQQF79uyp8LpjY2NZvXo1YG8L3HDDDQA8/PDDvP7669x+++3ccccdnHHGGXzyySfk5+eTnp5OmzZtmDBhAnfddRcFBQXMmTOHn3/+ucq/9+rSRK2UUnWgqiXf2nTppZcWVf2mpKQwZcoUtm7dioiQm5tb5j4XXHABoaGhhIaG0qJFCw4ePEhcXFyxbYYMGVK0rH///uzcuZOoqCg6d+5c1G948uTJzJw5s9Txc3Nzue2221izZg2BgYFs2bIFgMWLF3PttdcSEREBQNOmTUlLS2Pv3r2MHz8esIOIuOPyyy8vev7bb7/x8MMPk5ycTHp6Oueddx4A33zzDW+99RYAgYGBxMTEEBMTQ2xsLL/88gsHDx5kwIABxMbGunVOT9BErZRSDUxkZGTR8z//+c+MGjWKTz75hJ07dzJy5Mgy9wkNDS16HhgYSF5eXrW2Kc+//vUvWrZsydq1aykoKHA7+boKCgqioKCg6HXJ/squ1z116lTmzZtHv379mDVrFkuXLq3w2Ndffz2zZs3iwIEDTJs2rcqx1YS2+lZKqQYsJSWFtm3bAjBr1iyPH7979+7s2LGDnTt3AjB37txy42jdujUBAQG8/fbb5OfnA3DOOefw5ptvkpGRAcDRo0eJjo4mLi6OefPmAZCdnU1GRgYdOnRgw4YNZGdnk5yczNdff11uXGlpabRu3Zrc3FzefffdouVnnXUWL7/8MmAbnaWkpAAwfvx4vvjiC1auXFlU+q4rmqiVUqoBu//++3nwwQcZMGBAlUrA7goPD+ell15i9OjRDBo0iOjoaGJiYkptd8sttzB79mz69evHpk2bikq/o0ePZuzYscTHx9O/f3+efvppAN5++22ef/55+vbty7Bhwzhw4ADt2rXjsssu4+STT+ayyy5jwIAB5cb1+OOPM3ToUIYPH06PHj2Klj/33HMsWbKEPn36MGjQIDZs2ABASEgIo0aN4rLLLqvzFuNijKnTE1YmPj7eJCQkeDsMpZSqsY0bN9KzZ09vh+F16enpREVFYYzh1ltvpWvXrtx9993eDqtKCgoKGDhwIB988AFdu3at0bHK+rsQkVXGmDL7w2mJWimlVK169dVX6d+/P7179yYlJYUbb7zR2yFVyYYNGzjppJM466yzapykq0MbkymllKpVd999d70rQbvq1atXUb9qb9AStVJKKeXDNFErpZRSPsytRC0io0Vks4hsE5EHyljfXkSWiMgvIvKriJzvsu5BZ7/NIlK3bdqVUkqpeq7Se9QiEgi8CJwDJAIrRWS+MWaDy2YPA+8bY14WkV7AAqCj83wS0BtoAywWkW7GmHxPX4hSSinlj9wpUQ8BthljdhhjcoA5wLgS2xigkfM8BtjnPB8HzDHGZBtjfge2OcdTSilVy0aNGsWiRYuKLXv22We5+eaby91n5MiRFHaRPf/880lOTi61zYwZM4r6M5dn3rx5RX2QAR555BEWL15chehVIXcSdVvAdaTzRGeZqxnAVSKSiC1N316FfRGR6SKSICIJSUlJboaulFKqIpMnT2bOnDnFls2ZM6fciTFKWrBgAY0bN67WuUsm6scee4yzzz67WsfylsLR0bzNU92zJgOzjDH/JyKnAm+LyMnu7myMmQnMBDvgiYdiUkop37HwATiwzrPHbNUHxjxV7uqJEyfy8MMPk5OTQ0hICDt37mTfvn2MGDGCm2++mZUrV5KZmcnEiRP5y1/+Umr/jh07kpCQQLNmzXjiiSeYPXs2LVq0oF27dgwaNAiwfaRLThe5Zs0a5s+fz7fffstf//pXPvroIx5//HEuvPBCJk6cyNdff829995LXl4egwcP5uWXXyY0NJSOHTsyZcoUPv30U3Jzc/nggw+KjRoGDXM6THdK1HuBdi6v45xlrq4D3gcwxvwAhAHN3NxXKaVULWjatClDhgxh4cKFgC1NX3bZZYgITzzxBAkJCfz66698++23/Prrr+UeZ9WqVcyZM4c1a9awYMECVq5cWbRuwoQJrFy5krVr19KzZ09ef/11hg0bxtixY/nnP//JmjVr6NKlS9H2WVlZTJ06lblz57Ju3Try8vKKxtYGaNasGatXr+bmm28us3q9cDrM1atXM3fu3KJ5sV2nw1y7di33338/YKfDvPXWW1m7di0rVqygdevWlf7eCqfDnDRpUpnXBxRNh7l27VpWr15N7969mTZtWtHMW4XTYV511VWVnq8y7pSoVwJdRaQTNslOAq4osc1u4Cxgloj0xCbqJGA+8J6IPINtTNYVqLtJPJVSyldUUPKtTYXV3+PGjWPOnDlFieb9999n5syZ5OXlsX//fjZs2EDfvn3LPMZ3333H+PHji6aaHDt2bNG68qaLLM/mzZvp1KkT3bp1A2DKlCm8+OKLRaXQCRMmADBo0CA+/vjjUvs3xOkwK03Uxpg8EbkNWAQEAm8YY9aLyGNAgjFmPvAH4FURuRvbsGyqsYOIrxeR94ENQB5wq7b4VkqpujNu3DjuvvtuVq9eTUZGBoMGDeL333/n6aefZuXKlTRp0oSpU6eWmhLSXVWdLrIyhVNlljdNZkOcDtOtftTGmAXGmG7GmC7GmCecZY84SRpjzAZjzHBjTD9jTH9jzJcu+z7h7NfdGLPQI1ErpZRyS1RUFKNGjWLatGlFjchSU1OJjIwkJiaGgwcPFlWNl+f0009n3rx5ZGZmkpaWxqefflq0rrzpIqOjo0lLSyt1rO7du7Nz5062bdsG2FmwzjjjDLevpyFOh6kjkymllJ+bPHkya9euLUrU/fr1Y8CAAfTo0YMrrriC4cOHV7j/wIEDufzyy+nXrx9jxoxh8ODBRevKmy5y0qRJ/POf/2TAgAFs3769aHlYWBhvvvkml156KX369CEgIICbbrrJ7WtpiNNh+vc0l8bA989C7/HQpKNnjqmUUm7SaS4bHnemw9RpLl2l7Yfvn4M3RsOhjd6ORimllB+rrekw/TtRN2oDUxfYkvWbY2DvKm9HpJRSyk8VTof5f//3fx49rn8naoCWvWDaFxDaCGaPhd+XeTsipVQD4mu3F5V3Vefvwf8TNUDTTjBtEcS0g3cmwqYF3o5IKdUAhIWFceTIEU3WCrBJ+siRI1XuUuapIUR9X6PWcO0CeHcizL0KLn4J+k3ydlRKKT8WFxdHYmIiOoeBKhQWFkZcXFyV9mk4iRogoilc8z+YcwV8ciNkpcDQG70dlVLKTwUHB9OpUydvh6HquYZR9e0qNBqu+AB6XAgL74dv/2EbmymllFI+qOElaoDgMLh0NvSbDEuegEUPabJWSinlkxpW1berwCAY9xKExcCPL9pq8Iues8uVUkopH9Gws1JAAIx+CsIaw7dPQXYKXPI6BIV6OzKllFIKaKhV365EYNSDNmFv/BTeuxyy070dlVJKKQVooj7hlJvh4pfh92/h7Ysh85i3I1JKKaU0URfT/wq47C3YvxbevADSDng7IqWUUg2cJuqSel4EV7wPx3bayTyO7fR2REoppRowTdRl6TLKDoySecyZeWuTtyNSSinVQGmiLk+7wXbIUVOgM28ppZTyGk3UFWnZ25l5K9qZees7b0eklFKqgdFEXZmmnZ2Zt+LgnUt05i2llFJ1ShO1Oxq1hmsX2hL23Ktg7VxvR6SUUqqB0ETtroimMGU+dBgGn0yHla97OyKlvCNxFSS8AQUF3o5EqQbBrUQtIqNFZLOIbBORB8pY/y8RWeM8tohIssu6fJd18z0Ye90LjYYrP4Su58GC+2x/a6UaAmNg22KYdSG8diZ8djf8+JK3o/KO9EOw5G+QrnNMq7ohppJZo0QkENgCnAMkAiuBycaYDeVsfzswwBgzzXmdboyJcjeg+Ph4k5CQ4O7m3pFxFF46BaJawA1LIDDY2xEpVTvy82DDPPj+WTiwDqLbwKm3wK4fYOuXcMPX0Lqft6OsW5/eCatmQVRLmDATOo/0dkTKD4jIKmNMfFnr3ClRDwG2GWN2GGNygDnAuAq2nwz8t+ph1iMRTeGC/7MfXN8/5+1olPK83ExY+Rq8MAg+ug5ys2Dci3DnWhh2O4x7ASKbw4fXQc5xb0dbd1L3wZr3oPv5djKfty6Grx+3X2iUqiXuJOq2wB6X14nOslJEpAPQCfjGZXGYiCSIyI8icnE5+013tklISqon1Uk9L4Le4+Hbv+uAKMp/ZCbDsqfh2T7w+R8gIhYufwdu/RkGXAVBIXa7iKYw4RU4sg0W/tGrIdepFS9AQT6MfhKmL7G/k++ehlkXQPKeyvdXqho83ZhsEvChMSbfZVkHpzh/BfCsiHQpuZMxZqYxJt4YE9+8eXMPh1SLxvwTQqJg/m32n9fXZCbDK2fAoofsPUalypO6H758GP7VG7553FZnT/kMrv/afikNKOOjotPpMOIe+OVtWP9J3cdc144fgVVvQt/LoElHCIm0NQuXvA4H18N/ToONn3k7SuWH3EnUe4F2Lq/jnGVlmUSJam9jzF7n5w5gKTCgylH6qqjmMOYfkLgSfvqPt6Mpzhj4362wfw388IK9x6hUSYe3wv9ug+f6wg8vQrfRcON3cNVH0GmEnQa2IiMfhLbx9r6tv5cof/qPvSVw2t3Fl/eZCDd+a5P33CttQ9PcLK+EqPyTO4l6JdBVRDqJSAg2GZdqvS0iPYAmwA8uy5qISKjzvBkwHCizEVq91Wei/XD7+nE4usPb0Zzww4uw6TM49wk4+RJYPAN+fd/bUSlfkbjKjgnwwmBY9wEMvAZuXw0TX4fWfd0/TmAwXPKa7ar18Q3+e682KxV+fgV6XgjNu5deH9sFrvsKTrkVfp4Jr59tvwQp5QGVJmpjTB5wG7AI2Ai8b4xZLyKPichYl00nAXNM8WbkPYEEEVkLLAGeKq+1eL0lAhf+y35gzb/DN/qW7v4JFj9qqyxPvdXOs93hNJh3C+z41tvRKW8p2cXq92Uw4g9w12+2cWTTTtU7btNOcOEzsPsH+O7/PBuzr0h4HbJS7O+rPEEhMPpvMHkupOy1t53W+He7WlU3Ku2eVdfqRfessqx+C+bfDhc8A4Ov814cxw/Df0bYD40bl0FYjF2emWxnAkvda0dZa3Wy92JUdatUF6vW9gvcoKl2bABP+fhGWPe+/ftqf4rnjuttuZm2cV2rvnD1x+7tk7oPProBdi2HvpPsF6FQt3upqgaoou5Zmqg9xRh4+2JbpXjLD9C4XaW7eFxBAbx7Cez8Hq7/qnT/1pREeO1sQOz6mLi6j1GV7ejvsHYO5KR79rimADYvsPOqx3aF4XfaxlBBoZ49D9jq4VdG2IaVNy2H8MaeP4c3/PwqLLgXpi6AjsPd368gH5b90/YMadIJLn2z4fU5V27TRF1Xju2El4ZBh1PtCGaVNcTxtG//AUuegAufhfhry97mwG+2ZB0TZ2cG85cP0/oqMQFWPA8bP7Wvg8I9f46WvWyC7n5B2a23PSlxFbxxrr3tMvHNuv8f8LT8XHh+ADRqa/9fqnM9O5fDR9dDxhE4968wZHr9/70oj6soUQfVdTB+rUlHOPtRWHi/LR31n1x3596x1A5r2OcyW6VZnlYnw6R37Exgc6+yrXtro3SlyldQAFsWwop/2/u6YTE2kQ650U4AU5/FDYJRf4KvH4OTzrb9jOuzX9+HlD22HUp1k2vH0+Cm72HezfazYce3tltXRFPPxqr8lpaoPa2gAN4cA0mb7CAR0S1r/5yp+22VY3hTuOEb9+6FrZ1rJxc5eSJMeLX2S1rekpIIgaG2K5235WbC2v/aQTOOboeY9nY4zgFXefZesbcV5MNb42DvattOotlJ3o6oegry4cWhEBxmu6zVtBRsDPz4Mnz1iB1+9JLXbO2bUtR8CFFVFQEBdqjFvCz4/J7aH2gkP88O8ZhzHC57y/0GK/0uh7Mehd8+hK9n1GqIdS49CX56xd6P/1dveLqrfb7sn7YxVV1/OT1+GJY8aWP57G4Ia2Srhe/4BU652b+SNEBAoB0DOygEPpoGednejqh6Ns6HI1ttS29PVFWL2C9m131pe4nMOh++/advDpakfIqWqGvL8mdtF6lLZ9mhRmvL4hmw/F8wfqZNvlVhjB0mMuF1O8ra0Om1EmKdyE6DTZ/bqsodS8HkQ8uTbT/3/FzY8gXsXWW3bdQWup1n+793Oh2Ca+G+MMDhbXawmbX/tV/cuo2x42R3GNYw7lFu+hzmXGGv+dy/ejuaqjHG1lLlZsGtP9kvH56UlWq/tP32of0bnPAqRLfy7DlUvaKNybwhP88OepCSCLf8BJGxnj/H5i/gv5fbe9IXVXNykIJ8e69680K4/G3bCKi+yMuB7V/b5Lx5IeRl2urkPhOhz6W2EZWrtIOw7SubtLcvsS2sg8Kh8xk2cXc9D2LKHMbefcbA7h/t/efNCyAwBPpNglNvg+bdanbs+uize+wXwas+hpPO8nY07tv6Fbw7Eca9BAOurJ1zGAO/vGNHMguJhPGvQNeza+dcyudpovaWg+vtoAe9x8Mlr3r22Mm7bX/pxu3gusX2Plp15WTA7Ivg4G9wzXxoP9RzcXpaQYFtgLXuA9s3OPOYnTii93jbkK7dEPdKq3nZsOt72LLIJvnkXXZ5qz62pN1tNLQZ6P69+4J823J7xb9hbwKEN4HBN8CQG+x0qA1VbibMHGmnhr15hW+0FXDHG6Ptl+w7fqn9aWyTNsMH18Kh9bZR4ZmPQKC2821oNFF709KnYOmTdrSi7qM9c8y8HHhztB2icPpSO3xhTR0/DK+fYxPfdV9Bs641P6anGGO/9Kx7H9Z9BKmJEBwBPS6wybnLqJp9mBoDh7fYkvaWRfaLgCmw0zh2PdeWtjuPsveWS8o5Dr+8a6u4k3dB0852MJF+V0BIRPVj8icH18PMUbbm4or3fb/af+f39v5xXd4Oys2ELx60k350GA4T39Cq8AZGE7U35eXYEkXmUbjlR8/0W174RztBwGVvQ6+xlW/vrqM74LVzbDXc9Yu9XxI8tsvew/v1A0jaCAFB0OUsW63d43wbZ23IOArbvraJe9tXdujIgGA72EW30TZxB0fYMZ1Xvg5ZydBuqL0X2/18z9/P9Ac/zYSF98Hov8MpN3k7moq9PQEO/Ap3rau99gvlWTsXPrvLzso38XV7/1o1CJqovW3vanjtLNsNZ+y/a3as9Z/AB1PhlFvsnLielrjKzq3bvDtM/bzuhz08fgTWfwzrPoQ9P9pl7U6BvpdCr/G1c6+/Ivl5sOenE6Xtw5vtcgmwJfGeF8Kpt/v27QJfYAz8dxJs/8Z2IWzVx9sRlW3fL/aL9dkzSs+SVVcObYT3r7FzfY96CE67x3+7T6oimqh9wVeP2rGWr55nq2qr4/A2+yHSoocdzjAoxIMButj8BcyZbAesmPTf2r9flptpG16tnWM/yAvyoHlPm5xPnghNOtTu+avi6A7Y8iWkH7RfvDxx26GhOH4YXh5uB3iZvtQ3bw3MvQp2LIO7fyv7VkddyU6HT++A3z6yt1/Gv+L/A6QU5NsvwL5+a6SWaKL2BbmZdmL5/By4+Yeql1RzM21f4NS9dvCF2h5LPOEN231k4DVw0fOe/+cxxt4LXvtfWD8PslNtt6k+l9qHThrin7YvsWPiD7oWLnrW29EUd2gTvDQUTr8PznzY29HY/5GVr9l719Gt4NLZduQ3f7T7J1tT2GmE/VLSAJO1DnjiC4LD7UAoyXvgm8ervv+C+2yr7Amv1s2EH/HTYMS9dlawZf/03HGP7rBDnT7Xz47gtu4j6HGhbW1+129wzl80SfuzLqNg2B220dSGUtPae9f3z9q2B0Nv9nYklojtNXDdIkDgjfPsvX4fK1zV2KpZ9nZbbgb8OtfOWaCK0T4Adan9KXZA/p9egV4Xuz984Jr34Je37QhJXc+p1RCLOfNhW4Jf8oQt7Va3P2lmsr23vnaOc99ZoPNIe/+t54W11yhM+aYz/ww7v7PTwrYdVPO+655wbJftjz/0prpvB1GZtoPgxm+dscLvszVRY5+v/yPa5eXAFw/YfvZdzoRLXodFf4Klf7NjDtTmQFH1jFZ917XsdHj5VDsQxk3LK29VenADvHomxMXb+9t13b8yLwfeu9TOAHTFXHvf2h35ubbl9Nr/2n7K+dnQrLudqKTPZb7x4ay858h2Ow5AmwEwZb73W8p/do/9MnznWmjUxruxlKegwJb6v3kcmnaxQwaXHNSnvkg/ZBvM7f7B9h0/61H7N5CXbcd02P8rTFto/z4aCK369iWhUbbl95Ftto91RbLT7R9zaLQdwN8bgyAEhdhuYM17wvtTYN+a8rc1BvavtffUnulpR03b+Z2dcnP6UjsU42l3a5JWthHe+f+EXcth+TPejSXtgB0hrP8Vvpukwbb8HnGPvU2UlWK/wK/5r7ejqrq9q22j2H1rbCn6nMdOfFELCoXL34XIZvDfK+x7ozRRe0XnkbaR1orn7R9tWYyBT++0syx5e/CDsEZw5QcQ1hjeu8xWE7pK3Q/fPwcvD4NXTrcNYNqfaluM/2EzjPm7/WbcABuIqAr0vwJOvsROWLJnpffi+OFFKMi1Jbv6oNMIuOk7WyU+7yaYf4cdk7w+WDvHjvomAfbee5+JpbeJag6T59gvI/+dbBvSNnBa9e0tWSnw4il2qMnpS0t3tVr5mp0w48w/w+n3eiXEUg5ttA1aolraavhdK2zV9o4ldiSvuCF2XOve4/2/K4nyjKwU2xsCscknLKZuz59xFJ7tA93H2Fqr+iQ/z7YfWf6M7Zd+2Vt2ZDxflJ9np/f88UXoOMJOVhTZrOJ9Nn0Oc66EkyfYkreff9HXqm9fFBZjJ6M/tL501d++X2z18Unn2MEOfEWLnjDpPTi2E/7VCz6+3g5jOuIPcPtquP4rGHydJmnlvrAYmPCaHVf78z/UfYvmn2fayVl86f/MXYFBcPajdnji5D3wykjY+Jm3oyrt+BF4Z7xN0kNvgqs/qTxJgx0i+KxHbF/yZU/Xfpw+TEvU3vbRDbZF9I3fQsvedqztV86wnf9v+s43k97mhXZ2oZMnQPthOmqSqrlv/2FLh2f80T7qonFZdhr862Q7tvbk92r/fLXp2C7bD3nfajtT29kzan8yEXccWGenOk07aAsmVe05Ygx8cqPttuXpIZN9TI1L1CIyWkQ2i8g2EXmgjPX/EpE1zmOLiCS7rJsiIludx5RqX4W/GvN3O/73/261LaXn3Wq7RF36pm8mabDVhBc+Ax1P0yStPGPEH6DvJPj27/DOBNsquLatmmXHaR9RD0vTJTXpANO+sDO2/fACzLoQUvd5N6bfPobXz7Wfa9curF73ThE74FLcYJuw96/1fJz1QKUlahEJBLYA5wCJwEpgsjFmQznb3w4MMMZME5GmQAIQDxhgFTDIGHOsvPM1uBI1nBi/O24IJP4M5z0Jp97i7aiUqlvG2C5SC+6zVeKXvG4bTtWG3Cx4ri8072G7h/mTdR/aBmbB4fa+e3WHLK6ugnzbhWz5v+xkNZe9DdEta3bMtIO2lTsGblhS8+P5oJqWqIcA24wxO4wxOcAcYFwF208GCvsMnAd8ZYw56iTnrwAPzfXoR3pdDD0vskm650Vwio+MjKRUXRKxvSFu+AZCG8FbY22VeEG+58+15l07XruvNNT0pD4TYfoSex/47fGw8AE7dWdeTu2fOzMZ3rvcJumBU2DKp55JqtEtYfJ/7a3BOVfUn1buHuJOom4L7HF5negsK0VEOgCdgG+qum+DJgIXPgujHrbDjPp560alKtSyt+0JcfJEe9/a01Xh+Xl24JC4wbYFsj9q3t1+4el/hW0wN+t8+HtHePdS+OEl24PD0+2TDm2ypd4dS+z96LHP237RntK6rx0HfG+CHdXOx9pX1SZPj6AxCfjQGFOlr8AiMh2YDtC+fXsPh1RPRDaDM+7zdhRK+YbQKJgw01Z9L7jPduG65DXPzM/824eQvBvG/MO/vxSHRMLFL9npcH//zibQ7Utg65d2fVQrO6ZDl1H2Z03Gatj0OXx8IwSHwZTP3B8euap6jbVDG3/zVzuL4Ig/1M55fIw7iXov4DoLRJyzrCyTgFtL7DuyxL5LS+5kjJkJzAR7j9qNmJRS/q6wKrztIDsq3lvjYOSD9sO5uq3CCwrgu2egRW/oep5n4/VVYTF2TP2eF9rXybthx9ITSfvXOXZ5i17Q2UnaHYe7NwZ/QQEs+wcsfdIOanT5OxATV1tXYo24F5I2w9eP2WGJC6/Lj7nTmCwI25jsLGziXQlcYYxZX2K7HsAXQCfjHNRpTLYKGOhsthrbmOxoeedrkI3JlFIVy06Hz++x3XQ6j7SzyEW1qPpxNn5q55y+5PWyR8VqaAoK4MCvJ0rbu3+04/IHBNuGYF1G2uTdZkDpL0fZafDJTbDpM9ti/6JnK5+7wFNyM+2MW4c22RHOWvWpm/PWohrPRy0i5wPPAoHAG8aYJ0TkMSDBGDPf2WYGEGaMeaDEvtOAPzkvnzDGvFnRuTRRK6XKVKpVeBWrwo2BV0fZ0dBuS/D+RCC+KDfTTpSxfYlN3gfW2eVhMfZ33XmUrSo3xjbqOrwVznvCDmRS17cR0g44LcHFNp6rzhc3H1LjRF2XNFErpSp0cL3tznhkG5zxgG257U7S3fa1bZh20fMwSId0cEt6Evz+rVPiXgqpiXa5BNo5AC6dZWs4vGXfGjt2eKs+toV5cJj3YqkhTdRKKf/iWhXe6Qxbuq6sRPXmBXDsd7hjTemx9VXljLFfjrYvsT9PvQWadPR2VLDhf3aWwX6T4eKX620DwYoStRfmTVRKqRoKjbJddTqe5l6r8N0/2ik1Rz+lSbq6RKBZV/vwJb3GwaiHbFe+5j3gtLu8HZHH6fiPSqn6yXWAlLAY2yp86d/LHiDlu2cgItZur/zP6ffZKVMXz4BNC7wdjcdpolZK1W8te9thJftcCkv/Zkfjch0gZf+vsHWRHfHPnS5Hqv4RsYNFtekPH99g2zH4EU3USqn6r7AqfOwLsOcnWxX++zK7bvkzdkjSwTd4N0ZVu4LDYdJ/ITQa3ptkG8L5CU3USin/IAIDry5eFb7gPlg/DwZfb2epU/6tUWuY9B4cT7L95fOyvR2RR2iiVkr5F9eq8J9nQlAYnKKz0TUYbQfaoVP3/Aif3e0XY4Jrq2+llP8prArvdp7t8xvV3NsRqbp08gQ7zOi3T0FMO9sSvK5GTasFmqiVUv5JxLYEVg3TGX+Ew1tssv7hBeg+BnpPgJPO8uysXnVAE7VSSin/ExBg+9YPmgK/fQwb58O6D2zDwh4X2KTdeWS96FevI5MppZTyf/m5sONbWP8xbPwMslMgrDH0vMhWlXc8HQK9V3bVIUSVUkqpQnnZdijU9R/bAVJy0iCimZ3vuvcE6DCszidt0SFElVJKqUJBodB9tH3kZsK2xbZ6fO0cSHgDolraoUl7T7DTfQZ4t4OUlqiVUkopgJzjsGWRLWlv/QrysqBRW+h1sa0ebzuo1ib90KpvpZRSqiqy02DzQlvS3v415OdATHvofbFN2q37ezRpa6JWSimlqiszGTZ9bkvaO5ZCQR5MeBX6XuaxU+g9aqWUUqq6whvDgCvtI+MobPwUTjq7zk6viVoppZRyV0RT2ze7DulY30oppZQP00StlFJK+TBN1EoppZQP00StlFJK+TBN1EoppZQP00StlFJK+TCfG/BERJKAXR4+bDPgsIeP6W3+eE3gn9el11R/+ON1+eM1gf9dVwdjTPOyVvhcoq4NIpJQ3ogv9ZU/XhP453XpNdUf/nhd/nhN4L/XVRat+lZKKaV8mCZqpZRSyoc1lEQ909sB1AJ/vCbwz+vSa6o//PG6/PGawH+vq5QGcY9aKaWUqq8aSolaKaWUqpc0USullFI+zG8StYiMFpHNIrJNRB4oY32oiMx11v8kIh29EGaViEg7EVkiIhtEZL2I3FnGNiNFJEVE1jiPR7wRa1WIyE4RWefEm1DGehGR55336lcRGeiNOKtCRLq7vAdrRCRVRO4qsY3Pv1ci8oaIHBKR31yWNRWRr0Rkq/OzSTn7TnG22SoidTsPYCXKua5/isgm52/sExFpXM6+Ff69eks51zRDRPa6/I2dX86+FX5eeks51zTX5Xp2isiacvb1yffJI4wx9f4BBALbgc5ACLAW6FVim1uA/zjPJwFzvR23G9fVGhjoPI8GtpRxXSOBz7wdaxWvayfQrIL15wMLAQFOAX7ydsxVvL5A4AB2AIN69V4BpwMDgd9clv0DeMB5/gDw9zL2awrscH42cZ438fb1VHJd5wJBzvO/l3VdzroK/1597JpmAPdWsl+ln5e+dE0l1v8f8Eh9ep888fCXEvUQYJsxZocxJgeYA4wrsc04YLbz/EPgLBGROoyxyowx+40xq53nacBGoK13o6oT44C3jPUj0FhEWns7qCo4C9hujPH0CHu1zhizDDhaYrHr/85s4OIydj0P+MoYc9QYcwz4ChhdW3FWVVnXZYz50hiT57z8EYir88BqoJz3yh3ufF56RUXX5HxeXwb8t06D8gH+kqjbAntcXidSOqEVbeP8c6YAsXUSnQc4VfUDgJ/KWH2qiKwVkYUi0rtuI6sWA3wpIqtEZHoZ6915P33ZJMr/MKlv7xVAS2PMfuf5AaBlGdvU9/dsGrYWpyyV/b36mtuc6vw3yrlNUV/fqxHAQWPM1nLW17f3yW3+kqj9mohEAR8BdxljUkusXo2tYu0H/BuYV8fhVcdpxpiBwBjgVhE53dsBeYqIhABjgQ/KWF0f36tijK1j9Ks+nSLyEJAHvFvOJvXp7/VloAvQH9iPrSr2F5OpuDRdn96nKvGXRL0XaOfyOs5ZVuY2IhIExABH6iS6GhCRYGySftcY83HJ9caYVGNMuvN8ARAsIs3qOMwqMcbsdX4eAj7BVsW5cuf99FVjgNXGmIMlV9TH98pxsPDWg/PzUBnb1Mv3TESmAhcCVzpfQkpx4+/VZxhjDhpj8o0xBcCrlB1rvXuvnM/sCcDc8rapT+9TVflLol4JdBWRTk6JZhIwv8Q284HClqgTgW/K+8f0Fc49mdeBjcaYZ8rZplXhvXYRGYJ9T332C4iIRIpIdOFzbIOe30psNh+4xmn9fQqQ4lL16uvK/dZf394rF67/O1OA/5WxzSLgXBFp4lS3nuss81kiMhq4HxhrjMkoZxt3/l59Rom2HOMpO1Z3Pi99zdnAJmNMYlkr69v7VGXebs3mqQe2pfAWbGvGh5xlj2H/CQHCsNWR24Cfgc7ejtmNazoNW834K7DGeZwP3ATc5GxzG7Ae23LzR2CYt+Ou5Jo6O7GudeIufK9cr0mAF533ch0Q7+243by2SGzijXFZVq/eK+yXjP1ALvbe5XXYthxfA1uBxUBTZ9t44DWXfac5/1/bgGu9fS1uXNc27L3awv+twl4hbYAFFf29+sKjnGt62/mf+RWbfFuXvCbndanPS194lHVNzvJZhf9HLtvWi/fJEw8dQlQppZTyYf5S9a2UUkr5JU3USimllA/TRK2UUkr5ME3USimllA/TRK2UUkr5ME3USimllA/TRK2UC2cMbremaKzKtt7kTP93di0cd6mIXO88v1JEvnRn22qcp72IpItIYHVjreDYRkRO8vRxlfIkTdSq3nM+xAsfBSKS6fL6yqocyxgzxhgzu/Itq7atLxKRB0RkWRnLm4lIjoic7O6xjDHvGmPO9VBcxb5YGGN2G2OijDH5nji+UvWNJmpV7zkf4lHGmChgN3CRy7KiiRac8YLVCe8Aw0SkU4nlk4B1xhj/GYJRqXpME7XyWyIyUkQSReSPInIAeNMZi/ozEUkSkWPO8ziXfVyrc6eKyHIRedrZ9ncRGVPNbTuJyDIRSRORxSLyooi8U07c7sT4uIh87xzvS9fJPUTkahHZJSJHxM4MVSZjx03+Bri6xKprgLcqi6NEzFNFZLnL63NEZJOIpIjIC9hhYQvXdRGRb5z4DovIuyLS2Fn3NtAe+NSpEblfRDo6VdRBzjZtRGS+iBwVkW0icoPLsWeIyPsi8pbzu1kvIvHl/Q5KXEOMs1+S8/t7WEQCnHUnici3zvUcFpG5znIRkX+JyCERSRWRdVWpiVDKHZqolb9rBTQFOgDTsX/zbzqv2wOZwAsV7D8U2Aw0A/4BvC4iUo1t38OOMR8LzKB0cnTlToxXANcCLYAQ4F4AEemFnerwauxYyLHY2ZHKM9s1FhHpjp0i8T034yjF+dLwMfAw9nexHRjuugnwpBNfT+xMTjMAjDFXU7xW5B9lnGIOdhzoNtgJdv4mIme6rB/rbNMYO951pTE7/o2dVa8zcAb2C8u1zrrHgS+BJtjf57+d5ecCpwPdnH0vo35MtKLqEU3Uyt8VAI8aY7KNMZnGmCPGmI+MMRnGmDTgCeyHcnl2GWNede6PzgZaAy2rsq2ItAcGA48YY3KMMcupYLYiN2N80xizxRiTCbyPTa5gE9dnxphlxphs4M/O76A8nzgxDnNeXwMsNMYkVeN3Veh8YL0x5kNjTC7wLHDA5fq2GWO+ct6TJOAZN4+LiLTDJv0/GmOyjDFrgNecuAstN8YscN6Ht4F+bhw3EFvl/6AxJs0YsxM7l3Phl5hc7BeWNs55l7ssjwZ6AGKM2Wjqz0xvqp7QRK38XZIxJqvwhYhEiMgrTtVmKrAMaCzltyh2TTCFUyFGVXHbNsBRU3wqxT3lBexmjAdcnme4xNTG9djGmONUUMJzYvoAZ1pR4ErgrSrEUZaSMRjX1yLSUkTmiMhe57jvYEve7ij8Xaa5LNsFtHV5XfJ3EyaVt09oBgQ7xyrruPdjawJ+dqrTpznX9g22xP4icEhEZopIIzevRSm3aKJW/q7k9HB/ALoDQ40xjbDVluByD7UW7AeaikiEy7J2FWxfkxj3ux7bOWdsJfvMxlbZnoMtHX5awzhKxiAUv96/Yd+XPs5xrypxzIqm9NuH/V1GuyxrD+ytJKbKHOZEqbnUcY0xB4wxNxhj2gA3Ai+J063LGPO8MWYQ0AtbBX5fDWNRqhhN1Kqhicbea00WkabAo7V9QmPMLiABmCEiISJyKnBRLcX4IXChiJwmIiHYOdkr+z//DkgGZgJzjDE5NYzjc6C3iExwSrJ3YNsKFIoG0oEUEWlL6cR2EHufuBRjzB5gBfCkiISJSF/sPMxlNsxzl1NN/j7whIhEi0gH4J7C44rIpS4N6Y5hv0wUiMhgERkqIsHAcSCLim81KFVlmqhVQ/MsEI4tQf0IfFFH570SOBVbDf1XYC6QXc62z1LNGI0x64FbsY3B9mOTSmIl+xhsdXcH52eN4jDGHAYuBZ7CXm9X4HuXTf4CDARSsEn94xKHeBJ4WESSReTeMk4xGeiILV1/gm2DsNid2CpxOzbZ7gCWY3+HbzjrBgM/iUg6tn3BncaYHUAj4FXs73kX9nr/6YFYlCoi9n9UKVWXnO49m4wxtV6iV0rVb1qiVqoOOFWkXUQkQERGA+OAeV4OSylVD+hITUrVjVbYKt5YbFX0zcaYX7wbklKqPtCqb6WUUsqHadW3Ukop5cM0USullFI+zOfuUTdr1sx07NjR22EopZRSdWbVqlWHjTHNy1rnc4m6Y8eOJCQkeDsMpZRSqs6IyK7y1mnVt1JKKeXDNFErpZRSPkwTtVJKKeXDNFErpZRSPkwTtVJKKeXDNFErpZRS7spKgd8+hoyjdXZKn+uepZRSSvmUY7tgyxeweSHsXA4FuTDhVeh7WZ2cXhO1Ukop5aqgAPb/YhPz5oVw8De7vFk3OPUW6H4+xA2us3A0USullFK5mfD7Mti8ADZ/AekHQAKg/TA496/QbQw0O8kroWmiVkop1TClJ8HWRbbUvP0byM2AkGg46Sxbau56DkQ09XaUmqiVUko1EMZA0man1LwQElcCBhrFQf8rofsY6HgaBIV6O9JiapSoRWQ08BwQCLxmjHmqxPoOwBtAc+AocJUxJrEm51RKKaXclp8Hu39w7jcvgGO/2+VtBsCoP0G30dCqD4h4N84KVDtRi0gg8CJwDpAIrBSR+caYDS6bPQ28ZYyZLSJnAk8CV9ckYKWUUsota+fAwj9CVjIEhkLnM2D4HTY5N2rj7ejcVpMS9RBgmzFmB4CIzAHGAa6Juhdwj/N8CTCvBudTSiml3HNgHcy/A9r0h2G3Q+dREBrl7aiqpSYDnrQF9ri8TnSWuVoLTHCejweiRSS2BudUSimlKpZzHD64FsKbwKT3oOdF9TZJQ+2PTHYvcIaI/AKcAewF8ktuJCLTRSRBRBKSkpJqOSSllFJ+beH9cGQbXPIqRDbzdjQ1VpNEvRdo5/I6zllWxBizzxgzwRgzAHjIWZZc8kDGmJnGmHhjTHzz5s1rEJJSSqkGbd2H8Ms7MOIP0Ol0b0fjETVJ1CuBriLSSURCgEnAfNcNRKSZiBSe40FsC3CllKobu1bAjqXejkLVlaM74NO7oN0pMPJBb0fjMdVO1MaYPOA2YBGwEXjfGLNeRB4TkbHOZiOBzSKyBWgJPFHDeJVSyj0bP4XZF8GcqyDzmLejUbUtLwc+vA4CAmyVd6D/DBNSoysxxiwAFpRY9ojL8w+BD2tyDqWUqrKNn8IHU6FZdzi0Hn6aCSP/6O2oVG365jHYtxouexsat/d2NB6l01wqpfxLYZJuMwCmfWHHaP7pZchO93ZkqrZsXQwr/g3x10GvsZVvX89oolZK+Q/XJH3VxxDWCE6/11Z9J2gTGb+UdgA+uRFa9Ibz/PPuqiZqpZR/KCtJA8TFQ6cz4IcXIDfLqyEqDysosEk65zhMfAOCw70dUa3QRK2Uqv/KS9KFTr8X0g/CL297JTxVS75/1rbqH/N3aNHD29HUGk3USqn6beNnLkn6o9JJGqDjCIgbAt8/D/m5dR6iqgV7foZv/gq9J8DAa7wdTa3SRO0rVr8FLwyBQxu9HUnlCgogJ8PbUSjlJOkpLkk6puztRGypOmU3/Pp+3caoPC8z2XbFiomDi5716ZmvPEETtbfl58Ln98L82+HwZvj0TpsIfdn/boF/9YaD670diWrI3E3Shbqea6czXP4MFJQayVjVF8bAp3dA2j57X7qy990PaKL2puOH4e3xsPJVO7vL2H/Dnp/gl7e8HVn5tnwJa/8L2Wk29qM7vB2RaogKk3Tr/u4labClrhF/sGNAb/hfrYfot3KzIN2LczKsmmXfvzP/bBsKNgD+M3RLfXNgHfz3CtvAZfxM6He5/aa4di589Qh0Px+iWng7yuKy0+Hze+wgEpe8Bm+NhbcuhmmLoFFrb0enGgrXJH31x1UrUfUcC7Fd4btnoPd4v68yrRZjIP0QHNtZ9iNtn92u7+Vw3t/qdtKLQxvhiwegy5kw7I66O6+XaaL2hvWfwLxbIKyxHZCh7UC7XAQu/Be8PAwWPWSHwfMl3/wVUvbYxNy6ry3JzB4Lb18M1y6EiKbejlD5u02fVz9JAwQEwml329s3WxZB99G1EqbPy8mA5N3lJ+O8TJeNBRq1gSYdocso+zM7DX58GbZ+aZN1v8m1/6UnJ8NOXRnaCMa/YocKbSDEGOPtGIqJj483CQkJ3g6jdhQUwJIn4Lunod1QO9RddMvS2y35G3z7d7h6nv3H8AWJCfDa2RA/DS585sTy35fBOxOh1clwzf8gNNp7MSr/tulzeP+a6ifpQvm58PxA+7933Vf+XapOOwjbvy6diNMPFt8uJMom4LIeMe0gOKz0sQ9tgs/ugt0/2FmqLnwWYrvU3rV8ehesetN2vzvprNo7j5eIyCpjTJl1+Zqo60pWKnw8HbYshAFXwwX/B0GhZW+bm2VL1Ri4+Yey/0nqUn4uvHKGHd3p1h9Lf0BuWgBzr4KOw+GKD7wfr/I/nkrShX5+FRbcC1M+9ZupEEvZ8qUdDCTzKCC2hXSTjtCkg/Oz04lkHBFbvS8sBQWwejZ89SjkZcEZ99sq6aAQj14K6z+xXfCG3wnnPObZY/sITdTedngbzLkCjm6H0U/B4Osr/6fYsRTeGgen3w9nPlQnYZZr2dPwzeMw6T3ocUHZ26ydC59Mhx4XwqWz/WrmGuVlRUm6H1z9iWda+eZmwXN9oXkPmDK/8u3rk/xc+PoxWPG8beU+9t92eE1PJ09XaQdg4R9hwzxo0Qsueg7aDfHMsY/tgv+MgGZd7a3CwGDPHNfHVJSoa1TJLyKjRWSziGwTkQfKWN9eRJaIyC8i8quInF+T89VLWxfDq2dCxmFblT3kBve+uXYeaRtrLP8XJG2u7SjLd3gbfPsP2winvCQNtjHcmH/Cps9g/m2+38VM1Q+1kaTB1vqcehv8/q29reMvkvfAm+fbJD34erhuse2+VptJGiC6FVw2GybPtbWHr58Ln/8BslJqdtz8XPjoesDAxNf9NklXptqJWkQCgReBMUAvYLKI9Cqx2cPYeaoHAJOAl6p7vnrHGPj+OXjvUjvl2g1LoNOIqh3j3CcgJBI+u9ser64VFNh+3UFhcP4/K99+6HQY9ZDtvrXoQe/ErPzHps/h/SmeT9KF4qdBeBNbY+QPNi2A/5xmW0ZfOsveXqvr21DdR8OtP8EpN9tJUF4caod3ra4lf4PEn+2gJk06eirKeqcmJeohwDZjzA5jTA4wBxhXYhsDFI7nFwPsq8H56o/cTPj4BtvNqudYuG6RvS9UVVHN7f2YXd/Dmnc9H2dlfnkbdi2Hcx+z35jdcfp9cMot8NN/YOlTtRuf8l9FSbpv7SRpgNAoGHqzbTdy4DfPH7+u5OXAF3+COZPt58xNy2zXM28JjYLRT8L1iyGimW2/MudKSNlbtePsWGprFAdeAydfUiuh1hc1SdRtgT0urxOdZa5mAFeJSCKwALi9BuerH1IS4Y3zYN2HtkP+pbNsqbi6BlwN7U+FL/8Mx494LMxKpR2Er/4MHYbDgCqMoytiawL6XwnfPmW7cChVFa5J+ioPNByryNDpEBIN3/1f7Z2jNh3bCW+Ohh9fhCE32lbsTTt7Oyqr7SCYvsQWNrZ9bUvXP7/q3qhw6Um28W2zbjD677Ufq4+r7Y5ok4FZxpg44HzgbREpdU4RmS4iCSKSkJTkxRFvamrXDzBzJBzZAZPn2LGFa9r1IyDA9q3OToUvH/ZImG5ZeL9tcHPRc1XvrxgQABc9Dz0vsoMTrHmvdmJU/qdkkg5vXLvnC28Cg6+zrYoPb6vdc3naxk/hP6fbuC97G87/R/k9SbwlMNi21L71R2g32La0f/3ciocfLiiAeTfZ8bwvfRNCIuosXF9Vk0S9F2jn8jrOWebqOuB9AGPMD0AYUGoYG2PMTGNMvDEmvnnz5jUIyYtWzYLZF9nO+Dd87dmBFFr0tH/sa9+D37/z3HHLs2mBbb15xn22pWV1BAbBJa/bRnH/u82OJqVUReo6SRc69Vab4Jb/q27OV1N52bDgflulHNvFVnX3GuvtqCrWpKN9Tye8amsBXjkdFv/F3iYs6ccXYdtiGP03aNm7riP1STVJ1CuBriLSSURCsI3FSvZz2A2cBSAiPbGJuh4XmcuQlwOf3WMbXXU63Sbp5t09f57T77N/7J/dZf9Ra0tWqm2t2aIXDLuzZscKCoXL37WtTj+81t5zUqosB9bZfrJ1naTBDtU7cAr8OseO1uXLju6wJdKfX7FtQaYtqj+NrESg72Vw20roO8lOjvLSqcU/F/augsUzbG1c/HXeitTnVDtRG2PygNuARcBGbOvu9SLymIgUfr37A3CDiKwF/gtMNb7Wcbsm0pPs8JkJr9tO/ld+YKvSakNwuG3FeWQbLH+2ds4Btv9l2n7b99ITXTpCo+zvJfYkO7a5P3WFUZ6Rlw2f3GSH1L3ig7pN0oWG3wGIna/aV63/xA48dOx3O6bB6Cdrv9tVbYhoChe/CNfMt8n7rXHwyc22pP3hNIhubT9//HnEuCrSAU+qa/9a25LxeBKMfQH6Xlo35/1wmr03dfMP0Owkzx5790+2IdzQG2GMhxtwpB2wx85MtuOCtyzZk081WItn2GrnyXO9O/b2/26zc1Xfta7soX29JTcLvnwIVr4GbePtfdvG7b0dlWfkZtrucd8/C6YAELh2AbQ/xduR1blaG/CkwVr3Ibx+nv3DmvZF3SVpgPOehKBw+NzDfavzsu0cr43awpm10GgtupUdCzwozJke83fPn0PVP7t/suMNDLjK+xNknHY3FOTCDy94Nw5XR7bD62fbJH3qbfZLrr8kabA1hWf9GW78DrqcZUdubIBJujKaqKsiL8cOk/fRdXYQhulL7f3XuhTdEs5+1E6G8etczx13+bOQtMlOuFFbE2s06QjXzIP8bHvLIO1A7ZxH1Q85x23r3kZx9guot8V2sf2PE96AjKPejsYWCF453Xb5nDwXznuiflZ1u6NlL7jqQ9tdTpWiidpdqftg9oV2II+hN8PUz7w3X/SgayFuMCz6k2c+UJI22xm9Tr4Eup1X8+NVpEVPuPIjOH7Ylqx94QNRecdXj9rGURe/CGGNKt++Loz4A+Skw0+veC+G3EzbOPWj62yr55uWe7+2QXmVJmp3/P6d/WZ74Dfb5WjMU94dczYgwE4pl5lsRz+riYICmH8HBEfYaqe6EDfINoY5sg3evRSy0+vmvMp3bF8CK1+1X3p9afaqlr2h+/n2C3l2Wt2f//BWO53sqlkw/C6Y+rmd9Uo1aJqoK1I4Xvdb42yL1Bu+gT4TvR2V1epk2//zl7dh14rqH2fVm7DnR1utVpc1BJ3PgIlvwr5f7MxiuVl1d27lXZnJ8L9bIbarvY3ja0bcC1nJtgq8Lq2da1t1p+6DKz+Ec/7SYCehUMVpoi5PViq8f7UzXveFNkm36OHtqIob+QDEtLcTquflVH3/1H22xW2n0+2Qn3Wt54Uw7kU7g9FH10F+Xt3HoOreFw/Y9gnjX7GNiXxN3CA7UM+KF8oekMPTCueq/2S67Ud+03Loek7tn1fVG5qoy3JoI7w6yo7Qde4Tdn5lX7mH5iokEi54Gg5vttPaVdWC+yA/x1aje6vPYv/JdizfTZ/B/NttacsX5efZPuDLn7XV9a+dY0tA+uWiajZ+ZmdXG3GPTYi+asS9cPwQ/PJO7Z5nz0o749W6D2DkgzDlM4gpOWWCaui0H3VJ6z60CSM02lbNdhzuvVjc9f41sGUR3PKD+wPyb5hvawzOnmG7pXjb0qdgqdPyt1l321guLt7+bNETAgLrNp78XFstv3O5fez5yTYyKowP7Bekxh3gtLtsjYSvjbPsa9KT4KVToFEbuP5r327BbIzt95+6D+74xfNV0AX58N0z9m++UVu45FXtltTAVdSPWhN1obwcO+nFz6/Y2aouneX+1I7elrofXhhsB72/6uPKS8eZyXYmm6jmdp5sX7gPZgzs/sFO6ZmYAIkrIcOZLSw4EtoOdJK3k8A9fT89Lwf2rXZJzD9D7nG7rnlP+4Wt42l2NrGoFrYR3paFdrCGfavtaEqn3gbx19ZstjR/ZYwdm3rrlzD92/ox4M2WL+188uNetP28PSV5j63q3r3C9rS44BnvjMamfIom6sqk7LXjDCf+DKfcWj8bcfw0ExbeZ1ulV9bg7dO7YPVse9+9rvuBu8sYO1RiYdJOXGnHgy5wqpobd3BJ3IOhVZ+qldDysu24wju/h53f2cSc59yPbNG7eGKOLDWPTPE4dyy10yTu/A7Cm8IpN8OQ6frh62rtHPjkRjvl4fAajiFfV4yxvT1yjtvxqT1Rq/Pbx3a8/oJ8OP9p6DdJh8pUgCbqiv2+DD641jYaGfcCnDyh7s7tSQX58NpZ9kvHbSvLTxI7v4dZ59vS33lP1GmINZabaYduLUzciQmQ6kzYFhhqB6FxrTKPiTvxIZibBXsTTiTmxJWQ57Q0b9nnRGJuPwwiY6sX356fbcLe8oWd43jI9XbiBG/1t/cVKYnw0jBbip76ed3fxqiJ9fPggykw8Q1b+q2u7HQ7WNKad+w8zZe85jvzRiufoIm6LIVdr77+i50w4vJ3amfWq7q0f62dD3vQVDuHdUm5WbbhSn423PKjf1TRpuy1Cbgwce/75UQCjmplk3Zmsl2fnw2I7drWcYSTmE+1kwR40oF19v7j+k/sfeuBU2DY7dC4XeX7+htj7MA2e36Gm5fXv+RUUAAvDYXAENsauzql372r4aPr7eAuI/5ge2vUtxo7VesqStRBdR2MT8hKgXm32JbGvS62JenaGjazLrXuZweQ+PFF6DcZ2g0pvv67/4MjW+19bH9I0mBbyMa0hV7j7Ov8XDj4m0uVeYKdwWvIDbYau8OptTfDWaFWfezECaMegu//ZWdXS3jdVnMOv9vzk6n4spWvwY4l9j5sfUvSYAcXOu0eO9Tpli+g+xj39y0ogBXPwTd/haiWdjTDjqfVXqzKb9WoRC0io4HngEDgNWPMUyXW/wsY5byMAFoYYxpXdMxaL1EfXA9zr7ZTqp37uK2a9Kd7RNnptqFYWAzc+O2Jb+4HN9j7bSdPgAkzvRtjQ5O8B1b827YLyM+xXw5H3GMTem0zxnt/30e22xqc9qfCVR/V3/+z/Fz490CIbAHXL3bvOlL32Xvyvy+zXyIvfNbzNTfKr9RK1beIBAJbgHOARGAlMNkYs6Gc7W8HBhhjplV03FpN1L++b8fQDY22rbo7DKud83jbps/taF9n/8V2HSrIt11Nju6AW1dW/x6sqpn0Q/DjS/Dza5CTBt1G26rQkjUf7ioosC3jUxNtYkjZa+/Zp+61rwt/tuxt5/etiy8GRbHlwxujbRe2W360XbLqs5Wvw+f32BngOo+seNuNn9ounnnZdrrYAVfX3y8pqs7UVtX3EGCbMWaHc5I5wDigzEQNTAa8M15gXo6dwGLlq7ax0KVv1p+uV9XR4wLocaHtm9x7vO1jnbgSxs/UJO1NUS1sv/Xhd9pk/eNL8Po59n75iD/YBFD4gV5QABmHTyTbkkk4JRHS9tsSuquAYJsUG7W1DeoiW9jBNGaOtIN4jPhD3fRf/v4524tiwqv1P0mD7Sf/7T9sd7zyEnXOcfs5s2qWvQ11yevQrGtdRqn8VE1K1BOB0caY653XVwNDjTG3lbFtB+BHIM4Yk1/RcT1eok7Za1ttJq60LZ3PntEwGnKkJNoq8FZ94cCv0G5o/a5+9EfZ6bY6fMW/bdJt1dfW9riThGPaOs/jnJ9tbCv3iGb2vqqrjKN22M5f50LLk22bjNrslnfgN/vFoPsYuOwt//mbW/FvO9bCdV+VrgXZv9Y2GDu8xX4RG/Wwbw/oonxObVV9VyVR/xGbpG8v51jTgekA7du3H7Rr165qxVRK6n57jywvyw5a0Ptizxy3vvjhJVj0oJ0Z65Yf7HzQyvfkZcOa92D1WxAUVrUkXBWbv7B9eNMP2WQy8gHPj6aWlwOvngnpB2yVd0V90Oub7HR49mT7pfcKZy74ggJbM7J4BkTEwvj/QJdRFR5GqbLUVtX3XsC1v0mcs6wsk4BbyzuQMWYmMBNsiboGMRUX3QoGX2/7Pzbv5rHD1htDpttv+l3O1CTty4JC7Yhm8dfW7nm6j4b2P8Kih2D5M7B5AYx7ybNjbn/7FBxcB5P+619JGmzvgVNugSVP2C54kc1h3s2w/RvofoFtB6C3llQtqEmJOgjbmOwsbIJeCVxhjFlfYrsewBdAJ+PGybw+1rdSDcHWxfDpHbaK/dTbYNSfaj6T1Z6V8Ma5tmvgxS95Jk5fk3kM/tXHjrlw7HfIybADB8VP858qfuUVFZWoq12PZozJA24DFgEbgfeNMetF5DERGeuy6SRgjjtJWilVR7qebaumB15jZ177z2mw+6fqHy8nw/Y1btQWRj/puTh9TXgTO+Lc3gSIbgPTl8Lg6zRJq1rVcEcmU0pZ25fA/DsgZY8dp/zMP0NIRNWOseB+O6HNNfOh8xm1E6evyMmwtw16XAjBYd6ORvmJWilRK6X8RJdRcMsK257jx5fg5WF2BjF37Vhqk/TQm/w/SYP9EtNnoiZpVWc0USulbLewC562k2YAzLoAPr/XtnSuSFYKzLvVjpd/lneGSVDK32miVkqd0PE0uPl727p55Wvw8qm2xFyeLx6EtH0w/pWqV5crpdyiiVopVVxIpG0QNu0LO2vUW+PsHOZZqcW327QA1rxrJ62IK/PWmlLKAzRRK6XK1v4UO7XjsNvtCGovnQrbFtt1xw/b7l2t+sAZf/RunEr5uYY5zaVSyj3B4XDuX+2MX/+7Fd65BAZcBRnH7P3pa/6nQ2UqVcs0USulKhcXDzcug2//DsufBZNvx81v2dvbkSnl9zRRK6XcExQKZz0CPS+C37+DU8sdFVgp5UGaqJVSVdNmQO3OvqWUKkYbkymllFI+TBO1Ukop5cM0USullFI+TBO1Ukop5cNq1JhMREYDzwGBwGvGmKfK2OYyYAZggLXGmCtqck6llFLF5ebmkpiYSFZWlrdDUZUICwsjLi6O4OBgt/epdqIWkUDgReAcIBFYKSLzjTEbXLbpCjwIDDfGHBORFtU9n1JKqbIlJiYSHR1Nx44dEZ0b22cZYzhy5AiJiYl06tTJ7f1qUvU9BNhmjNlhjMkB5gDjSmxzA/CiMeaYE+ShGpxPKaVUGbKysoiNjdUk7eNEhNjY2CrXfNQkUbcF9ri8TnSWueoGdBOR70XkR6eqXCmllIdpkq4fqvM+1faAJ0FAV2AkEAcsE5E+xphk141EZDowHaB9+/a1HJJSSilVf9SkRL0XaOfyOs5Z5ioRmG+MyTXG/A5swSbuYowxM40x8caY+ObNm9cgJKWUUnXtyJEj9O/fn/79+9OqVSvatm1b9DonJ6fCfRMSErjjjjsqPcewYcM8EuvSpUu58MILPXKsulKTEvVKoKuIdMIm6ElAyRbd84DJwJsi0gxbFb6jBudUSinlY2JjY1mzZg0AM2bMICoqinvvvbdofV5eHkFBZaeb+Ph44uMrn898xYoVHom1Pqp2idoYkwfcBiwCNgLvG2PWi8hjIjLW2WwRcERENgBLgPuMMUdqGrRSSinfNnXqVG666SaGDh3K/fffz88//8ypp57KgAEDGDZsGJs3bwaKl3BnzJjBtGnTGDlyJJ07d+b5558vOl5UVFTR9iNHjmTixIn06NGDK6+8EmMMAAsWLKBHjx4MGjSIO+64o9KS89GjR7n44ovp27cvp5xyCr/++isA3377bVGNwIABA0hLS2P//v2cfvrp9O/fn5NPPpnvvvvO47+z8tToHrUxZgGwoMSyR1yeG+Ae56GUUqqW/eXT9WzYl+rRY/Zq04hHL6r6lKaJiYmsWLGCwMBAUlNT+e677wgKCmLx4sX86U9/4qOPPiq1z6ZNm1iyZAlpaWl0796dm2++uVSf419++YX169fTpk0bhg8fzvfff098fDw33ngjy5Yto1OnTkyePLnS+B599FEGDBjAvHnz+Oabb7jmmmtYs2YNTz/9NC+++CLDhw8nPT2dsLAwZs6cyXnnncdDDz1Efn4+GRkZVf59VJfOnqWUUqpWXHrppQQGBgKQkpLClClT2Lp1KyJCbm5umftccMEFhIaGEhoaSosWLTh48CBxcXHFthkyZEjRsv79+7Nz506ioqLo3LlzUf/kyZMnM3PmzArjW758edGXhTPPPJMjR46QmprK8OHDueeee7jyyiuZMGECcXFxDB48mGnTppGbm8vFF19M//79a/KrqRJN1Eop5UeqU/KtLZGRkUXP//znPzNq1Cg++eQTdu7cyciRI8vcJzQ0tOh5YGAgeXl51dqmJh544AEuuOACFixYwPDhw1m0aBGnn346y5Yt4/PPP2fq1Kncc889XHPNNR49b3l0rG+llFK1LiUlhbZt7VAbs2bN8vjxu3fvzo4dO9i5cycAc+fOrXSfESNG8O677wL23nezZs1o1KgR27dvp0+fPvzxj39k8ODBbNq0iV27dtGyZUtuuOEGrr/+elavXu3xayiPJmqllFK17v777+fBBx9kwIABHi8BA4SHh/PSSy8xevRoBg0aRHR0NDExMRXuM2PGDFatWkXfvn154IEHmD17NgDPPvssJ598Mn379iU4OJgxY8awdOlS+vXrx4ABA5g7dy533nmnx6+hPFLYWs5XxMfHm4SEBG+HoZRS9cbGjRvp2bOnt8PwuvT0dKKiojDGcOutt9K1a1fuvvtub4dVSlnvl4isMsaU2U9NS9RKKaX8wquvvkr//v3p3bs3KSkp3Hjjjd4OySO0MZlSSim/cPfdd/tkCbqmtEStlFJK+TBN1EoppZQP00StlFJK+TBN1EoppZQP00StlFKqRkaNGsWiRYuKLXv22We5+eaby91n5MiRFHbFPf/880lOTi61zYwZM3j66acrPPe8efPYsGFD0etHHnmExYsXVyH6svnSdJiaqJVSStXI5MmTmTNnTrFlc+bMcWtiDLCzXjVu3Lha5y6ZqB977DHOPvvsah3LV9UoUYvIaBHZLCLbROSBMtZPFZEkEVnjPK6vyfmUUkr5nokTJ/L555+Tk5MDwM6dO9m3bx8jRozg5ptvJj4+nt69e/Poo4+WuX/Hjh05fPgwAE888QTdunXjtNNOK5oKE2wf6cGDB9OvXz8uueQSMjIyWLFiBfPnz+e+++6jf//+bN++nalTp/Lhhx8C8PXXXzNgwAD69OnDtGnTyM7OLjrfo48+ysCBA+nTpw+bNm2q8Pq8PR1mtftRi0gg8CJwDpAIrBSR+caYDSU2nWuMua0GMSqllHLXwgfgwDrPHrNVHxjzVLmrmzZtypAhQ1i4cCHjxo1jzpw5XHbZZYgITzzxBE2bNiU/P5+zzjqLX3/9lb59+5Z5nFWrVjFnzhzWrFlDXl4eAwcOZNCgQQBMmDCBG264AYCHH36Y119/ndtvv52xY8dy4YUXMnHixGLHysrKYurUqXz99dd069aNa665hpdffpm77roLgGbNmrF69Wpeeuklnn76aV577bVyr8/b02HWpEQ9BNhmjNlhjMkB5gDjahyRUkqpese1+tu12vv9999n4MCBDBgwgPXr1xerpi7pu+++Y/z48URERNCoUSPGjh1btO63335jxIgR9OnTh3fffZf169dXGM/mzZvp1KkT3bp1A2DKlCksW7asaP2ECRMAGDRoUNFEHuVZvnw5V199NVD2dJjPP/88ycnJBAUFMXjwYN58801mzJjBunXriI6OrvDY7qjJyGRtgT0urxOBoWVsd4mInA5sAe42xuwpYxullFKeUEHJtzaNGzeOu+++m9WrV5ORkcGgQYP4/fffefrpp1m5ciVNmjRh6tSpZGVlVev4U6dOZd68efTr149Zs2axdOnSGsVbOFVmTabJrKvpMGu7MdmnQEdjTF/gK2B2WRuJyHQRSRCRhKSkpFoOSSmllKdFRUUxatQopk2bVlSaTk1NJTIykpiYGA4ePMjChQsrPMbpp5/OvHnzyMzMJC0tjU8//bRoXVpaGq1btyY3N7doakqA6Oho0tLSSh2re/fu7Ny5k23btgHw9ttvc8YZZ1Tr2rw9HWZNStR7gXYur+OcZUWMMUdcXr4G/KOsAxljZgIzwc6eVYOYlFJKecnkyZMZP358URV44bSQPXr0oF27dgwfPrzC/QcOHMjll19Ov379aNGiBYMHDy5a9/jjjzN06FCaN2/O0KFDi5LzpEmTuOGGG3j++eeLGpEBhIWF8eabb3LppZeSl5fH4MGDuemmm6p1XTNmzGDatGn07duXiIiIYtNhLlmyhICAAHr37s2YMWOYM2cO//znPwkODiYqKoq33nqrWud0Ve1pLkUkCFudfRY2Qa8ErjDGrHfZprUxZr/zfDzwR2PMKRUdV6e5VEqpqtFpLuuXqk5zWe0StTEmT0RuAxYBgcAbxpj1IvIYkGCMmQ/cISJjgTzgKDC1uudTSimlGqIaTXNpjFkALCix7BGX5w8CD9bkHEoppVRDpiOTKaWUH6jubUxVt6rzPmmiVkqpei4sLIwjR45osvZxxhiOHDlCWFhYlfarUdW3Ukop74uLiyMxMRHt3ur7wsLCiIuLq9I+mqiVUqqeCw4OplOnTt4OQ9USrfpWSimlfJgmaqWUUsqHaaJWSimlfJgmaqWUUsqHaaJWSimlfJgmaqWUUsqHaaJWSimlfJgmaqWUUsqHaaJWSimlfFiNErWIjBaRzSKyTUQeqGC7S0TEiEiZc20qpZRSqmzVTtQiEgi8CIwBegGTRaRXGdtFA3cCP1X3XEoppVRDVZMS9RBgmzFmhzEmB5gDjCtju8eBvwNZNTiXUkop1SDVJFG3Bfa4vE50lhURkYFAO2PM5zU4j1JKKdVg1VpjMhEJAJ4B/uDGttNFJEFEEnSaNqWUUuqEmiTqvUA7l9dxzrJC0cDJwFIR2QmcAswvq0GZMWamMSbeGBPfvHnzGoSklFJK+ZeaJOqVQFcR6SQiIcAkYH7hSmNMijGmmTGmozGmI/AjMNYYk1CjiJVSSqkGpNqJ2hiTB9wGLAI2Au8bY9aLyGMiMtZTASqllFINWVBNdjbGLAAWlFj2SDnbjqzJuZRSSqmGSEcmU0oppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXyYJmqllFLKh2miVkoppXxYjRK1iIwWkc0isk1EHihj/U0isk5E1ojIchHpVZPzKaWUUg1NtRO1iAQCLwJjgF7A5DIS8XvGmD7GmP7AP4Bnqns+pZRSqiGqSYl6CLDNGLPDGJMDzAHGuW5gjEl1eRkJmBqcr1p+25tCXn5BXZ9WKaWU8oigGuzbFtjj8joRGFpyIxG5FbgHCAHOrMH5qiw5I4eJ/1lBbGQoV5/agcvj29EkMqQuQ1BKKaVqpNYbkxljXjTGdAH+CDxc1jYiMl1EEkQkISkpyWPnjg4L5rlJA2jfNIKnFm7ilCe/5oGPfmXj/tTKd1ZKKaV8gBhTvdpoETkVmGGMOc95/SCAMebJcrYPAI4ZY2IqOm58fLxJSEioVkwV2XQgldkrdvHJL4lk5RYwtFNTrh3ekbN7tiQoUBu/K6WU8h4RWWWMiS9zXQ0SdRCwBTgL2AusBK4wxqx32aarMWar8/wi4NHyAilUW4m6UHJGDnNX7uGtH3axNzmTto3DueqUDkwarNXiSimlvKNWErVz4POBZ4FA4A1jzBMi8hiQYIyZLyLPAWcDucAx4DbXRF6W2k7UhfILDIs3HmTW9zv5YccRQoMCuLh/W6YM60ivNo1q/fxKKaVUoVpL1LWhrhK1q7KqxacO68g5vbRaXCmlVO3TRO2m5Iwc3k/Yw+wVtlq8TUwYV5/aUavFlVJK1SpN1FVUWC0+e8VOVmzXanGllFK1SxN1DWw+kMasFTuLqsWHdGrKtVotrpRSyoM0UXtAyWrxiJBA2jeNoF3TCNo3jaBD7InncU3CCQ0K9HbISiml6glN1B6UX2D4euNBftxxlN1HM9h99Di7j2aQlXtimFIRaN0ojPaxNnG3bxpB+9hIm9CbRtA4IhgR8eJVKKWU8iUVJeqaDCHaIAUGCOf2bsW5vVsVLTPGkJSeze4jGew+msGuIxnsOWqfL9mcRFJadrFjRIcG0c4phReWyjvERtChaSRtm4QTGKBJXCmllKWJ2gNEhBbRYbSIDiO+Y9NS6zNy8kg8lskuJ5HvPmJL4VsOpvH1pkPk5J0ojYcEBdC5WSRdWkTRpXkUJ7WIokvzSLo0jyIsWKvTlVKqodFEXQciQoLo1jKabi2jS60rKDAcTMti95EMdh45zvak42w/lM5ve1NYuG4/Bc6dCRGIaxJuk3dhAm9hn2vXMaWU8l+aqL0sIEBoHRNO65hwhnaOLbYuKzefnUeOs+1QOtsOpbM9yT7/YfsRsl1K4bGRIXRp7iRupwR+Uoso2sSEE6DV6EopVa9povZhYcGB9GjViB6tivfdzi8w7EvOdEng9ufC3/aTnJFbtF14cCCdm0fSvWU0PVs3ch7RxEaF1vWlKKWUqiZN1PVQYIDQzmmENqpHi6LlxhiOHs+xCTwpne2HjrP1UBrLtx3m41/2Fm3XPDq0KGn3chJ4p2aRBGu/cKWU8jmaqP2IiBAbFUpsVGipavQj6dlsOpDGxv2pbNifysb9afyw/TC5+fYmeEhQAF1bRBUrefdq3YjGEXr/WymlvEkTdQMRGxXK8JNCGX5Ss6JlufkFbE9KZ6OTuDfuT2Xp5iQ+XJVYtE2rRmH0bO1adW5L39qFTCml6kaNErWIjAaew05z+Zox5qkS6+8BrgfygCRgmjFmV03OqTwnODCg6B74+AEnlielZTvJO7WoFP7d1sPkOU3QQ4MC6N4q2mnJHkW3ltF0bxVNq0ZhOpCLUkp5WLVHJhORQGALcA6QCKwEJhtjNrhsMwr4yRiTISI3AyONMZdXdFxfH5msocrOy2fboXQ27k9jk5PAtxxM45DLYC7RYSe6oXVvGUW3VtF0b6mN15RSqjK1NTLZEGCbMWaHc5I5wDigKFEbY5a4bP8jcFUNzqe8KDQokN5tYujdJqbY8mPHc9hyMM15pLP5YBoL1u3nvz+faH0eGxlSVOouLIV3bRlNTHiwR2M0xpCdV0BGTj7Hs/NIz84jIyePRmHBtI+N0PHXlVL1Uk0SdVtgj8vrRGBoBdtfByyswfmUD2oSGcLQzrHFGq8ZY0hKyy5K3FsOpLH5YBofJOzheE5+0XatY8KKVZ93bh5FgTGkZ+dxvOjhJN2cPDKyXRNwfvHtnORcWD1fUoBAm8bhdGoWWerRtnG4zoSmlPJZddKYTESuAuKBM8pZPx2YDtC+ffu6CEnVIhGhRaMwWjQK47SuJxqvFRQY9qVksuVgGpsPpBeVxH/YcaTYMKplCQkKIDIkkMjQIKJCg4gICSQ6LIjWMWFEhAQRFRpIhLMuMuTE84iQQJIzcvn98PGixyer95KWnVd07OBA292tc7NIOsZG0qn5iSTeMjpMB41RSnlVTRL1XqCdy+s4Z1kxInI28BBwhjEmu+R6AGPMTGAm2HvUNYhJ+bCAACGuSQRxTSI4s0fLouX5BYZdR46z88hxQgIDiQy1CTnSSbqRoUEe7eNtjOFweg47jxzn96Tj/F748/Bxvtt6uNiob+HBgXSIjaBzcyeJN4ukc/NI2jS2U5mGBAUQEhhAcKBoQzqlVK2oSWOyIGxjsrOwCXolcIUxZr3LNgOAD4HRxpit7hxXG5MpbyooMOxPzWLn4ePsOGwT+M4jNonvOZpRbtU6QEhggE3cQTZxFybxkKBAQgpfFyX2E9uGBtnXoUEBNI0MpUV0KM2jQ2nRKJQW0WE00WlRlfJ7tdKYzBiTJyK3AYuw3bPeMMasF5HHgARjzHzgn0AU8IHzQbPbGDO2uudUqrYFBAhtG4fTtnF4sT7nYPudJx7L5PfD6exPySI3r4Cc/AJy8grIyTf2Z14BOfn55OYZl3UFReuycwtIy8pz2fbEz6zc/GLzmhcKDhSaRRUm8DCbxF0SeeHrZlGhhATpvXal/E21S9S1RUvUqiHLyMnjUGo2SenZHErN5lBaFofSsklKy+ZQWjaHUrNISsvmyPGcMvdvEhFsp1xtZEvlzaNDaRIR4tzbDyQyJKjotkKUc4vB3uMPqpNBbApb5mfm5JORm09mTj5ZuflkOD9DggKIKmxr4PwMCw7QGgXl92qre5ZSysMiQoLo2CyIjs0iK9wuN7+AI+k5NpGXSOyFSX1H0nGS0rLJya+4oV6hsOAApwFe8URuk/uJhnyRoUGEBAaQlZdPVo5Nspm5ziOnkp+5+VS1bBAYIESGBJ5I3mGFjQbt6+iw4vG5JvnC9Y3Dg2kUHqzj2at6SRO1UvVQcGAArWLCaBUTVuF2xhgycwu7suW7dGfLI931dXa+s6x4t7ijx3PYfTTjRNe4nLxiiVbENrgLDw4kPKT4z6aRIYQ3PvE6wvkZFhJIhLNdWHAgESFBhAcHEhocQE5eQbFud2ku8aRn55GelVcU58HULI5n55OWlcvxnHzyK2g/UCgyJJCY8GBiIkKICQ8iJjyYxuEhxEQEE+Mk88bh9nlMeDCNneXRYcE6bK7yGk3USvkxESEixJaSia758QoTf3ZuAeEhgYQG+Ua1dGGVemEyT3f5QpKamUdKZm7RIznD/kzNtN32UjKTScnMLbN9gKvosKCixN0ozJbObaNAISggwHktRcsLnwc5P0PKee66T2xUCG0bhxMTrg0I1QmaqJVSbjuR+L0dSXEiQliwLaE3q+aQtVm5+aQWJvPMXFIyXJ47id0m+hzSsuwXgZx8Q15+Abn5BeTmG+dnAXn5tjFhbn4BbhT0SwkPDqR14zDaxITTpnEYrZ2fbRqHFz2PCKndj++CAkNqVi5Hjudw7HgOR47ncNR5pGXl0bJRKG0bh9sul03DaRTm2ZEG1QmaqJVSCooSfYtGFd9OqKr8guIJPDe/gNwCQ25e8QSfk1/A4bRs9qVksS85k/0pmexLzmLp5iSS0rNL3dtvHBFsk3aMk8CLEns4rZ3bIq735HPzCzh2PIejGTkcTT+ReAsTsX2e7STjXI5l5JR7OyEoQEp1VWwUFkTbJhHENQknrkn4iSTeJJx2TSJoFB5Ua7UExhhSs/JIzsjhWIaNPcX5eTzb3q4x4Pw0Ra8xpszlha9xLtE453Bdf/ngdnRv5YFqKjdoolZKqVoUGCAEBtgvAdWVk1fAwdTCBJ7FvpRM+zw5i73JmSTsOkZKZm6xfUSgeVQoESGBHD2eQ2pWXjlHt0m/aWQIsZEhdIyNZFCHEJpGhtA0MpTYyMLnJx6hQQEcPZ7D3uRMEo9lkngsg8Rjmew9lsnuIxms2Ha42HDBAFGhQWUm8bgmEbRtEl40XkBWbj7JTpI9kXDt68JE7PozOcPWerjTRqEsIiDYWhkpem0XSrFtpNi2p3WN1UStlFLKCgkKoF3TCNo1jSh3m+PZeUWl8P0pmexNzmJ/ciaZuflFCTbWSb5NI0OIjQqhSUQITSKCqzXWfWxUKLFRofSNa1xqnTGG5IxcJ5FnOMn8RFL/ccdR0rOLf3GICAnEGMjMzS91vEJhwQE0Dg+hcUQwTSJC6N4qmsbONTSJCCl63jgi2HkeQmRoIAFFSdglGdejNgCaqJVSyg9EhgZxUotoTmpRN6W8iogITSJDaBIZwsltY0qtN8aQmplHYnJGsQQeIOIk2hNfIhpHhNAk0ibimtRK1GeaqJVSStUpEbFd4iJKT52rStPe/0oppZQP00StlFJK+TBN1EoppZQP00StlFJK+TBN1EoppZQP00StlFJK+TBN1EoppZQPE1PVyWFrmYgkAbs8fNhmwGEPH9Pb/PGawD+vS6+p/vDH6/LHawL/u64OxpjmZa3wuURdG0QkwRgT7+04PMkfrwn887r0muoPf7wuf7wm8N/rKotWfSullFI+TBO1Ukop5cMaSqKe6e0AaoE/XhP453XpNdUf/nhd/nhN4L/XVUqDuEetlFJK1VcNpUStlFJK1Ut+k6hFZLSIbBaRbSLyQBnrQ0VkrrP+JxHp6IUwq0RE2onIEhHZICLrReTOMrYZKSIpIrLGeTzijVirQkR2isg6J96EMtaLiDzvvFe/ishAb8RZFSLS3eU9WCMiqSJyV4ltfP69EpE3ROSQiPzmsqypiHwlIludn03K2XeKs81WEZlSd1FXrpzr+qeIbHL+xj4Rkcbl7Fvh36u3lHNNM0Rkr8vf2Pnl7Fvh56W3lHNNc12uZ6eIrClnX598nzzCGFPvH0AgsB3oDIQAa4FeJba5BfiP83wSMNfbcbtxXa2Bgc7zaGBLGdc1EvjM27FW8bp2As0qWH8+sBAQ4BTgJ2/HXMXrCwQOYPtF1qv3CjgdGAj85rLsH8ADzvMHgL+XsV9TYIfzs4nzvIm3r6eS6zoXCHKe/72s63LWVfj36mPXNAO4t5L9Kv289KVrKrH+/4BH6tP75ImHv5SohwDbjDE7jDE5wBxgXIltxgGznecfAmeJiNRhjFVmjNlvjFntPE8DNgJtvRtVnRgHvGWsH4HGItLa20FVwVnAdmOMpwfuqXXGmGXA0RKLXf93ZgMXl7HrecBXxpijxphjwFfA6NqKs6rKui5jzJfGmDzn5Y9AXJ0HVgPlvFfucOfz0isquibn8/oy4L91GpQP8JdE3RbY4/I6kdIJrWgb558zBYitk+g8wKmqHwD8VMbqU0VkrYgsFJHedRtZtRjgSxFZJSLTy1jvzvvpyyZR/odJfXuvAFoaY/Y7zw8ALcvYpr6/Z9OwtThlqezv1dfc5lTnv1HObYr6+l6NAA4aY7aWs76+vU9u85dE7ddEJAr4CLjLGJNaYvVqbBVrP+DfwLw6Dq86TjPGDATGALeKyOneDshTRCQEGAt8UMbq+vheFWNsHaNfdRURkYeAPODdcjapT3+vLwNdgP7AfmxVsb+YTMWl6fr0PlWJvyTqvUA7l9dxzrIytxGRICAGOFIn0dWAiARjk/S7xpiPS643xqQaY9Kd5wuAYBFpVsdhVokxZq/z8xDwCbYqzpU776evGgOsNsYcLLmiPr5XjoOFtx6cn4fK2KZevmciMhW4ELjS+RJSiht/rz7DGHPQGJNvjCkAXqXsWOvde+V8Zk8A5pa3TX16n6rKXxL1SqCriHRySjSTgPkltpkPFLZEnQh8U94/pq9w7sm8Dmw0xjxTzjatCu+1i8gQ7Hvqs19ARCRSRKILn2Mb9PxWYrP5wDVO6+9TgBSXqldfV+63/vr2Xrlw/d+ZAvyvjG0WAeeKSBOnuvVcZ5nPEpHRwP3AWGNMRjnbuPP36jNKtOUYT9mxuvN56WvOBjYZYxLLWlnf3qcq83ZrNk89sC2Ft2BbMz7kLHsM+08IEIatjtwG/Ax09nbMblzTadhqxl+BNc7jfOAm4CZnm9uA9diWmz8Cw7wddyXX1NmJda0Td+F75XpNArzovJfrgHhvx+3mtUViE2+My7J69V5hv2TsB3Kx9y6vw7bl+BrYCiwGmjrbxgOvuew7zfn/2gZc6+1rceO6tmHv1Rb+bxX2CmkDLKjo79UXHuVc09vO/8yv2OTbuuQ1Oa9LfV76wqOsa3KWzyr8P3LZtl68T5546MhkSimllA/zl6pvpZRSyi9polZKKaV8mCZqpZRSyodpolZKKaV8mCZqpZRSyodpolZKKaV8mCZqpZRSyodpolbK4UyU4dY8ylXZ1pucOXrProXjLhWR653nV4rIl+5sW43ztBeRdBEJrG6sStV3mqhVveZ8iBc+CkQk0+X1lVU5ljFmjDFmduVbVm1bXyQiD4jIsjKWNxORHBE52d1jGWPeNcac66G4in2xMMbsNsZEGWPyPXH8Ms4nIrJDRDZUFouzbKqILHd5HSIiM0Rkq4gcd/Z5w5ntTimP0ESt6jXnQzzKGBMF7AYucllWNBuSM6i/OuEdYJiIdCqxfBKwzhjjP+MkV+x0oAXQWUQGV2P/D7GzpV2BneinH7AKOye5Uh6hiVr5JREZKSKJIvJHETkAvOlMGPGZiCSJyDHneZzLPq7VuVNFZLmIPO1s+7uIjKnmtp1EZJmIpInIYhF5UUTeKSdud2J8XES+d473pbjMwCUiV4vILhE5Inb6xjIZO7nBN8DVJVZdA7xVWRwlYi5ZyjxHRDaJSIqIvIAdu71wXRcR+caJ77CIvCsijZ11bwPtgU+dGpH7RaSjiJjCL1oi0kZE5ovIURHZJiI3uBx7hoi8LyJvOb+b9SISX97vwFE4ycgCTkw84hantH0OMM4Ys9IYk2eMSTHGvGiMeb0qx1KqIpqolT9rBTQFOgDTsX/vbzqv2wOZwAsV7D8U2Aw0A/4BvC4iUo1t38NOBBMLzKB0cnTlToxXANdiS4IhwL0AItILOx/x1dgJC2KxUxiWZ7ZrLCLSHTuP8XtuxlGK86XhY+Bh7O9iOzDcdRPgSSe+ntjpFmcAGGOupnityD/KOMUc7GQNbbCz4P1NRM50WT/W2aYxdlKKcmMWkQjnGO86j0liZ5Ny19nAz8aYPVXYR6kq00St/FkB8KgxJtsYk2mMOWKM+cgYk2GMSQOeAM6oYP9dxphXnfujs4HWQMuqbCsi7YHBwCPGmBxjzHIqmFLQzRjfNMZsMcZkAu9jkyvYpPOZMWaZMSYb+LPzOyjPJ06Mw5zX1wALjTFJ1fhdFTofWG+M+dAYkws8Cxxwub5txpivnPckCXjGzeMiIu2wSf+PxpgsY8wa4DUn7kLLjTELnPfhbWxVdHkmANnAl8DnQDBwgTuxOGKxMz0pVas0USt/lmSMySp8ISIRIvKKUzWcCiwDGkv5LYpdE0zhfMVRVdy2DXDUFJ/vuNwSmJsxHnB5nuESUxvXYxtjjlPBfNdOTB/gzP0NXAm8VYU4ylIyBuP6WkRaisgcEdnrHPcdbMnbHYW/yzSXZbuAti6vS/5uwqT89glTgPedKuss4COKV3/nYZO3q2DsFIxgf7etUaqWaaJW/qzkHK5/ALoDQ40xjbANicDlHmot2A80dapZC7WrYPuaxLjf9djOOWMr2Wc2cBn2Xms08GkN4ygZg1D8ev+GfV/6OMe9qsQxK5p3dx/2dxntsqw9sLeSmEpx7refCVwlIgfEtmOYCJzvcs9/N9CxxK6dsF8OwM7NPaS8e/dKeYomatWQRGPvtSaLSFPg0do+oTFmF5AAzBDbledU4KJaivFD4EIROc251/oYlf+PfwckAzOBOcaYnBrG8TnQW0QmOCXZO7BtBQpFA+lAioi0Be4rsf9BoHNZB3buBa8AnhSRMBHpC1yHLZVX1dXAFuyXkf7Ooxv2/vdkZ5u5wF0i0kOseGAa9h44xpjFwFfAJyIySESCRCRaRG4SkWnViEmpMmmiVg3Js0A4cBj4Efiijs57JXAqtqr0r9gEkF3Ots9SzRiNMeuBW7GNwfYDx7CJp6J9DLa6u4Pzs0ZxGGMOA5cCT2GvtyvwvcsmfwEGAinYpP5xiUM8CTwsIskicm8Zp5iMLeXuw95jf9RJmFU1BXjJGHPA9QH8hxPV369iG9R96sT7FvCQMcb1dzER22J8rrPNb0A8trStlEeI/T9VStUVEZkLbDLG1HqJXilV/2mJWqlaJiKDnf7DASIyGhgHzPNyWEqpeqLSRC12OLxDIlLmSEXOvZvnncEHfhWRgS7rpogdWm+r1INxkZWqJa2Apdh7s88DNxtjfvFqREqpeqPSqm8ROR37AfOWMabU+L8icj5wO7b/5FDgOfP/7d13fFRV2sDx3zOTXuk1VKUI0gOIgjRFQBekqGADWUVY0RV1Xd21La6v7uruu/paEbEviKiICiJVXF2VIiBdUNTQREoo6Znz/nFuwhBSJmSSKXm+n08+c+eWmXMzyTz3nHvOc4zp6XRAWY29X2OwafW6GWMO+/cUlFJKqfBVZo3aGLMSOFTKLsOxQdwYY77EjrVsCFwCLDbGHHKC82JgsD8KrZRSSlUX/piooDGnJnBIc9aVtP40IjIRm+KR+Pj4bm3btvVDsZRSSqnQsGbNml+NMXWL2xYUMwoZY6Zjx3GSmppqVq9eHeASKaWUUlVHRH4saZs/en3v5tTMQynOupLWK6WUUspH/gjU83FyBYvIeUC6MWYvsAgYJHa6vJrAIGedUkoppXxUZtO3iMwC+gF1RCQNm0owEsAY8zw2K89QYAc2Cf4NzrZDIvIwsMp5qWnGmNI6pSmllFKqiDIDtTFmbBnbDTZtYXHbZgIzz6xoSimllNLMZEoppVQQC4pe30oppaovj8dwLCsPBOKi3ES6tQ7pTQO1UkqFMI/HcDwnj/SMXI5m5ZKemcvRzDyOZtrnOfkeYiPdxEW5iY2K8Fp2F7Mcgdt15tOz5+R5SM/MdX5yOJKRa38yc0nPyOFIZvHPj2bl4p0kM9ItheWJi7ZljIuMIDbqZHnjouz2gnOIi44gLtJ7ewRxUW5iIl2ICC4RXAIusefncp18Ls5jwT5S5LGkfaqKBmqllKpkHo/BYwz5xuDxQL4x5HsMHo+zzll/PDvPBtqsXBtonaB3NKtIIPYKyMeycvH4cRLEqAhXCcE8gthIF3FREUS6hePZeYWBOD0zlyMZOZzIyS/xdUUgOTaSGrGRJMdFkRwXRbPa8dSIs+uSYiMByMzJJyM3n8ycfE5k5xUuZ+TkcSQjhz1H8snIyScz127PzvP47+TL4YXrunFJ+wZl7+gHGqiVUtWCMYacfA8Z2fmcyMnjhPNY8DzDWXfKY04+GdnOo9f6zNx88vONE3CxQdhTEHBPD8gVFRPpIikmkmQnoNVLjOHsugmFz5NjI0mKsctJsRGFz5PjIol0ucjKLQh+eWTmeMjIsQEwK8cGPe/lTGe/k8t2/dHMXPan55ORm0dOnofEGBtgG9WI4ZyGSTYIx9kfuxxFjYJ1sVEkxkTgqkBtvST5HkNmrvO5FJxPzsngnpXnwRiDMfZz8jiPJ9edfO7x2scUXEAZCo/13uesugl+P5eSaKBWKgzk5Xs4lpXHsaw8WxvLyi18npmbT16+h7x8Q67HPuble8jzGPI8hlxnW57HQ66zLddjvI4xpx3vMYYIt4tIlxDpdhEZcXI5wi1EOY+RbpfzU7DNRZRb7LFFliPdYt8j30NuvoecfENOnsfruefk8zy7X3a+h9zCfcyp+zjrspyaV0ZOPnnlCJqxkW7io082ocZHR5AYE0GDpBhio9y4XYJbBJdLcLvALYKI2PUu20RasN5V+PzkepfXviL2teKj3acE3mQn8EZHuCv09xEb5aZmhV4heLldQkJ0BAnR4RvOwvfMlApCxtjgmO8EyHwnWBYEqOPZeU6APTXY2qZQu77gecF+x7JsECqvSLcQ4ToZUCO8Aq3bJUQ62woCcoRbSIiMIMIJNt5BPjMzt3A5N99DrscG0zxPQeA8eSFwJkQgyu0iyrkosI/iBHsXUREng31iTMQp66IjXMRHRxQG3Xjnfma8c/8z3isQF2yLjXRX6F6tUv6kgVqpEuTkedh/NIt9R7PYm57FvvRM9qZnsfdIFocyck7WSp0gVLBsg29BLfXU2uuZNoNGRbhIiokgKSaSxJgIEmMiaZgcQ2K0fZ4Ue3J9kvOY6OwfE+UqDLoFAbmgFlfVCi5UCmq7BTXfPKc2HOESr6B7Mghr0FTVmQZqFVB5+R72pmex+0gmvxzLJsotxDq1ntiok7Wdgh6d/rrHlZ2Xz/70bPakZ7Iv/dRAXBCYfz2eTdHp2hOjI2iQHEPthCjioyOcoGdrcm6nRup2CRFODTTC5QRGt7POeR7hFTDtsTaQJkR7B+OTAbiiTZ/BQkQKm8GVUr7RQK0qVVZuPruPZLL7cGbhY9rhjMLlfUezytVjNcbpdRrnNTzD+zE+2k1spG3mjI1yExfp5kROvhOMnUCcnsXBEzmnvXZSTAQNk2NpkBxD+0ZJNEiKpWFyDA2SYwofE2Mi/fjbUUqpsmmgVhWSnpnrFYSdAOwVmH89fmpAdLuEBkkxNK4RS8+WtWlcI5bGNWNpXMMGyNx8j1fPTXvv9USO7YV6IvvkkIzMnIKeurZ35+GMTLuP8/xETt4pteEacZE0TLaBt1OTGjRMsoG3kfO+DZJiiA/jzihKqdCl30yqVNl5+aQdzuSngxn8dMj+/Hgww9aKD2dyLDvvlP2jI1yFwfechkmnBOLGNWNpkBRDRBU0expjyM7zcCI7zyZFiAqPpmOlVPWjgbqaM8ZwOCOXHw+esIHYKyD/dCiDfUezTqmZxka6aVorjia1YunZopYThOMKg3GdhKiAdFIqSkSIiXQTE6kBWikV2jRQVwM5eR72HMm0teFDGfzsBOSC5eNFasX1EqNpVjuOXmfVpmmtOJrVjnOCcxx1E6KDIhArpVR1oYE6DHg8hgPHs/n5UAY/H87g50OZpyzvTc88pcNWVISLprVs8O3ZolbhcrPacaTUjNNmYqWUCiIaqEOAMYb0zFwbgA9nnBqQD2eQdjiTnCL5buslRtOkVhzdm9ekaa3GNK0dXxiQ6yVGV0oqP6WUUv6ngToIFATi/UezSSsMxJmFj2mHMk7rtJUcG0mTWrG0qZ/IRefUp0nNWFJqxdGkZhwpNWP13qxSSoUJDdSVxBjD0aw8DhzL5tfj9qdg2T7mnLKtaGrFmEgXTWra+8I9mtekSS3bLN2kVixNasWRpON5lVKqWvApUIvIYOBJwA3MMMY8VmR7M2AmUBc4BFxrjElztv0duBRwAYuB3xtTNN9TaDmalcvWvceKCb5eQfh49mnN0WDHEddJiKJOQjR1E6Np0yCxcLluYjQpNWNpUjMuaHpPK6WUCqwyA7WIuIFngIuBNGCViMw3xmz22u0J4DVjzKsiMgB4FLhORM4HLgA6Ovv9B+gLrPDfKVSNfI/hs+8O8M7a3SzatO+UIOwSqJ0QTZ2EaOokRHFWvQTqOsG3TpHHGrGRen9YKaWUz3ypUfcAdhhjvgcQkdnAcMA7ULcD7nCWlwPznGUDxABRgACRwP4Kl7oKfbf/GHPXpvHe2t38ciybGnGRjOnehAFt61E/KYa6idHUjIvSSQOUUkpVCl8CdWPgZ6/naUDPIvusB0Zim8dHAIkiUtsY818RWQ7sxQbqp40xW4q+gYhMBCYCNG3atNwn4W+HT+TwwYY9zF2Txoa0dNwuoX+buozqmsKAc+qFzQQJSimlgp+/OpPdBTwtIuOBlcBuIF9EzgbOAVKc/RaLSB9jzGfeBxtjpgPTAVJTUwNy/zo338OKbQd4Z00aS7fuJzffcE7DJO679ByGd25M3cToQBRLKaVUNedLoN4NNPF6nuKsK2SM2YOtUSMiCcAoY8wREbkJ+NIYc9zZthDoBZwSqANp856jzF2TxvvrdnPwRA6146O47rzmjOrWmPaNkgNdPKWUUtWcL4F6FdBKRFpgA/QY4GrvHUSkDnDIGOMB7sX2AAf4CbhJRB7FNn33Bf7ln6KfuV+PZzPvm928s3Y3W/YeJdItDGxbn9HdUujbpq7OlauUUipolBmojTF5IjIFWIQdnjXTGLNJRKYBq40x84F+wKMiYrBN37c4h88FBgDfYjuWfWyM+cD/p1G27Lx8lm35hXfWprF82wHyPYaOKclMG96e33RsRM34qEAUSymllCqVBNuQ5tTUVLN69Wq/vJYxhg1p6byzNo356/dwJCOXeonRjOjamNFdU2hVP9Ev76OUUkpVhIisMcakFrctrDOTHc7IZdRzX+B2CYPaN2BU18b0PrtOlcyHrJRSSvlDWAfqWvFRvDgula5Na5Icqyk3lVJKhZ6wDtQA/dvUC3QRlFJKqTOmbcBKKaVUENNArZRSSgUxDdRKKaVUENNArZRSSgUxDdRKKaVUENNArZRSSgUxDdRKKaVUENNArZRSSgUxDdRKKaVUENNArZRSSgUxDdRKKaVUENNArZRSSgUxDdRKKaVUENNArZRSSgUxDdRKKaVUEPMpUIvIYBHZJiI7ROSeYrY3E5GlIrJBRFaISIrXtqYi8omIbBGRzSLS3I/lV0oppcJamYFaRNzAM8AQoB0wVkTaFdntCeA1Y0xHYBrwqNe214DHjTHnAD2AX/xRcKWUUqo68KVG3QPYYYz53hiTA8wGhhfZpx2wzFleXrDdCegRxpjFAMaY48aYDL+UXCmllKoGfAnUjYGfvZ6nOeu8rQdGOssjgEQRqQ20Bo6IyLsi8o2IPO7U0E8hIhNFZLWIrD5w4ED5z0IppZQKU/7qTHYX0FdEvgH6AruBfCAC6ONs7w60BMYXPdgYM90Yk2qMSa1bt66fiqSUUkqFPl8C9W6gidfzFGddIWPMHmPMSGNMF+DPzroj2Nr3OqfZPA+YB3T1Q7mVUkqpasGXQL0KaCUiLUQkChgDzPfeQUTqiEjBa90LzPQ6toaIFFSTBwCbK15spZRSqnooM1A7NeEpwCJgCzDHGLNJRKaJyDBnt37ANhHZDtQHHnGOzcc2ey8VkW8BAV70+1kopZRSYUqMMYEuwylSU1PN6tWrA10MpZRSqsqIyBpjTGpx2zQzmVJKKRXENFArpZRSQUwDtVJKKRXENFArpZRSQUwDtVJKKRXENFArpZRSQUwDtVJKKRXENFArpZRSQUwDtVJKKRXENFArpZRSQUwDtVJKKRXENFArpZRSQUwDtVJKKRXENFArpZRSQUwDtVJKKRXENFArpZRSQUwDtVJKKRXEfArUIjJYRLaJyA4RuaeY7c1EZKmIbBCRFSKSUmR7koikicjT/iq4UkopVR2UGahFxA08AwwB2gFjRaRdkd2eAF4zxnQEpgGPFtn+MLCy4sVVSimlqpcIH/bpAewwxnwPICKzgeHAZq992gF3OMvLgXkFG0SkG1Af+BhIrXiRlVJKAeTm5pKWlkZWVlagi6J8FBMTQ0pKCpGRkT4f40ugbgz87PU8DehZZJ/1wEjgSWAEkCgitYHDwD+Aa4GLfC6VUkqpMqWlpZGYmEjz5s0RkUAXR5XBGMPBgwdJS0ujRYsWPh/nr85kdwF9ReQboC+wG8gHfgcsMMaklXawiEwUkdUisvrAgQN+KpJSSoW3rKwsateurUE6RIgItWvXLncLiC816t1AE6/nKc66QsaYPdgaNSKSAIwyxhwRkV5AHxH5HZAARInIcWPMPUWOnw5MB0hNTTXlOgOllKrGNEiHljP5vHwJ1KuAViLSAhugxwBXF3njOsAhY4wHuBeYCWCMucZrn/FAatEgrZRSSqmSldn0bYzJA6YAi4AtwBxjzCYRmSYiw5zd+gHbRGQ7tuPYI5VUXqWUUkHi4MGDdO7cmc6dO9OgQQMaN25c+DwnJ6fUY1evXs1tt91W5nucf/75/iouALfffjuNGzfG4/EUrnvooYd44oknTtmvefPm/PrrrwDs27ePMWPGcNZZZ9GtWzeGDh3K9u3b/Vqu0vhSo8YYswBYUGTdA17Lc4G5ZbzGK8Ar5S6hUkqpoFS7dm3WrVsH2GCXkJDAXXfdVbg9Ly+PiIjiw0xqaiqpqWUPBPriiy/8UlYAj8fDe++9R5MmTfj000/p379/mccYYxgxYgTjxo1j9uzZAKxfv579+/fTunVrv5WtNJqZTCmllN+MHz+eSZMm0bNnT+6++26+/vprevXqRZcuXTj//PPZtm0bACtWrOCyyy4DbJCfMGEC/fr1o2XLljz11FOFr5eQkFC4f79+/Rg9ejRt27blmmuuwRjbpWnBggW0bduWbt26cdtttxW+blErVqygffv2TJ48mVmzZvl0PsuXLycyMpJJkyYVruvUqRN9+vQp/y/nDPlUo1ZKKRXc/vLBJjbvOerX12zXKIkHf9O+3MelpaXxxRdf4Ha7OXr0KJ999hkREREsWbKEP/3pT7zzzjunHbN161aWL1/OsWPHaNOmDZMnTz5trPE333zDpk2baNSoERdccAGff/45qamp3HzzzaxcuZIWLVowduzYEss1a9Ysxo4dy/Dhw/nTn/5Ebm5umeOZN27cSLdu3cr9O/AnrVErpZTyqyuuuAK32w1Aeno6V1xxBeeeey5Tp05l06ZNxR5z6aWXEh0dTZ06dahXrx779+8/bZ8ePXqQkpKCy+Wic+fO7Nq1i61bt9KyZcvCccklBeqcnBwWLFjA5ZdfTlJSEj179mTRokVAyT2xg6VHvdaolVIqDJxJzbeyxMfHFy7ff//99O/fn/fee49du3bRr1+/Yo+Jjo4uXHa73eTl5Z3RPiVZtGgRR44coUOHDgBkZGQQGxvLZZddRu3atdm7d+8p+x87dowaNWrQvn175s4ttQtWpdMatVJKqUqTnp5O48aNAXjllVf8/vpt2rTh+++/Z9euXQC89dZbxe43a9YsZsyYwa5du9i1axc//PADixcvJiMjgwsvvJD58+dz7NgxAN599106deqE2+1mwIABZGdnM3369MLX2rBhA5999pnfz6UkGqiVUkpVmrvvvpt7772XLl26lKsG7KvY2FieffZZBg8eTLdu3UhMTCQ5OfmUfTIyMvj444+59NJLC9fFx8fTu3dvPvjgAzp27MiUKVPo3bs3nTt35vnnn2fGjBmAbf5+7733WLJkCWeddRbt27fn3nvvpUGDBn4/l5JIQa+5YJGammpWr14d6GIopVTQ27JlC+ecc06gixFwx48fJyEhAWMMt9xyC61atWLq1KmBLlaJivvcRGSNMabY8Wpao1ZKKRXSXnzxRTp37kz79u1JT0/n5ptvDnSR/Eo7kymllAppU6dODeoadEVpjVoppZQKYhqolVJKqSCmgVoppZQKYhqolVJKqSCmgVoppdQZ6d+/f2EazgL/+te/mDx5conH9OvXj4IhuEOHDuXIkSOn7VPctJNFzZs3j82bNxc+f+CBB1iyZEk5Sl+6YJoOUwO1UkqpMzJ27NjCqR8LzJ49u9SJMbwtWLCAGjVqnNF7Fw3U06ZN46KLLjqj1yqq6HSYviiYDrNfv37s3LmTNWvW8Oijjxabs7y8NFArpZQ6I6NHj+ajjz4iJycHgF27drFnzx769OnD5MmTSU1NpX379jz44IPFHu9dG33kkUdo3bo1vXv3LpwKE+wY6e7du9OpUydGjRpFRkYGX3zxBfPnz+cPf/gDnTt3ZufOnYwfP74wJ/fSpUvp0qULHTp0YMKECWRnZxe+34MPPkjXrl3p0KEDW7duLbZcwTYdpo6jVkqpcLDwHtj3rX9fs0EHGPJYiZtr1apFjx49WLhwIcOHD2f27NlceeWViAiPPPIItWrVIj8/n4EDB7JhwwY6duxY7OusWbOG2bNns27dOvLy8ujatWvh1JIjR47kpptuAuC+++7jpZde4tZbb2XYsGFcdtlljB49+pTXysrKYvz48SxdupTWrVtz/fXX89xzz3H77bcDUKdOHdauXcuzzz7LE088UZgq1FuwTYepNWqllFJnzLv527vZe86cOXTt2pUuXbqwadOmU5qpi/rss88YMWIEcXFxJCUlMWzYsMJtGzdupE+fPnTo0IE333yzxGkyC2zbto0WLVrQunVrAMaNG8fKlSsLt48cORKAbt26FU7k4S0Yp8P0qUYtIoOBJwE3MMMY81iR7c2AmUBd4BBwrTEmTUQ6A88BSUA+8IgxpvipTZRSSp25Umq+lWn48OFMnTqVtWvXkpGRQbdu3fjhhx944oknWLVqFTVr1mT8+PFkZWWd0euPHz+eefPm0alTJ1555RVWrFhRofIWTJVZ0jSZwTgdZpk1ahFxA88AQ4B2wFgRaVdktyeA14wxHYFpwKPO+gzgemNMe2Aw8C8RqeGnsiullAqwhIQE+vfvz4QJEwpr00ePHiU+Pp7k5GT279/PwoULS32NCy+8kHnz5pGZmcmxY8f44IMPCrcdO3aMhg0bkpuby5tvvlm4PjExsXBaSm9t2rRh165d7NixA4DXX3+dvn37+nw+wTgdpi9N3z2AHcaY740xOcBsYHiRfdoBy5zl5QXbjTHbjTHfOct7gF+wtW6llFJhYuzYsaxfv74wUHfq1IkuXbrQtm1brr76ai644IJSj+/atStXXXUVnTp1YsiQIXTv3r1w28MPP0zPnj254IILaNu2beH6MWPG8Pjjj9OlSxd27txZuD4mJoaXX36ZK664gg4dOuByuU7p4FWaYJ0Os8xpLkVkNDDYGHOj8/w6oKcxZorXPv8GvjLGPCkiI4F3gDrGmINe+/QAXgXaG2M8Rd5jIjARoGnTpt1+/PHHCp+YUkqFO53mMjQFaprLu4C+IvIN0BfYjb0nXVCAhsDrwA1FgzSAMWa6MSbVGJNat65WuJVSSqkCvnQm2w008Xqe4qwr5DRrjwQQkQRglDHmiPM8CfgI+LMx5ks/lFkpFWiefHC5A10KpaoFX2rUq4BWItJCRKKAMcB87x1EpI6IFLzWvdge4Dj7v4ftaFY53eGUUlUn+zi8OxEePwuO/BTo0ihsRiwVOs7k8yozUBtj8oApwCJgCzDHGLNJRKaJSMFgt37ANhHZDtQHHnHWXwlcCIwXkXXOT+dyl1IpFXj7NsL0fvDt25BzApY+HOgSVXsxMTEcPHhQg3WIMMZw8OBBYmJiynVcmZ3JqlpqaqopSNiulAoCxsDa12Dh3RBTA0a/BDuXwWf/gJuWQ+OugS5htZWbm0taWtoZj1FWVS8mJoaUlJTTMp2V1plMU4gqpUqWfQw+nGpr0S37w8gXIaEuNOgIa16FT+6H8R9CJWdmUsWLjIykRYsWgS6GqmSaQlQpVbyCpu6N78CA++Dad22QBohJgv73wo//gW2lJ7NQSlWMBmql1KmMsbXlGQNt57FxH8CFfwBXka+LruOgTmtY/ADk5wamrIGwbyO8NhzS1gS6JKqa0ECtlDop+xi8exN8cBs07QWT/gPNexe/rzsSLp4GB7+DNa9UaTED6tO/wfcr4OUh8M0bgS6NqgbCP1BnHw90CZQKDaU1dZek9WBo3gdWPApZ6VVSzIA68hNs/RC6jYem58H7t8CCP1SvFgVV5cI7UGccgufOh+X/A57TEqIppcBp6n6l7Kbu4ojAoIch4yD851+VXdLA+/pFQOzv59p3odcU+Hq6bQo/fiDQpVNhKrwDdWScbbb79G8w+2rIOhroEikVXAqbun9fdlN3SRp1gY5XwZfPwpGfK6ecwSDnBKx9Fc75DSSngDsCLnnE9oTfvca2Ruz5JtClVGEozAN1DAx/BoY8Dt99YmsMv34X6FIpFRzOpKm7JAPutzXzZX/1axGDyvrZtnn/vMmnru94JUxYZFsXZg62+ynlR+EdqMH+8/ScCOPm2+a5FwfAto8DXSqlAqciTd0lqdEEev0ONsyGPev8VdLgYQx89QI07AxNep6+vVFnmLgCUrrDezfDx/dCfl4VF1KFq/AP1AWa94aJn0KtFjBrDHz6uN63VtWPP5q6S9J7KsTVhk/us4EtnOxcBr9us7XpkpK7xNeB696DnpPtbYA3RsCJg8Xvq1Q5VJ9ADfaqf8Ii21S1/K/w9vX2iyucff9peN83DBf5ubB9kQ0Iv2ytnP4U/mzqLk5MMvS7F3Z9Zs8lnHz1PMTXg/YjSt/PHQlDHoPLn4OfvrK/773rq6SIKnxVz1zfxtgr3k/uhzqtYMy/ofZZlfuegbB/Mzx/AdRsATd/CtGJgS6RKsoY2DIflk6DgztO3RaVAEmN7E+i85jUEJIaQ6LzGFe77CZrY2wnqIV/PJmr21+16KLyc+HZ80BcMPm/tsNVqPt1BzzdzV6E9LvH9+N2r4G3rrOjT4Y/DR1GV14ZVcgrLdd39QzUBb5fAW+PB+OBUTOh1UVV875V5fWR8PPXkHsCOlwJI18IdImUt12f26xeu1dD3bbQ/8+2+fTonpM/x7yX94HJP/U13FGQ2MAreDfy+nEC+YpHT8/VXZm2fmRHWVz6D+h+Y+W+V1VY8Ad7T3/qJkioV75jj/8Cc8bBT1/A+bfCwIfC4+JF+Z1OylGSlv1sB5DZ18Kbo2HgA/Y+WzhMMLBjCexcCpf8j23eX/GoPd/OYwNdMvXLFljyEGz/2NaUhz0Nna8Gl7v04zz59ovfO3gXBvG9sHcdbFsAeUVmUhKXberufWfFOoz5qs1QaHYBLH/UXiDGJFX+e1aWrHRY9284d1T5gzTYY65/Hxb9Cb74P3v7YfRMiKvl/7KqsFW9a9QFck7A+1Ng07v2HtTwZyAqvmrL4E+efHi+D+RmwC1f2wDw6jA7xvPmT21zv6p66btt8p31/4aoROgzFXrcDFFx/nsPYyDz8MngfXQ3NOgAjbv57z18sXuNHWHR5057ARyq/vuMDbITP7U9uyti7Wvw0Z225WPMv6HBuX4pogoP2vTtC2Pg8ydh6V+gXju46g3bQzwUrXnV5mq+4lVof7ldl74bnu8NyY3ht0vsGHNVNTIPw3/+1w7vMR7oMdEGsHCvVb1zI2z5AG5dYxOEhBpPPjzVxd5GmOCnIZ0/r4I519ma+uXPlt05TVUbpQXq6tXruzQi0Pt2uOZtSP8ZXuwPO5cHulTll30clj8CTc6DdsNPrk9ubHui7vvW3hetDn7dASufONnkWNUXpblZ8PlT8GRn+9juchu0Lnkk/IM0hH4SlO0fw5Efoeck/71mk+72dluDDrZ/zJKH7AWBUqWo3veoi3P2RXDTcph9Dbwx0s4O1GtK6Ny3/vxJOL7fNq0VLXObwXDe72yP95Z9oe2lgSljZUpPg43vwsa5pw+LSahv79O37A9n9bedsCqDJx82zLEXTOk/27+pix6yX87VSc1mcN4ke5HSc1LFm46r2pfPQXITaHuZf183sQGM+xAW3m1bWvZ9C6NmQGxN/76PChs+NX2LyGDgScANzDDGPFZkezNgJlAXOARca4xJc7aNA+5zdv2rMebV0t4rYE3fRWUfh3mTbNNdhyvgN0/5915iZTi6B57qCm2H2g4rxcnLhpcuhsM/wuTPQ7NJsqgTv8Km92yA/ukLu65RFzh3tNO0aGwP/53L7GOGk4SiXjsnaA+AZudX/PM1xnbiW/IQ7N9os1hdPM1eFFVXmUds83H99jYDWqhc8O7baIc2XvQX29JWWVbPhAV32//DsbOg3jmV914qqFXoHrWIuIHtwMVAGrAKGGuM2ey1z9vAh8aYV0VkAHCDMeY6EakFrAZSAQOsAboZYw6X9H5BE6jBfvF+9gQse8TWhsa8CTWaBrpUJZv3OzsMZ8oqqNm85P0O7oQXLrTnNO7D0BwuknXUTjf47VwbfE0+1Gljx6qeO6rkcfEeD+z/1gbtncvhpy8hP9sOc2p63snadoNO5eshvXsNLH7QJvuo2dx2oGo3omp6WQe7r16wtcer50DrSwJdGt+8P8X+bd2xufJvU/z0Jcy53lYORr8EbYZU7vupoFTRQN0LeMgYc4nz/F4AY8yjXvtsAgYbY34WEQHSjTFJIjIW6GeMudnZ7wVghTFmVknvF1SBusD2RbZjjDvSdtBq0SfQJTrd3g02+J5/q512sCwb5thUkhfeDQP+XPnl84fcTPtZbJwL2z+xATa5KXQYZYNz/XPLX2PLybC18J3LbcDfv9Guj6sNLfra2vZZ/UtueTi4E5Y9bGv0cXWg7x/tXMURURU50/CSl2OToLgiYPIXwX9heOIg/G876DQWfvOvqnnPo3vs2PO9623rXdfrquZ9VdCo6DjqxoB3Dso0oGhW+vXASGzz+AggUURql3Bs42IKOBGYCNC0aRDWWFtfAjcts/9Irw2HwY/anrvB0oxnDHzyZ3uPq8+dvh3T8UobmFY+bi88WlxYqUU8Y/m5tpzfzrWJNHKO2VSO3cbb2nNK94p9DlFx9h7y2U6ym2P77ft9v9wG703v2vW1W50M2s17245in/4N1rwM7mgboHtNCe0xw5UlIsreAnjrGvjmNUidEOgSlW7Ny3Ysuj87kZUlqZFt3ZpzHcyfAid+gd53BM93jAoof13a3gU8LSLjgZXAbsDnrozGmOnAdLA1aj+Vyb/qtIIbl9qZcRbebZNWXPa/wfGPtH0R/LDSTucZW8P344b83WYue3einZwhvk6lFbFcPB5by934DmyaB5mHIDoZ2g+3952b96m8Wllifeh0lf0xxn7OBUF77Wvw9Qu2ZuiKhPwce8HQ94/2OFWytpdC0/PtOPIOVwRvOtv8XFj1kr0FUq9t1b53dAKMfQve/51NKXv8gE1YpLdPqj1fvu12A028nqc46woZY/Zga9SISAIwyhhzRER2A/2KHLuiAuUNrJgkuOpNWPIgfPGUvQ96/q2BLVN+Hiy+H2qfDak3lO/Y6ATb6WzGRTBvsr2HGMgLjz3r7D32je/a7FuRcfZ+3bmj4eyBEBFdteURgfrt7E+vW2xHvJ+/skE787CtQdc5u2rLFKpEYNBfYcYAOzJhwH1lHxMIm9+3f3tV1eRdVEQUjJgO8XXt6IwTB+ywSr2VUq35EqhXAa1EpAU2QI8BrvbeQUTqAIeMMR7gXmwPcIBFwP+ISMG4g0HO9tDlctlmvCM/2vHI9dvbJtFAWfsK/LrdDsdyR5b/+IYd7bjeBXfZL4Zet/i9iGXKzbLZn1a/ZGuqZ19k77O3GRJcGeIiou0tgmC9TRDsUrrZi64vnoZuN9ix/cHmq+eh1llw9sWBK4PLZWvS8XVtAqbMQ3Dl6/bCWlVLZbapGGPygCnYoLsFmGOM2SQi00RkmLNbP2CbiGwH6gOPOMceAh7GBvtVwDRnXWgTgeHP2okU5k6AQz8EphxZR20+5Wa9bX7lM9X9RjtWdPGDsHut/8rniwPbYcZAG6R7TYG7tsPVs+3952AK0so/Bj5ge+gvfyTQJTld2hpIWwU9bw58c7MI9LnDpjP+/lN49Td2GKKqljSFaEUc+h6m97ezFN24uOoDy5KHbMKEiSvsuOGKyDhk84O7I+HmlVXTKWrdLJv7ODIGRrwArQJYi1FV55P7bba4m1faFp1g8c6Ntr/HHZuD6x76toU2i1lyClz3XnAPEVVnTFOIVpZaLe24xwNb7BjmqrzoOfIT/PdZ6Dim4kEa7FjR0S/Z1/1wauWeS/ZxeG+STSjTqIvtyKZBuvroc6ft9PjJfVWf1rUkR/faIXZdrg2uIA32FtB18+z96pcGwf5NgS6RqmIaqCuqID3k5nm2dltVlj5sm8cG3u+/12x6HvS/145TXvem/17X276NML0frJ8Nfe+BcfPt0BRVfcTWsJ/9D5/aTG7BYPVLNvVrj4mBLknxmvWCG5yJQV4eAj/+N7DlUVVKA7U/nH+bTbixdBp8t7jy32/3Gvh2ju345e8UoL3vsMOfFvwBDmzz3+saY4e9vDjAzo89br69KChrDmYVnlIn2BapT+6zIxcCKTcLVr9sa67BPGNe/Xbw209sHoHXL4etCwJdIlVFNFD7gwgMe9rOLzv3tzZbVWUxBhbdZ3uE9p7q/9d3uWHkixAZazvK5WZW/DUzj8Db4+CjO2xylUn/0Z7T1V1ElM2jfWArrHsjsGXZOBcyfq3aBCdnqkZTmLDIjjZ56xo7tj8cHNgGz55vKzvqNBqo/SUqzo6xdrltBrPsY5XzPls/tMlA+v+p8u6lJTWEy5+36TQ/qeB417Q18EIfm1Xs4mlw9duQUNc/5VSh7Zzf2OlYlz1i+y0EgjHw5fN2gpZQuXiMrw3Xz7dJWebfCp/9I3ju9Z+JnctgxsW2r89n/9Bm/WJooPanms3gilfg1+9sZymPx7+vn5djx27XbQtdrvfvaxfVepAdLrVqBmyeX/7jPR7bs3fmIDsdyw0fwwW/D/ywFxU8ROwY/hO/2ARCgfDj53aSlp6TgiPLoK+iE2DsbOhwpa2Ffnyv/79vqsKqGfDGaHsLb/J/bYvB/Cn+ackLI/qt6W8t+9oMTFs/tDNv+dPqmXZI2MUPV83EBgMftL2y50+xvcF9deIgzBpja+OtB8OkldCke+WVU4WulFRoP9LOWX10T9W//5fPQWwtm/s+1ERE2WGN590CXz1nJ9nJywl0qXyTn2en9/zoTtsh97eLbMrWYf8HB3fAikfLfo1qRAN1ZThvsh02tfwR/3X4yDwMnz4GLftV3VCmiCibYtTjsffe83PLPmbX5/B8b5sfe+gTcNUbdrIQpUpy0YOBSYJy+EfYtsDma4+Mrdr39heXy7ZKXPQXe6991lWBu43gq6x0W86vX7CtdmNnnbyN17IfdB1nW+N2rwloMYOJBurKIGJzBTfsbCe8OLC94q+58gnbKWvQX6u2ia5WS3suaV+XfpXryYdP/w6vXma/9G5cAj1uCq3mRBUYNZvbYVHfvGkniakqX08HxGbmC2Ui0Pv20MhidngXvHSJnaHuN0/ai4yiIz8GPQwJDeyc4KHSQlDJNFBXlshYGPOmzQ89e6y9ijxTh36wXypdroEGHfxXRl91GA1droPP/mn/wYo6ts8OF1n+iM3lfPOn0LBTVZdShbIL77IZ/l65zA7jq+zOUdnHYe3r0G54cOYcPxNdrrU5/3/ZAjMvsS0GweSnr+DFgXbSk2vftS0ZxYlJtpWDXzbbzmVKA3WlSk6BK1+zV5HvTjzzzh5L/2KnVuwfwBmHhvwN6rS253H8wMn1O5bAcxdA2mp7RT9yevBldlLBL7amvcBr3tsO45s7weayryzrZ0F2ur1NFU7aDIbr3w++LGYb5tjWtphkuHGZ7ctTmtaXQMerbD+ffRurpoxBTAN1ZWt+AQx+DLZ/fGYdJH7+2qY2PP82O2wqUKLi4YqXbfP7vEm2SWrJQ/DGKEioBzctt1f02tStzlR8Hbhmru3EuPl9mN4X9q73//t4PPDVC9CoK6SEYSfHpj3tWGtxwcwhdq76QPF4YNlfbUe3Jj3tLTFfp4Yd/Ji9gHv/d4FPihNgGqirQvcbbRBb+ffyDXUyxk7/mNAALrit8srnq/rtYfCjthb9VBebMrXbeLhpme2xqVRFuVx21qjxH9qMYTMutkN4/NkUvnMZHPzO1qbD9cKy3jk2i1lCPXvP+uVLYcsHti9JVcnJgLnjYeXj9tbZte/aOQV8FVcLLv2HvVgL1PC9IKGBuiqIwNB/QONUO756/2bfjtv0np12b8B9wTPlY+oEO5wmK932CP/Nk6HbY1YFr2bnw6TPbCa7j+6EuTf4ryn8q+fsxW+7y/3zesGqRhN7ET3or3Z45VvXwlOd7XzgmUcq972P7YNXhtqKyaC/2mFXEVHlf512w+GcYbDiMf90yg1ROs1lVTq6x05IERkHE5eXPmwpLxue7m7v9968MrhyYns8kJdls7EpVZk8HvjiSTsJTY2mcOWrFeuoeGA7PNMd+v8Z+t7tv3IGu/w8OxTtq+dtkpfIeOh8tU304mtTtK/2brB5FDKPwKgZ0HZoxV7v2H54tifUbgUTPg6u70I/0mkug0VSI7jydUhPs+OSS2uG+no6HPnRDlUItj9Ml0uDtKoaLpfNaT/+I3vxOuMi+PrFM28K//oFcEdBtxv8W85g546AdsPghgX2wr/dcFj7KjzdDd68AnYs9c/tha0fwczBgNgkJhUN0gCJ9WHw3+wQ0a+nV/z1QpAG6qrWtCcMfRx2Li05AX3GIXtf5+yL4awBVVs+pYJRs152MpeW/WDBXXaSl/IOecw8AutmQYcrqne++YadYMRzMHUT9PsT7FkHb4yEZ3ra7Ic5GeV/TWPg8ydh9jW2v8pNy/w7lLTjldDqEljyF5udsZrRQB0IqTfYK/rP/wUb3z19+6d/s5N6DHq4youmVNCKrw1j37JZuLZ8CC9cCHu+8f34b16H3BOhMUtWVUioB/3+CFM32lSkkbHw4VT45zl2ToEjP/v2Onk5Ns3w4geg/eW29SOxvn/LKgKX/S+4I2H+baE9CckZ8ClQi8hgEdkmIjtE5J5itjcVkeUi8o2IbBCRoc76SBF5VUS+FZEtInKvv08gZA35u5056P1bYN+3J9f/usP2cu06zvbcVEqd5HLZLFw3LLApbV8aBF9NL/uL25Nvm02bXQANO1ZJUUNGRDR0GgMTV9hhXS372hSeT3aCOePgpy9L/v1mHILXR8A3b0DfP8KomZXXuTS5sa287PoM1rxSOe8RpMoM1CLiBp4BhgDtgLEi0q7IbvcBc4wxXYAxwLPO+iuAaGNMB6AbcLOINPdT2UNbRJRNhhKTbKfFzDhk1y95ECJi7DSWSqniNT3PaQrvDwv/AHOuL70pfNsC2/NZa9MlE7G/1ytfg99vgPOn2EyEMy+xnWDXzz41peev38GLA+zIlJEv2u+syp4dr+s4aNEXPrnf9vWpJnz5rfYAdhhjvjfG5ACzgeFF9jFAkrOcDOzxWh8vIhFALJADVGK6oRCTWN/OYX1sH7w93iYm2PqhrTEk1At06ZQKbnG17FSPFz9sOzG9cCHsXlv8vl8+D8lNoY0fOjdVBzWa2Pnj79gMl/7TTjv53s3wr3Nhxd9sQpoZAyHnuB3zXlWzj4nAsKfsJC4f3F5tmsB9CdSNAe+bFWnOOm8PAdeKSBqwALjVWT8XOAHsBX4CnjDGHCr6BiIyUURWi8jqAwcOFN0c3lK62XsvP3wKb15p8x2fd0ugS6VUaHC5bDKgGxbaIUgvDbJZx7y/wPdugB//Az1urJrpYcNJVDx0/y3c8pVNWNKgI6z4H9uCkdQYblwKTXpUbZlqNoeLHoIdi20tvxrwVzvFWOAVY0wKMBR4XURc2Np4PtAIaAHcKSItix5sjJlujEk1xqTWrVsNe2N2udbOHpSXCQMf0KFPSpVX0542QcrZA2Hh3TDnupNJPb56weYu6Hp9QIsY0kTs7/bauTBltR0uNWER1GwWmPJ0v8n28fn4HjvOOsz5Eqh3A028nqc467z9FpgDYIz5LxAD1AGuBj42xuQaY34BPgeKHdBd7Q1+zHbm6HhVoEuiVGgqaAof9FfYttA2hX+3GL5923aW0nnR/aNOKzhvEsQklb1vZXG5YPjTtkn+ozvCvgncl0C9CmglIi1EJArbWaxowuqfgIEAInIONlAfcNYPcNbHA+cBW/1T9DDjckOjLuGbe1ipqiAC599qm8I9+fDmaMjP1k5k4ahOK9uBbeuHsHleoEtTqcoM1MaYPGAKsAjYgu3dvUlEponIMGe3O4GbRGQ9MAsYb2xu0meABBHZhA34LxtjNlTGiSilVKEmPWxT+LmjbM6Cum0CXSJVGXpNsRWcj+6CEwcDXZpKo7m+lVJKha79m+CFvtB+BIx6MdClOWOa61sppVR4qt8eLrwLvp1j+yaEIQ3USimlQlvvO6Bee5sCtbKn8AwADdRKKaVCW0QUXP4MHP8FPrkv0KXxOw3USimlQl+jLjb5zTevw85lgS6NX2mgVkopFR763gO1W8H830P28UCXxm80UCullAoPkTE2EUr6z7D0L4Eujd9ooFZKKRU+mp5nE9x8PR1+/CLQpfELDdRKKaXCy8D7oUYzeH+KTTMa4jRQK6WUCi9R8TDs/+DQTvj43tLnKg8BOuebUkqp8NOyr51la9WL8M0b0OJCOOcyaHMpJNYPdOnKRVOIKqWUCk8eD6Stgq0fwJYP4fAPgEBKdxu0214Gtc8KdCmB0lOIaqBWSikV/oyBX7bY2ba2fAD7nPmh6rWDtpfaoN2wU8BmMNRArZRSSnk78hNs/cjWtH/6AowHkpucDNpNe4G76u4Oa6BWSimlSnLiIGxfaIP2zmV2DvPYWtBmqA3cZ/WHyNhKLYIGaqWUUsoX2cdh51IbtLcvgux0iIyHswfamnbrQRBb0+9vW1qg1l7fSimlVIHoBGg33P7k5cCP/7FBe+tHsGU+uCKgeW/ofx806V4lRdJArZRSShUnIgrOGmB/hj4Be9bajmhbP6zSTmc+JTwRkcEisk1EdojIPcVsbyoiy0XkGxHZICJDvbZ1FJH/isgmEflWRGL8eQJKKaVUpXO5ICUVLv4L3LoGGnersrcus0YtIm7gGeBiIA1YJSLzjTGbvXa7D5hjjHlORNoBC4DmIhIBvAFcZ4xZLyK1gVy/n4VSSilVlYKsRt0D2GGM+d4YkwPMBoYX2ccASc5yMrDHWR4EbDDGrAcwxhw0xuRXvNhKKaVU9eBLoG4M/Oz1PM1Z5+0h4FoRScPWpm911rcGjIgsEpG1InJ3BcurlFJKVSv+mpRjLPCKMSYFGAq8LiIubNN6b+Aa53GEiAwserCITBSR1SKy+sCBA34qklJKKRX6fAnUu4EmXs9TnHXefgvMATDG/BeIAepga98rjTG/GmMysLXtrkXfwBgz3RiTaoxJrVu3bvnPQimllApTvgTqVUArEWkhIlHAGGB+kX1+AgYCiMg52EB9AFgEdBCROKdjWV9gM0oppZTySZm9vo0xeSIyBRt03cBMY8wmEZkGrDbGzAfuBF4UkanYjmXjjU15dlhE/okN9gZYYIz5qLJORimllAo3QZdCVEQOAD/6+WXrAL/6+TUDLRzPCcLzvPScQkc4nlc4nhOE33k1M8YUe+836AJ1ZRCR1SXlUA1V4XhOEJ7npecUOsLxvMLxnCB8z6s4/ur1rZRSSqlKoIFaKaWUCmLVJVBPD3QBKkE4nhOE53npOYWOcDyvcDwnCN/zOk21uEetlFJKharqUqNWSimlQpIGaqWUUiqIhU2g9mHO7GgRecvZ/pWINA9AMctFRJo483xvdubz/n0x+/QTkXQRWef8PBCIspaHiOxy5iZfJyKri9kuIvKU81ltEJHT0s4GGxFp4/UZrBORoyJye5F9gv6zEpGZIvKLiGz0WldLRBaLyHfOY80Sjh3n7POdiIyrulKXrYTzelxEtjp/Y++JSI0Sji317zVQSjinh0Rkt9ff2NASji31+zJQSjint7zOZ5eIrCvh2KD8nPzCGBPyP9iMaTuBlkAUsB5oV2Sf3wHPO8tjgLcCXW4fzqsh0NVZTgS2F3Ne/YAPA13Wcp7XLqBOKduHAgsBAc4Dvgp0mct5fm5gHzaBQUh9VsCF2Hz8G73W/R24x1m+B/hbMcfVAr53Hms6yzUDfT5lnNcgIMJZ/ltx5+VsK/XvNcjO6SHgrjKOK/P7MpjOqcj2fwAPhNLn5I+fcKlR+zJn9nDgVWd5LjBQpApn/j4Dxpi9xpi1zvIxYAunTzEajoYDrxnrS6CGiDQMdKHKYSCw0xjj7wx7lc4YsxI4VGS19//Oq8DlxRx6CbDYGHPIGHMYWAwMrqxylldx52WM+cQYk+c8/RI74VDIKOGz8oUv35cBUdo5Od/XVwKzqrRQQSBcArUvc2YX7uP8c6YDtaukdH7gNNV3Ab4qZnMvEVkvIgtFpH3VluyMGOATEVkjIhOL2e7L5xnMxlDyl0mofVYA9Y0xe53lfUD9YvYJ9c9sArYVpzhl/b0GmylOc/7MEm5ThOpn1QfYb4z5roTtofY5+SxcAnVYE5EE4B3gdmPM0SKb12KbWDsB/wfMq+LinYnexpiuwBDgFhG5MNAF8hexM8wNA94uZnMoflanMLaNMazGdIrIn4E84M0Sdgmlv9fngLOAzsBebFNxuBhL6bXpUPqcyiVcArUvc2YX7iN2ys1k4GCVlK4CRCQSG6TfNMa8W3S7MeaoMea4s7wAiBSROlVczHIxxux2Hn8B3sM2xXnz5fMMVkOAtcaY/UU3hOJn5dhfcOvBefylmH1C8jMTkfHAZcA1zkXIaXz4ew0axpj9xph8Y4wHeJHiyxpyn5XznT0SeKukfULpcyqvcAnUvsyZPR8o6Ik6GlhW0j9msHDuybwEbDHG/LOEfRoU3GsXkR7YzzRoL0BEJF5EEguWsR16NhbZbT5wvdP7+zwg3avpNdiVeNUfap+VF+//nXHA+8XsswgYJCI1nebWQc66oCUig4G7gWHGmIwS9vHl7zVoFOnLMYLiy+rL92WwuQjYaoxJK25jqH1O5Rbo3mz++sH2FN6O7c34Z2fdNOw/IUAMtjlyB/A10DLQZfbhnHpjmxk3AOucn6HAJGCSs88UYBO25+aXwPmBLncZ59TSKet6p9wFn5X3OQnwjPNZfgukBrrcPp5bPDbwJnutC6nPCnuRsRfIxd67/C22L8dS4DtgCVDL2TcVmOF17ATn/2sHcEOgz8WH89qBvVdb8L9VMCqkEbCgtL/XYPgp4Zxed/5nNmCDb8Oi5+Q8P+37Mhh+ijsnZ/0rBf9HXvuGxOfkjx9NIaqUUkoFsXBp+lZKKaXCkgZqpZRSKohpoFZKKaWCmAZqpZRSKohpoFZKKaWCmAZqpZRSKohpoFZKKaWC2P8DBhpx+pXg+IMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(8, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.plot(history.epoch, history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training and Validation loss')\n",
    "plt.plot(history.epoch, history.history['loss'], label='Training loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.plot(history.epoch, history.history['AUC'], label='Training AUC')\n",
    "plt.plot(history.epoch, history.history['val_AUC'], label='Validation AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40110ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169239</td>\n",
       "      <td>0.941402</td>\n",
       "      <td>0.991336</td>\n",
       "      <td>0.945525</td>\n",
       "      <td>0.937240</td>\n",
       "      <td>0.644424</td>\n",
       "      <td>0.754429</td>\n",
       "      <td>0.917484</td>\n",
       "      <td>0.759841</td>\n",
       "      <td>0.750492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.161587</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>0.946537</td>\n",
       "      <td>0.938554</td>\n",
       "      <td>0.681393</td>\n",
       "      <td>0.752953</td>\n",
       "      <td>0.913572</td>\n",
       "      <td>0.758396</td>\n",
       "      <td>0.744587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.229819</td>\n",
       "      <td>0.919715</td>\n",
       "      <td>0.984677</td>\n",
       "      <td>0.927210</td>\n",
       "      <td>0.911062</td>\n",
       "      <td>0.693260</td>\n",
       "      <td>0.747047</td>\n",
       "      <td>0.907301</td>\n",
       "      <td>0.755937</td>\n",
       "      <td>0.736220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299881</td>\n",
       "      <td>0.895290</td>\n",
       "      <td>0.975204</td>\n",
       "      <td>0.907230</td>\n",
       "      <td>0.883680</td>\n",
       "      <td>0.694842</td>\n",
       "      <td>0.786909</td>\n",
       "      <td>0.911371</td>\n",
       "      <td>0.798077</td>\n",
       "      <td>0.776083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.183464</td>\n",
       "      <td>0.934611</td>\n",
       "      <td>0.990073</td>\n",
       "      <td>0.941437</td>\n",
       "      <td>0.929682</td>\n",
       "      <td>0.697770</td>\n",
       "      <td>0.738189</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.742814</td>\n",
       "      <td>0.724902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.174088</td>\n",
       "      <td>0.937897</td>\n",
       "      <td>0.991028</td>\n",
       "      <td>0.943448</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.708558</td>\n",
       "      <td>0.738189</td>\n",
       "      <td>0.905505</td>\n",
       "      <td>0.745848</td>\n",
       "      <td>0.729331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200277</td>\n",
       "      <td>0.931216</td>\n",
       "      <td>0.988039</td>\n",
       "      <td>0.938320</td>\n",
       "      <td>0.924754</td>\n",
       "      <td>0.720154</td>\n",
       "      <td>0.732776</td>\n",
       "      <td>0.902906</td>\n",
       "      <td>0.739919</td>\n",
       "      <td>0.722441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.195469</td>\n",
       "      <td>0.930997</td>\n",
       "      <td>0.988755</td>\n",
       "      <td>0.935946</td>\n",
       "      <td>0.923439</td>\n",
       "      <td>0.741410</td>\n",
       "      <td>0.720472</td>\n",
       "      <td>0.897358</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>0.713583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.186016</td>\n",
       "      <td>0.934392</td>\n",
       "      <td>0.989797</td>\n",
       "      <td>0.940360</td>\n",
       "      <td>0.927382</td>\n",
       "      <td>0.744242</td>\n",
       "      <td>0.722441</td>\n",
       "      <td>0.898578</td>\n",
       "      <td>0.731954</td>\n",
       "      <td>0.713583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.159448</td>\n",
       "      <td>0.940745</td>\n",
       "      <td>0.992306</td>\n",
       "      <td>0.946179</td>\n",
       "      <td>0.935816</td>\n",
       "      <td>0.751041</td>\n",
       "      <td>0.727362</td>\n",
       "      <td>0.900744</td>\n",
       "      <td>0.731902</td>\n",
       "      <td>0.721457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.258285</td>\n",
       "      <td>0.912158</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>0.922757</td>\n",
       "      <td>0.900219</td>\n",
       "      <td>0.770318</td>\n",
       "      <td>0.754429</td>\n",
       "      <td>0.898530</td>\n",
       "      <td>0.766154</td>\n",
       "      <td>0.735236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.144157</td>\n",
       "      <td>0.949945</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.954144</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.775032</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.726401</td>\n",
       "      <td>0.708169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.173175</td>\n",
       "      <td>0.939211</td>\n",
       "      <td>0.990988</td>\n",
       "      <td>0.945406</td>\n",
       "      <td>0.933187</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>0.706201</td>\n",
       "      <td>0.888687</td>\n",
       "      <td>0.711839</td>\n",
       "      <td>0.695374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.148312</td>\n",
       "      <td>0.944797</td>\n",
       "      <td>0.993334</td>\n",
       "      <td>0.948973</td>\n",
       "      <td>0.941073</td>\n",
       "      <td>0.823551</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.886224</td>\n",
       "      <td>0.704296</td>\n",
       "      <td>0.693898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.156196</td>\n",
       "      <td>0.944250</td>\n",
       "      <td>0.992671</td>\n",
       "      <td>0.948695</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.836439</td>\n",
       "      <td>0.691437</td>\n",
       "      <td>0.879279</td>\n",
       "      <td>0.697990</td>\n",
       "      <td>0.683563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212066</td>\n",
       "      <td>0.925192</td>\n",
       "      <td>0.986821</td>\n",
       "      <td>0.932732</td>\n",
       "      <td>0.917306</td>\n",
       "      <td>0.845522</td>\n",
       "      <td>0.707677</td>\n",
       "      <td>0.885539</td>\n",
       "      <td>0.716223</td>\n",
       "      <td>0.701772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245253</td>\n",
       "      <td>0.913801</td>\n",
       "      <td>0.982616</td>\n",
       "      <td>0.922065</td>\n",
       "      <td>0.905805</td>\n",
       "      <td>0.849171</td>\n",
       "      <td>0.701280</td>\n",
       "      <td>0.878659</td>\n",
       "      <td>0.715235</td>\n",
       "      <td>0.688484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.168148</td>\n",
       "      <td>0.939650</td>\n",
       "      <td>0.991376</td>\n",
       "      <td>0.945700</td>\n",
       "      <td>0.934721</td>\n",
       "      <td>0.883662</td>\n",
       "      <td>0.680118</td>\n",
       "      <td>0.876725</td>\n",
       "      <td>0.688253</td>\n",
       "      <td>0.674705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.151324</td>\n",
       "      <td>0.945126</td>\n",
       "      <td>0.993096</td>\n",
       "      <td>0.948990</td>\n",
       "      <td>0.941402</td>\n",
       "      <td>0.907713</td>\n",
       "      <td>0.677657</td>\n",
       "      <td>0.868365</td>\n",
       "      <td>0.679680</td>\n",
       "      <td>0.668307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.151684</td>\n",
       "      <td>0.945564</td>\n",
       "      <td>0.992977</td>\n",
       "      <td>0.950542</td>\n",
       "      <td>0.940964</td>\n",
       "      <td>0.937267</td>\n",
       "      <td>0.665846</td>\n",
       "      <td>0.863329</td>\n",
       "      <td>0.668329</td>\n",
       "      <td>0.659449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy       AUC  precision    recall  val_loss  \\\n",
       "epoch                                                                \n",
       "10     0.169239  0.941402  0.991336   0.945525  0.937240  0.644424   \n",
       "13     0.161587  0.942935  0.992128   0.946537  0.938554  0.681393   \n",
       "3      0.229819  0.919715  0.984677   0.927210  0.911062  0.693260   \n",
       "0      0.299881  0.895290  0.975204   0.907230  0.883680  0.694842   \n",
       "8      0.183464  0.934611  0.990073   0.941437  0.929682  0.697770   \n",
       "9      0.174088  0.937897  0.991028   0.943448  0.933735  0.708558   \n",
       "6      0.200277  0.931216  0.988039   0.938320  0.924754  0.720154   \n",
       "5      0.195469  0.930997  0.988755   0.935946  0.923439  0.741410   \n",
       "7      0.186016  0.934392  0.989797   0.940360  0.927382  0.744242   \n",
       "14     0.159448  0.940745  0.992306   0.946179  0.935816  0.751041   \n",
       "1      0.258285  0.912158  0.981153   0.922757  0.900219  0.770318   \n",
       "17     0.144157  0.949945  0.993789   0.954144  0.945783  0.775032   \n",
       "11     0.173175  0.939211  0.990988   0.945406  0.933187  0.786460   \n",
       "15     0.148312  0.944797  0.993334   0.948973  0.941073  0.823551   \n",
       "16     0.156196  0.944250  0.992671   0.948695  0.939759  0.836439   \n",
       "4      0.212066  0.925192  0.986821   0.932732  0.917306  0.845522   \n",
       "2      0.245253  0.913801  0.982616   0.922065  0.905805  0.849171   \n",
       "12     0.168148  0.939650  0.991376   0.945700  0.934721  0.883662   \n",
       "18     0.151324  0.945126  0.993096   0.948990  0.941402  0.907713   \n",
       "19     0.151684  0.945564  0.992977   0.950542  0.940964  0.937267   \n",
       "\n",
       "       val_accuracy   val_AUC  val_precision  val_recall  \n",
       "epoch                                                     \n",
       "10         0.754429  0.917484       0.759841    0.750492  \n",
       "13         0.752953  0.913572       0.758396    0.744587  \n",
       "3          0.747047  0.907301       0.755937    0.736220  \n",
       "0          0.786909  0.911371       0.798077    0.776083  \n",
       "8          0.738189  0.907227       0.742814    0.724902  \n",
       "9          0.738189  0.905505       0.745848    0.729331  \n",
       "6          0.732776  0.902906       0.739919    0.722441  \n",
       "5          0.720472  0.897358       0.729743    0.713583  \n",
       "7          0.722441  0.898578       0.731954    0.713583  \n",
       "14         0.727362  0.900744       0.731902    0.721457  \n",
       "1          0.754429  0.898530       0.766154    0.735236  \n",
       "17         0.719488  0.892741       0.726401    0.708169  \n",
       "11         0.706201  0.888687       0.711839    0.695374  \n",
       "15         0.700787  0.886224       0.704296    0.693898  \n",
       "16         0.691437  0.879279       0.697990    0.683563  \n",
       "4          0.707677  0.885539       0.716223    0.701772  \n",
       "2          0.701280  0.878659       0.715235    0.688484  \n",
       "12         0.680118  0.876725       0.688253    0.674705  \n",
       "18         0.677657  0.868365       0.679680    0.668307  \n",
       "19         0.665846  0.863329       0.668329    0.659449  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29750799",
   "metadata": {},
   "source": [
    "#### Fine-tune SqueezeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118ffa6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-04\n",
      "Epoch 20/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9260 - AUC: 0.9885 - precision: 0.9339 - recall: 0.9196\n",
      "Epoch 00020: val_loss did not improve from 0.64442\n",
      "End of epoch 19. Learning rate: 1e-04\n",
      "286/286 [==============================] - 109s 374ms/step - loss: 0.1979 - accuracy: 0.9260 - AUC: 0.9885 - precision: 0.9339 - recall: 0.9196 - val_loss: 0.9306 - val_accuracy: 0.6767 - val_AUC: 0.8638 - val_precision: 0.6828 - val_recall: 0.6663 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 21/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9342 - AUC: 0.9902 - precision: 0.9400 - recall: 0.9280\n",
      "Epoch 00021: val_loss did not improve from 0.64442\n",
      "End of epoch 20. Learning rate: 1e-04\n",
      "286/286 [==============================] - 107s 375ms/step - loss: 0.1810 - accuracy: 0.9342 - AUC: 0.9902 - precision: 0.9400 - recall: 0.9280 - val_loss: 1.1603 - val_accuracy: 0.6368 - val_AUC: 0.8183 - val_precision: 0.6419 - val_recall: 0.6299 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 22/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9412 - AUC: 0.9920 - precision: 0.9463 - recall: 0.9359\n",
      "Epoch 00022: val_loss did not improve from 0.64442\n",
      "End of epoch 21. Learning rate: 1e-04\n",
      "286/286 [==============================] - 112s 391ms/step - loss: 0.1634 - accuracy: 0.9412 - AUC: 0.9920 - precision: 0.9463 - recall: 0.9359 - val_loss: 2.4994 - val_accuracy: 0.3937 - val_AUC: 0.6672 - val_precision: 0.3946 - val_recall: 0.3932 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 23/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.9424 - AUC: 0.9920 - precision: 0.9454 - recall: 0.9370\n",
      "Epoch 00023: val_loss did not improve from 0.64442\n",
      "End of epoch 22. Learning rate: 1e-04\n",
      "286/286 [==============================] - 113s 395ms/step - loss: 0.1624 - accuracy: 0.9424 - AUC: 0.9920 - precision: 0.9454 - recall: 0.9370 - val_loss: 1.0713 - val_accuracy: 0.6762 - val_AUC: 0.8485 - val_precision: 0.6783 - val_recall: 0.6713 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 24/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9433 - AUC: 0.9925 - precision: 0.9480 - recall: 0.9388\n",
      "Epoch 00024: val_loss did not improve from 0.64442\n",
      "End of epoch 23. Learning rate: 1e-04\n",
      "286/286 [==============================] - 115s 403ms/step - loss: 0.1573 - accuracy: 0.9433 - AUC: 0.9925 - precision: 0.9480 - recall: 0.9388 - val_loss: 0.8113 - val_accuracy: 0.7500 - val_AUC: 0.8870 - val_precision: 0.7575 - val_recall: 0.7426 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 25/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9510 - AUC: 0.9941 - precision: 0.9544 - recall: 0.9472\n",
      "Epoch 00025: val_loss did not improve from 0.64442\n",
      "End of epoch 24. Learning rate: 1e-04\n",
      "286/286 [==============================] - 115s 404ms/step - loss: 0.1393 - accuracy: 0.9510 - AUC: 0.9941 - precision: 0.9544 - recall: 0.9472 - val_loss: 1.0149 - val_accuracy: 0.6476 - val_AUC: 0.8502 - val_precision: 0.6525 - val_recall: 0.6442 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 26/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9539 - AUC: 0.9945 - precision: 0.9574 - recall: 0.9506\n",
      "Epoch 00026: val_loss did not improve from 0.64442\n",
      "End of epoch 25. Learning rate: 1e-04\n",
      "286/286 [==============================] - 114s 397ms/step - loss: 0.1338 - accuracy: 0.9539 - AUC: 0.9945 - precision: 0.9574 - recall: 0.9506 - val_loss: 0.7902 - val_accuracy: 0.7785 - val_AUC: 0.9092 - val_precision: 0.7840 - val_recall: 0.7717 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 27/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9584 - AUC: 0.9953 - precision: 0.9610 - recall: 0.9556\n",
      "Epoch 00027: val_loss did not improve from 0.64442\n",
      "End of epoch 26. Learning rate: 1e-04\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.1178 - accuracy: 0.9584 - AUC: 0.9953 - precision: 0.9610 - recall: 0.9556 - val_loss: 1.2058 - val_accuracy: 0.6117 - val_AUC: 0.8262 - val_precision: 0.6129 - val_recall: 0.6063 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 28/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9517 - AUC: 0.9940 - precision: 0.9547 - recall: 0.9484\n",
      "Epoch 00028: val_loss did not improve from 0.64442\n",
      "End of epoch 27. Learning rate: 1e-04\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.1374 - accuracy: 0.9517 - AUC: 0.9940 - precision: 0.9547 - recall: 0.9484 - val_loss: 1.0145 - val_accuracy: 0.6604 - val_AUC: 0.8379 - val_precision: 0.6657 - val_recall: 0.6496 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 29/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9600 - AUC: 0.9960 - precision: 0.9620 - recall: 0.9578\n",
      "Epoch 00029: val_loss did not improve from 0.64442\n",
      "End of epoch 28. Learning rate: 1e-04\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 0.1087 - accuracy: 0.9600 - AUC: 0.9960 - precision: 0.9620 - recall: 0.9578 - val_loss: 1.2216 - val_accuracy: 0.6142 - val_AUC: 0.8234 - val_precision: 0.6197 - val_recall: 0.6063 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 30/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9541 - AUC: 0.9944 - precision: 0.9581 - recall: 0.9512\n",
      "Epoch 00030: val_loss did not improve from 0.64442\n",
      "End of epoch 29. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 405ms/step - loss: 0.1298 - accuracy: 0.9541 - AUC: 0.9944 - precision: 0.9581 - recall: 0.9512 - val_loss: 0.8701 - val_accuracy: 0.7549 - val_AUC: 0.8824 - val_precision: 0.7692 - val_recall: 0.7446 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 31/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9587 - AUC: 0.9955 - precision: 0.9620 - recall: 0.9560\n",
      "Epoch 00031: val_loss did not improve from 0.64442\n",
      "End of epoch 30. Learning rate: 1e-04\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 0.1170 - accuracy: 0.9587 - AUC: 0.9955 - precision: 0.9620 - recall: 0.9560 - val_loss: 0.7961 - val_accuracy: 0.7859 - val_AUC: 0.9040 - val_precision: 0.7933 - val_recall: 0.7781 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 32/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9632 - AUC: 0.9964 - precision: 0.9663 - recall: 0.9607\n",
      "Epoch 00032: val_loss did not improve from 0.64442\n",
      "End of epoch 31. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 406ms/step - loss: 0.1049 - accuracy: 0.9632 - AUC: 0.9964 - precision: 0.9663 - recall: 0.9607 - val_loss: 1.0480 - val_accuracy: 0.6545 - val_AUC: 0.8423 - val_precision: 0.6559 - val_recall: 0.6481 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 33/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9639 - AUC: 0.9962 - precision: 0.9655 - recall: 0.9619\n",
      "Epoch 00033: val_loss did not improve from 0.64442\n",
      "End of epoch 32. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 404ms/step - loss: 0.1033 - accuracy: 0.9639 - AUC: 0.9962 - precision: 0.9655 - recall: 0.9619 - val_loss: 0.8507 - val_accuracy: 0.7726 - val_AUC: 0.9123 - val_precision: 0.7805 - val_recall: 0.7682 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 34/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9599 - AUC: 0.9962 - precision: 0.9621 - recall: 0.9574\n",
      "Epoch 00034: val_loss did not improve from 0.64442\n",
      "End of epoch 33. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 404ms/step - loss: 0.1106 - accuracy: 0.9599 - AUC: 0.9962 - precision: 0.9621 - recall: 0.9574 - val_loss: 1.0971 - val_accuracy: 0.7279 - val_AUC: 0.8721 - val_precision: 0.7333 - val_recall: 0.7239 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 35/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9647 - AUC: 0.9969 - precision: 0.9663 - recall: 0.9623\n",
      "Epoch 00035: val_loss improved from 0.64442 to 0.46251, saving model to ./weights/squeezenet_hef.hdf5\n",
      "End of epoch 34. Learning rate: 1e-04\n",
      "286/286 [==============================] - 115s 403ms/step - loss: 0.0983 - accuracy: 0.9647 - AUC: 0.9969 - precision: 0.9663 - recall: 0.9623 - val_loss: 0.4625 - val_accuracy: 0.8642 - val_AUC: 0.9599 - val_precision: 0.8699 - val_recall: 0.8622 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 36/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9613 - AUC: 0.9961 - precision: 0.9630 - recall: 0.9594\n",
      "Epoch 00036: val_loss did not improve from 0.46251\n",
      "End of epoch 35. Learning rate: 1e-04\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 0.1057 - accuracy: 0.9613 - AUC: 0.9961 - precision: 0.9630 - recall: 0.9594 - val_loss: 0.5753 - val_accuracy: 0.8228 - val_AUC: 0.9402 - val_precision: 0.8255 - val_recall: 0.8194 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 37/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9673 - AUC: 0.9972 - precision: 0.9688 - recall: 0.9657\n",
      "Epoch 00037: val_loss did not improve from 0.46251\n",
      "End of epoch 36. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 404ms/step - loss: 0.0907 - accuracy: 0.9673 - AUC: 0.9972 - precision: 0.9688 - recall: 0.9657 - val_loss: 1.4341 - val_accuracy: 0.6009 - val_AUC: 0.7867 - val_precision: 0.6013 - val_recall: 0.5960 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 38/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9667 - AUC: 0.9969 - precision: 0.9680 - recall: 0.9647\n",
      "Epoch 00038: val_loss did not improve from 0.46251\n",
      "End of epoch 37. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 405ms/step - loss: 0.0923 - accuracy: 0.9667 - AUC: 0.9969 - precision: 0.9680 - recall: 0.9647 - val_loss: 0.9962 - val_accuracy: 0.6929 - val_AUC: 0.8586 - val_precision: 0.6962 - val_recall: 0.6845 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 39/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9648 - AUC: 0.9970 - precision: 0.9677 - recall: 0.9627\n",
      "Epoch 00039: val_loss did not improve from 0.46251\n",
      "End of epoch 38. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 405ms/step - loss: 0.0944 - accuracy: 0.9648 - AUC: 0.9970 - precision: 0.9677 - recall: 0.9627 - val_loss: 0.8576 - val_accuracy: 0.7840 - val_AUC: 0.9029 - val_precision: 0.7900 - val_recall: 0.7776 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 40/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9655 - AUC: 0.9969 - precision: 0.9673 - recall: 0.9632\n",
      "Epoch 00040: val_loss did not improve from 0.46251\n",
      "End of epoch 39. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 405ms/step - loss: 0.0946 - accuracy: 0.9655 - AUC: 0.9969 - precision: 0.9673 - recall: 0.9632 - val_loss: 0.7607 - val_accuracy: 0.7746 - val_AUC: 0.9102 - val_precision: 0.7795 - val_recall: 0.7726 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 41/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9682 - AUC: 0.9975 - precision: 0.9701 - recall: 0.9670\n",
      "Epoch 00041: val_loss did not improve from 0.46251\n",
      "End of epoch 40. Learning rate: 1e-04\n",
      "286/286 [==============================] - 115s 401ms/step - loss: 0.0874 - accuracy: 0.9682 - AUC: 0.9975 - precision: 0.9701 - recall: 0.9670 - val_loss: 1.3126 - val_accuracy: 0.7136 - val_AUC: 0.8493 - val_precision: 0.7181 - val_recall: 0.7096 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 42/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9727 - AUC: 0.9979 - precision: 0.9756 - recall: 0.9716\n",
      "Epoch 00042: val_loss did not improve from 0.46251\n",
      "End of epoch 41. Learning rate: 1e-04\n",
      "286/286 [==============================] - 115s 403ms/step - loss: 0.0764 - accuracy: 0.9727 - AUC: 0.9979 - precision: 0.9756 - recall: 0.9716 - val_loss: 1.1205 - val_accuracy: 0.6688 - val_AUC: 0.8622 - val_precision: 0.6730 - val_recall: 0.6663 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 43/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9701 - AUC: 0.9977 - precision: 0.9724 - recall: 0.9692\n",
      "Epoch 00043: val_loss improved from 0.46251 to 0.45008, saving model to ./weights/squeezenet_hef.hdf5\n",
      "End of epoch 42. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 404ms/step - loss: 0.0807 - accuracy: 0.9701 - AUC: 0.9977 - precision: 0.9724 - recall: 0.9692 - val_loss: 0.4501 - val_accuracy: 0.8780 - val_AUC: 0.9643 - val_precision: 0.8800 - val_recall: 0.8770 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 44/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9708 - AUC: 0.9974 - precision: 0.9721 - recall: 0.9697\n",
      "Epoch 00044: val_loss did not improve from 0.45008\n",
      "End of epoch 43. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 404ms/step - loss: 0.0831 - accuracy: 0.9708 - AUC: 0.9974 - precision: 0.9721 - recall: 0.9697 - val_loss: 0.5088 - val_accuracy: 0.8297 - val_AUC: 0.9426 - val_precision: 0.8347 - val_recall: 0.8223 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 45/45\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9756 - AUC: 0.9981 - precision: 0.9771 - recall: 0.9742\n",
      "Epoch 00045: val_loss did not improve from 0.45008\n",
      "End of epoch 44. Learning rate: 1e-04\n",
      "286/286 [==============================] - 117s 409ms/step - loss: 0.0712 - accuracy: 0.9756 - AUC: 0.9981 - precision: 0.9771 - recall: 0.9742 - val_loss: 1.2900 - val_accuracy: 0.6752 - val_AUC: 0.8265 - val_precision: 0.6801 - val_recall: 0.6737 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "squeezenet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")\n",
    "\n",
    "history_finetune = squeezenet_model.fit(train_generator,\n",
    "                            epochs=45,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            initial_epoch=history.epoch[-1],\n",
    "                            callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df013f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.080696</td>\n",
       "      <td>0.970099</td>\n",
       "      <td>0.997724</td>\n",
       "      <td>0.972418</td>\n",
       "      <td>0.969222</td>\n",
       "      <td>0.450076</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.964266</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.876969</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.964732</td>\n",
       "      <td>0.996871</td>\n",
       "      <td>0.966344</td>\n",
       "      <td>0.962322</td>\n",
       "      <td>0.462507</td>\n",
       "      <td>0.864173</td>\n",
       "      <td>0.959944</td>\n",
       "      <td>0.869911</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.083117</td>\n",
       "      <td>0.970756</td>\n",
       "      <td>0.997366</td>\n",
       "      <td>0.972109</td>\n",
       "      <td>0.969660</td>\n",
       "      <td>0.508777</td>\n",
       "      <td>0.829724</td>\n",
       "      <td>0.942600</td>\n",
       "      <td>0.834665</td>\n",
       "      <td>0.822343</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.105724</td>\n",
       "      <td>0.961336</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.962951</td>\n",
       "      <td>0.959365</td>\n",
       "      <td>0.575319</td>\n",
       "      <td>0.822835</td>\n",
       "      <td>0.940152</td>\n",
       "      <td>0.825483</td>\n",
       "      <td>0.819390</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.094635</td>\n",
       "      <td>0.965498</td>\n",
       "      <td>0.996855</td>\n",
       "      <td>0.967330</td>\n",
       "      <td>0.963198</td>\n",
       "      <td>0.760695</td>\n",
       "      <td>0.774606</td>\n",
       "      <td>0.910189</td>\n",
       "      <td>0.779543</td>\n",
       "      <td>0.772638</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.133816</td>\n",
       "      <td>0.953888</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>0.957419</td>\n",
       "      <td>0.950602</td>\n",
       "      <td>0.790240</td>\n",
       "      <td>0.778543</td>\n",
       "      <td>0.909151</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.117012</td>\n",
       "      <td>0.958708</td>\n",
       "      <td>0.995524</td>\n",
       "      <td>0.961975</td>\n",
       "      <td>0.955969</td>\n",
       "      <td>0.796095</td>\n",
       "      <td>0.785925</td>\n",
       "      <td>0.904029</td>\n",
       "      <td>0.793276</td>\n",
       "      <td>0.778051</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157348</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>0.992468</td>\n",
       "      <td>0.948015</td>\n",
       "      <td>0.938773</td>\n",
       "      <td>0.811325</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.887035</td>\n",
       "      <td>0.757530</td>\n",
       "      <td>0.742618</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.103275</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.965479</td>\n",
       "      <td>0.961884</td>\n",
       "      <td>0.850735</td>\n",
       "      <td>0.772638</td>\n",
       "      <td>0.912268</td>\n",
       "      <td>0.780500</td>\n",
       "      <td>0.768209</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.094435</td>\n",
       "      <td>0.964841</td>\n",
       "      <td>0.996971</td>\n",
       "      <td>0.967738</td>\n",
       "      <td>0.962651</td>\n",
       "      <td>0.857618</td>\n",
       "      <td>0.783957</td>\n",
       "      <td>0.902945</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.777559</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.129845</td>\n",
       "      <td>0.954107</td>\n",
       "      <td>0.994419</td>\n",
       "      <td>0.958076</td>\n",
       "      <td>0.951150</td>\n",
       "      <td>0.870057</td>\n",
       "      <td>0.754921</td>\n",
       "      <td>0.882385</td>\n",
       "      <td>0.769192</td>\n",
       "      <td>0.744587</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.197905</td>\n",
       "      <td>0.925958</td>\n",
       "      <td>0.988497</td>\n",
       "      <td>0.933927</td>\n",
       "      <td>0.919606</td>\n",
       "      <td>0.930598</td>\n",
       "      <td>0.676673</td>\n",
       "      <td>0.863768</td>\n",
       "      <td>0.682804</td>\n",
       "      <td>0.666339</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.092258</td>\n",
       "      <td>0.966703</td>\n",
       "      <td>0.996901</td>\n",
       "      <td>0.968018</td>\n",
       "      <td>0.964732</td>\n",
       "      <td>0.996247</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.696196</td>\n",
       "      <td>0.684547</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.137367</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>0.994004</td>\n",
       "      <td>0.954686</td>\n",
       "      <td>0.948412</td>\n",
       "      <td>1.014476</td>\n",
       "      <td>0.660433</td>\n",
       "      <td>0.837872</td>\n",
       "      <td>0.665658</td>\n",
       "      <td>0.649606</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.139340</td>\n",
       "      <td>0.951041</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>0.954420</td>\n",
       "      <td>0.947207</td>\n",
       "      <td>1.014868</td>\n",
       "      <td>0.647638</td>\n",
       "      <td>0.850160</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>0.644193</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.104947</td>\n",
       "      <td>0.963198</td>\n",
       "      <td>0.996413</td>\n",
       "      <td>0.966288</td>\n",
       "      <td>0.960679</td>\n",
       "      <td>1.047961</td>\n",
       "      <td>0.654528</td>\n",
       "      <td>0.842303</td>\n",
       "      <td>0.655877</td>\n",
       "      <td>0.648130</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.942388</td>\n",
       "      <td>0.991955</td>\n",
       "      <td>0.945408</td>\n",
       "      <td>0.937021</td>\n",
       "      <td>1.071324</td>\n",
       "      <td>0.676181</td>\n",
       "      <td>0.848450</td>\n",
       "      <td>0.678270</td>\n",
       "      <td>0.671260</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.110585</td>\n",
       "      <td>0.959912</td>\n",
       "      <td>0.996241</td>\n",
       "      <td>0.962135</td>\n",
       "      <td>0.957393</td>\n",
       "      <td>1.097116</td>\n",
       "      <td>0.727854</td>\n",
       "      <td>0.872129</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>0.723917</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.076433</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.997883</td>\n",
       "      <td>0.975586</td>\n",
       "      <td>0.971632</td>\n",
       "      <td>1.120470</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>0.862249</td>\n",
       "      <td>0.672962</td>\n",
       "      <td>0.666339</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.934173</td>\n",
       "      <td>0.990175</td>\n",
       "      <td>0.939982</td>\n",
       "      <td>0.928039</td>\n",
       "      <td>1.160252</td>\n",
       "      <td>0.636811</td>\n",
       "      <td>0.818300</td>\n",
       "      <td>0.641926</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117848</td>\n",
       "      <td>0.958379</td>\n",
       "      <td>0.995346</td>\n",
       "      <td>0.961009</td>\n",
       "      <td>0.955641</td>\n",
       "      <td>1.205838</td>\n",
       "      <td>0.611713</td>\n",
       "      <td>0.826233</td>\n",
       "      <td>0.612935</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.108718</td>\n",
       "      <td>0.960022</td>\n",
       "      <td>0.996023</td>\n",
       "      <td>0.962046</td>\n",
       "      <td>0.957831</td>\n",
       "      <td>1.221583</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.823364</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.071180</td>\n",
       "      <td>0.975575</td>\n",
       "      <td>0.998107</td>\n",
       "      <td>0.977148</td>\n",
       "      <td>0.974151</td>\n",
       "      <td>1.290009</td>\n",
       "      <td>0.675197</td>\n",
       "      <td>0.826469</td>\n",
       "      <td>0.680079</td>\n",
       "      <td>0.673720</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.087369</td>\n",
       "      <td>0.968237</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.970113</td>\n",
       "      <td>0.967032</td>\n",
       "      <td>1.312633</td>\n",
       "      <td>0.713583</td>\n",
       "      <td>0.849302</td>\n",
       "      <td>0.718127</td>\n",
       "      <td>0.709646</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.090662</td>\n",
       "      <td>0.967251</td>\n",
       "      <td>0.997250</td>\n",
       "      <td>0.968795</td>\n",
       "      <td>0.965717</td>\n",
       "      <td>1.434106</td>\n",
       "      <td>0.600886</td>\n",
       "      <td>0.786660</td>\n",
       "      <td>0.601291</td>\n",
       "      <td>0.595965</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163350</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>0.991998</td>\n",
       "      <td>0.946290</td>\n",
       "      <td>0.935926</td>\n",
       "      <td>2.499409</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.667161</td>\n",
       "      <td>0.394568</td>\n",
       "      <td>0.393209</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy       AUC  precision    recall  val_loss  \\\n",
       "epoch                                                                \n",
       "23     0.080696  0.970099  0.997724   0.972418  0.969222  0.450076   \n",
       "15     0.098312  0.964732  0.996871   0.966344  0.962322  0.462507   \n",
       "24     0.083117  0.970756  0.997366   0.972109  0.969660  0.508777   \n",
       "16     0.105724  0.961336  0.996051   0.962951  0.959365  0.575319   \n",
       "20     0.094635  0.965498  0.996855   0.967330  0.963198  0.760695   \n",
       "6      0.133816  0.953888  0.994522   0.957419  0.950602  0.790240   \n",
       "11     0.117012  0.958708  0.995524   0.961975  0.955969  0.796095   \n",
       "4      0.157348  0.943264  0.992468   0.948015  0.938773  0.811325   \n",
       "13     0.103275  0.963855  0.996205   0.965479  0.961884  0.850735   \n",
       "19     0.094435  0.964841  0.996971   0.967738  0.962651  0.857618   \n",
       "10     0.129845  0.954107  0.994419   0.958076  0.951150  0.870057   \n",
       "0      0.197905  0.925958  0.988497   0.933927  0.919606  0.930598   \n",
       "18     0.092258  0.966703  0.996901   0.968018  0.964732  0.996247   \n",
       "8      0.137367  0.951698  0.994004   0.954686  0.948412  1.014476   \n",
       "5      0.139340  0.951041  0.994141   0.954420  0.947207  1.014868   \n",
       "12     0.104947  0.963198  0.996413   0.966288  0.960679  1.047961   \n",
       "3      0.162442  0.942388  0.991955   0.945408  0.937021  1.071324   \n",
       "14     0.110585  0.959912  0.996241   0.962135  0.957393  1.097116   \n",
       "22     0.076433  0.972727  0.997883   0.975586  0.971632  1.120470   \n",
       "1      0.180952  0.934173  0.990175   0.939982  0.928039  1.160252   \n",
       "7      0.117848  0.958379  0.995346   0.961009  0.955641  1.205838   \n",
       "9      0.108718  0.960022  0.996023   0.962046  0.957831  1.221583   \n",
       "25     0.071180  0.975575  0.998107   0.977148  0.974151  1.290009   \n",
       "21     0.087369  0.968237  0.997500   0.970113  0.967032  1.312633   \n",
       "17     0.090662  0.967251  0.997250   0.968795  0.965717  1.434106   \n",
       "2      0.163350  0.941183  0.991998   0.946290  0.935926  2.499409   \n",
       "\n",
       "       val_accuracy   val_AUC  val_precision  val_recall      lr  \n",
       "epoch                                                             \n",
       "23         0.877953  0.964266       0.880000    0.876969  0.0001  \n",
       "15         0.864173  0.959944       0.869911    0.862205  0.0001  \n",
       "24         0.829724  0.942600       0.834665    0.822343  0.0001  \n",
       "16         0.822835  0.940152       0.825483    0.819390  0.0001  \n",
       "20         0.774606  0.910189       0.779543    0.772638  0.0001  \n",
       "6          0.778543  0.909151       0.784000    0.771654  0.0001  \n",
       "11         0.785925  0.904029       0.793276    0.778051  0.0001  \n",
       "4          0.750000  0.887035       0.757530    0.742618  0.0001  \n",
       "13         0.772638  0.912268       0.780500    0.768209  0.0001  \n",
       "19         0.783957  0.902945       0.790000    0.777559  0.0001  \n",
       "10         0.754921  0.882385       0.769192    0.744587  0.0001  \n",
       "0          0.676673  0.863768       0.682804    0.666339  0.0001  \n",
       "18         0.692913  0.858600       0.696196    0.684547  0.0001  \n",
       "8          0.660433  0.837872       0.665658    0.649606  0.0001  \n",
       "5          0.647638  0.850160       0.652542    0.644193  0.0001  \n",
       "12         0.654528  0.842303       0.655877    0.648130  0.0001  \n",
       "3          0.676181  0.848450       0.678270    0.671260  0.0001  \n",
       "14         0.727854  0.872129       0.733300    0.723917  0.0001  \n",
       "22         0.668799  0.862249       0.672962    0.666339  0.0001  \n",
       "1          0.636811  0.818300       0.641926    0.629921  0.0001  \n",
       "7          0.611713  0.826233       0.612935    0.606299  0.0001  \n",
       "9          0.614173  0.823364       0.619718    0.606299  0.0001  \n",
       "25         0.675197  0.826469       0.680079    0.673720  0.0001  \n",
       "21         0.713583  0.849302       0.718127    0.709646  0.0001  \n",
       "17         0.600886  0.786660       0.601291    0.595965  0.0001  \n",
       "2          0.393701  0.667161       0.394568    0.393209  0.0001  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history_finetune.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29808ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-04\n",
      "Epoch 45/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9716 - AUC: 0.9979 - precision: 0.9737 - recall: 0.9702\n",
      "Epoch 00045: val_loss did not improve from 0.45008\n",
      "End of epoch 44. Learning rate: 1e-04\n",
      "286/286 [==============================] - 127s 442ms/step - loss: 0.0781 - accuracy: 0.9716 - AUC: 0.9979 - precision: 0.9737 - recall: 0.9702 - val_loss: 0.6750 - val_accuracy: 0.7835 - val_AUC: 0.9226 - val_precision: 0.7879 - val_recall: 0.7805 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 46/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9710 - AUC: 0.9977 - precision: 0.9726 - recall: 0.9691\n",
      "Epoch 00046: val_loss did not improve from 0.45008\n",
      "End of epoch 45. Learning rate: 1e-04\n",
      "286/286 [==============================] - 123s 429ms/step - loss: 0.0778 - accuracy: 0.9710 - AUC: 0.9977 - precision: 0.9726 - recall: 0.9691 - val_loss: 0.6622 - val_accuracy: 0.8258 - val_AUC: 0.9362 - val_precision: 0.8299 - val_recall: 0.8189 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 47/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9742 - AUC: 0.9982 - precision: 0.9754 - recall: 0.9721\n",
      "Epoch 00047: val_loss did not improve from 0.45008\n",
      "End of epoch 46. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 405ms/step - loss: 0.0710 - accuracy: 0.9742 - AUC: 0.9982 - precision: 0.9754 - recall: 0.9721 - val_loss: 1.7288 - val_accuracy: 0.6107 - val_AUC: 0.7879 - val_precision: 0.6121 - val_recall: 0.6073 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 48/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9763 - AUC: 0.9983 - precision: 0.9776 - recall: 0.9755\n",
      "Epoch 00048: val_loss did not improve from 0.45008\n",
      "End of epoch 47. Learning rate: 1e-04\n",
      "286/286 [==============================] - 117s 408ms/step - loss: 0.0672 - accuracy: 0.9763 - AUC: 0.9983 - precision: 0.9776 - recall: 0.9755 - val_loss: 0.5581 - val_accuracy: 0.8248 - val_AUC: 0.9441 - val_precision: 0.8306 - val_recall: 0.8179 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 49/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9732 - AUC: 0.9977 - precision: 0.9748 - recall: 0.9717\n",
      "Epoch 00049: val_loss did not improve from 0.45008\n",
      "End of epoch 48. Learning rate: 1e-04\n",
      "286/286 [==============================] - 116s 407ms/step - loss: 0.0763 - accuracy: 0.9732 - AUC: 0.9977 - precision: 0.9748 - recall: 0.9717 - val_loss: 1.7480 - val_accuracy: 0.5827 - val_AUC: 0.7709 - val_precision: 0.5846 - val_recall: 0.5782 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 50/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9727 - AUC: 0.9978 - precision: 0.9738 - recall: 0.9721\n",
      "Epoch 00050: val_loss did not improve from 0.45008\n",
      "End of epoch 49. Learning rate: 1e-04\n",
      "286/286 [==============================] - 118s 411ms/step - loss: 0.0778 - accuracy: 0.9727 - AUC: 0.9978 - precision: 0.9738 - recall: 0.9721 - val_loss: 1.0000 - val_accuracy: 0.7057 - val_AUC: 0.8732 - val_precision: 0.7088 - val_recall: 0.7042 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 51/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9773 - AUC: 0.9984 - precision: 0.9784 - recall: 0.9762\n",
      "Epoch 00051: val_loss did not improve from 0.45008\n",
      "End of epoch 50. Learning rate: 1e-04\n",
      "286/286 [==============================] - 117s 407ms/step - loss: 0.0627 - accuracy: 0.9773 - AUC: 0.9984 - precision: 0.9784 - recall: 0.9762 - val_loss: 2.0879 - val_accuracy: 0.5871 - val_AUC: 0.7427 - val_precision: 0.5879 - val_recall: 0.5842 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 52/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9729 - AUC: 0.9981 - precision: 0.9741 - recall: 0.9710\n",
      "Epoch 00052: val_loss did not improve from 0.45008\n",
      "End of epoch 51. Learning rate: 1e-04\n",
      "286/286 [==============================] - 117s 408ms/step - loss: 0.0739 - accuracy: 0.9729 - AUC: 0.9981 - precision: 0.9741 - recall: 0.9710 - val_loss: 0.5388 - val_accuracy: 0.8489 - val_AUC: 0.9503 - val_precision: 0.8515 - val_recall: 0.8465 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 53/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9765 - AUC: 0.9979 - precision: 0.9779 - recall: 0.9749\n",
      "Epoch 00053: val_loss did not improve from 0.45008\n",
      "End of epoch 52. Learning rate: 1e-04\n",
      "286/286 [==============================] - 117s 408ms/step - loss: 0.0677 - accuracy: 0.9765 - AUC: 0.9979 - precision: 0.9779 - recall: 0.9749 - val_loss: 0.6870 - val_accuracy: 0.8376 - val_AUC: 0.9406 - val_precision: 0.8448 - val_recall: 0.8332 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 54/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9780 - AUC: 0.9984 - precision: 0.9786 - recall: 0.9770\n",
      "Epoch 00054: val_loss did not improve from 0.45008\n",
      "End of epoch 53. Learning rate: 1e-04\n",
      "286/286 [==============================] - 118s 411ms/step - loss: 0.0646 - accuracy: 0.9780 - AUC: 0.9984 - precision: 0.9786 - recall: 0.9770 - val_loss: 1.2017 - val_accuracy: 0.7421 - val_AUC: 0.8748 - val_precision: 0.7490 - val_recall: 0.7357 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 55/55\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9747 - AUC: 0.9981 - precision: 0.9764 - recall: 0.9736\n",
      "Epoch 00055: val_loss did not improve from 0.45008\n",
      "End of epoch 54. Learning rate: 1e-04\n",
      "286/286 [==============================] - 117s 408ms/step - loss: 0.0702 - accuracy: 0.9747 - AUC: 0.9981 - precision: 0.9764 - recall: 0.9736 - val_loss: 0.9147 - val_accuracy: 0.7653 - val_AUC: 0.9009 - val_precision: 0.7655 - val_recall: 0.7613 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history_finetune2 = squeezenet_model.fit(train_generator,\n",
    "                            epochs=55,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            initial_epoch=history_finetune.epoch[-1],\n",
    "                            callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd348f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history_finetune2.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b09d1",
   "metadata": {},
   "source": [
    "#### Test Image Generation for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.keras.models.load_model('./weights/squeezenet_hef.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45f3bf",
   "metadata": {},
   "source": [
    "#### Shenzhen Dataset Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_FOLDER = '/home/TBX11K/HEF/test/Shenzhen'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode=CLASS_MODE)\n",
    "\n",
    "res = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = np.argmax(res, axis=1)\n",
    "report = classification_report(test_generator.classes, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385799da",
   "metadata": {},
   "source": [
    "#### Montgomery Countery Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_FOLDER = '/home/TBX11K/HEF/test/Montgomery'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode=CLASS_MODE)\n",
    "\n",
    "res = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f492dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = np.argmax(res, axis=1)\n",
    "report = classification_report(test_generator.classes, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01495852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
