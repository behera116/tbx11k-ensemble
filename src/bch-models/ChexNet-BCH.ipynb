{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e5dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import cv2\n",
    "import os\n",
    "from skimage import exposure\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seaborn import heatmap\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from ast import literal_eval\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a32f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "TARGET_SIZE = (224,224)\n",
    "INPUT_SHAPE = (224,224,3)\n",
    "EPOCHS = 60\n",
    "\n",
    "CLASS_MODE = 'categorical'\n",
    "LOSS_METRIC = 'categorical_crossentropy'\n",
    "\n",
    "MODEL_SAVED_FILE = './weights/chexnet_3channel_scratch_d4.hdf5'\n",
    "TRAIN_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/train'\n",
    "VALIDATION_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/val'\n",
    "\n",
    "SEED = 42\n",
    "IMAGE_SHAPE = (224,224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1774e026",
   "metadata": {},
   "source": [
    "#### Keras Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02125e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs-\"+dt.datetime.now().strftime(\"%m%d%Y%H%M%S\"),\n",
    "                            histogram_freq=0,\n",
    "                            write_graph=False,\n",
    "                            update_freq='epoch')\n",
    "\n",
    "def epoch_end(epoch, logs):\n",
    "    message = \"End of epoch \"+str(epoch)+\". Learning rate: \"+str(K.eval(chexnet_model.optimizer.lr))\n",
    "    os.system('echo '+message)\n",
    "\n",
    "def epoch_begin(epoch, logs):\n",
    "    print(\"Learning rate: \", K.eval(chexnet_model.optimizer.lr))\n",
    "    \n",
    "def train_begin(logs):\n",
    "    os.system(\"echo Beginning training\")\n",
    "    \n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVED_FILE,\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             save_weights_only=False,\n",
    "                             save_freq='epoch')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta = 1e-4, \n",
    "                          patience=30,\n",
    "                          verbose=1,\n",
    "                          mode='min',\n",
    "                          baseline=None,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                             factor=np.sqrt(.1),\n",
    "                             patience=10,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             min_delta=.0001,\n",
    "                             cooldown=0,\n",
    "                             min_lr=0.0000001)\n",
    "\n",
    "lambdacb = LambdaCallback(on_epoch_begin=epoch_begin,\n",
    "                          on_epoch_end=epoch_end,\n",
    "                          on_batch_begin=None,\n",
    "                          on_batch_end=None,\n",
    "                          on_train_begin=train_begin,\n",
    "                          on_train_end=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473aadb3",
   "metadata": {},
   "source": [
    "#### Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa0b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7566 images belonging to 3 classes.\n",
      "Found 1551 images belonging to 3 classes.\n",
      "train class indices: {'health': 0, 'sick': 1, 'tb': 2}\n",
      "class weights: {0: 0.7479240806642942, 1: 0.8135483870967742, 2: 2.3053016453382082}\n",
      "samples for train class labels: dict_items([(0, 3372), (1, 3100), (2, 1094)])\n",
      "\n",
      "\n",
      "validation class indices: {'health': 0, 'sick': 1, 'tb': 2}\n",
      "samples for validation class labels: dict_items([(0, 702), (1, 600), (2, 249)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "#train data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.3,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=10,\n",
    "    brightness_range = [0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        class_mode= CLASS_MODE)\n",
    "\n",
    "#validation imagedatagenerator\n",
    "test_datagen = ImageDataGenerator()\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        VALIDATION_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        class_mode=CLASS_MODE)\n",
    "from collections import Counter\n",
    "print('train class indices:',train_generator.class_indices)\n",
    "counter = Counter(train_generator.classes)\n",
    "\n",
    "total_train = 0\n",
    "num_classes = 0\n",
    "for cls_idx,item in counter.items():\n",
    "    total_train += item\n",
    "    num_classes += 1\n",
    "\n",
    "class_weights = {}\n",
    "for cls_idx,weight in counter.items():\n",
    "    cls_weight = total_train/(weight*num_classes)\n",
    "    class_weights[cls_idx] = cls_weight\n",
    "\n",
    "print('class weights:',class_weights)\n",
    "print('samples for train class labels:',counter.items())\n",
    "print('\\n')\n",
    "\n",
    "print('validation class indices:',validation_generator.class_indices)\n",
    "counter = Counter(validation_generator.classes)\n",
    "print('samples for validation class labels:',counter.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0080b0",
   "metadata": {},
   "source": [
    "### ChexNet Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbf0476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 05:30:14.706669: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-08-27 05:30:14.706766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11261 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:1d:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['relu[0][0]']                   \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            3075        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,040,579\n",
      "Trainable params: 6,956,931\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CHEXNET_WEIGHTS_PATH ='/home/ChexNet/pretrained/chexnet-pretrained-weights.h5'\n",
    "base_model = DenseNet121(weights=None,include_top=False,input_shape=INPUT_SHAPE)\n",
    "out = Dense(14, activation='sigmoid')(base_model.output)\n",
    "base_model = Model(inputs=base_model.input, outputs=out) \n",
    "base_model.load_weights(CHEXNET_WEIGHTS_PATH)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=True\n",
    "\n",
    "chexnet_extract = base_model.layers[-2].output\n",
    "chexnet_extract = GlobalAveragePooling2D()(chexnet_extract)\n",
    "chexnet_extract = Dropout(0.5)(chexnet_extract)\n",
    "output = Dense(3, activation='softmax')(chexnet_extract)\n",
    "\n",
    "chexnet_model = Model(base_model.input, output)\n",
    "chexnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b815dad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  0.001\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 05:30:32.238799: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7906 - AUC: 0.9302 - precision: 0.8422 - recall: 0.7322\n",
      "Epoch 00001: val_loss improved from inf to 0.86866, saving model to ./weights/chexnet_3channel_scratch_d4.hdf5\n",
      "End of epoch 0. Learning rate: 0.001\n",
      "237/237 [==============================] - 122s 451ms/step - loss: 0.5238 - accuracy: 0.7906 - AUC: 0.9302 - precision: 0.8422 - recall: 0.7322 - val_loss: 0.8687 - val_accuracy: 0.6660 - val_AUC: 0.8235 - val_precision: 0.7010 - val_recall: 0.6151 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.9100 - AUC: 0.9818 - precision: 0.9173 - recall: 0.9015\n",
      "Epoch 00002: val_loss did not improve from 0.86866\n",
      "End of epoch 1. Learning rate: 0.001\n",
      "237/237 [==============================] - 106s 445ms/step - loss: 0.2640 - accuracy: 0.9100 - AUC: 0.9818 - precision: 0.9173 - recall: 0.9015 - val_loss: 0.9716 - val_accuracy: 0.6093 - val_AUC: 0.8450 - val_precision: 0.6106 - val_recall: 0.6015 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.9311 - AUC: 0.9882 - precision: 0.9358 - recall: 0.9268\n",
      "Epoch 00003: val_loss did not improve from 0.86866\n",
      "End of epoch 2. Learning rate: 0.001\n",
      "237/237 [==============================] - 106s 445ms/step - loss: 0.2058 - accuracy: 0.9311 - AUC: 0.9882 - precision: 0.9358 - recall: 0.9268 - val_loss: 3.3449 - val_accuracy: 0.1876 - val_AUC: 0.4988 - val_precision: 0.1876 - val_recall: 0.1870 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9343 - AUC: 0.9907 - precision: 0.9391 - recall: 0.9310\n",
      "Epoch 00004: val_loss did not improve from 0.86866\n",
      "End of epoch 3. Learning rate: 0.001\n",
      "237/237 [==============================] - 107s 448ms/step - loss: 0.1832 - accuracy: 0.9343 - AUC: 0.9907 - precision: 0.9391 - recall: 0.9310 - val_loss: 3.0216 - val_accuracy: 0.2431 - val_AUC: 0.5733 - val_precision: 0.2421 - val_recall: 0.2405 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9413 - AUC: 0.9926 - precision: 0.9451 - recall: 0.9389\n",
      "Epoch 00005: val_loss did not improve from 0.86866\n",
      "End of epoch 4. Learning rate: 0.001\n",
      "237/237 [==============================] - 106s 448ms/step - loss: 0.1648 - accuracy: 0.9413 - AUC: 0.9926 - precision: 0.9451 - recall: 0.9389 - val_loss: 2.9623 - val_accuracy: 0.2637 - val_AUC: 0.5741 - val_precision: 0.2639 - val_recall: 0.2637 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9414 - AUC: 0.9918 - precision: 0.9449 - recall: 0.9388\n",
      "Epoch 00006: val_loss did not improve from 0.86866\n",
      "End of epoch 5. Learning rate: 0.001\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 0.1679 - accuracy: 0.9414 - AUC: 0.9918 - precision: 0.9449 - recall: 0.9388 - val_loss: 2.6124 - val_accuracy: 0.2785 - val_AUC: 0.6422 - val_precision: 0.2785 - val_recall: 0.2785 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9466 - AUC: 0.9937 - precision: 0.9485 - recall: 0.9445\n",
      "Epoch 00007: val_loss did not improve from 0.86866\n",
      "End of epoch 6. Learning rate: 0.001\n",
      "237/237 [==============================] - 106s 446ms/step - loss: 0.1477 - accuracy: 0.9466 - AUC: 0.9937 - precision: 0.9485 - recall: 0.9445 - val_loss: 3.4731 - val_accuracy: 0.1670 - val_AUC: 0.5279 - val_precision: 0.1670 - val_recall: 0.1670 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9486 - AUC: 0.9942 - precision: 0.9519 - recall: 0.9466\n",
      "Epoch 00008: val_loss did not improve from 0.86866\n",
      "End of epoch 7. Learning rate: 0.001\n",
      "237/237 [==============================] - 106s 448ms/step - loss: 0.1375 - accuracy: 0.9486 - AUC: 0.9942 - precision: 0.9519 - recall: 0.9466 - val_loss: 6.5834 - val_accuracy: 0.1605 - val_AUC: 0.4242 - val_precision: 0.1605 - val_recall: 0.1605 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9549 - AUC: 0.9949 - precision: 0.9565 - recall: 0.9524\n",
      "Epoch 00009: val_loss did not improve from 0.86866\n",
      "End of epoch 8. Learning rate: 0.001\n",
      "237/237 [==============================] - 106s 445ms/step - loss: 0.1281 - accuracy: 0.9549 - AUC: 0.9949 - precision: 0.9565 - recall: 0.9524 - val_loss: 4.1473 - val_accuracy: 0.1612 - val_AUC: 0.4701 - val_precision: 0.1612 - val_recall: 0.1612 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9531 - AUC: 0.9955 - precision: 0.9557 - recall: 0.9515\n",
      "Epoch 00010: val_loss did not improve from 0.86866\n",
      "End of epoch 9. Learning rate: 0.001\n",
      "237/237 [==============================] - 106s 444ms/step - loss: 0.1246 - accuracy: 0.9531 - AUC: 0.9955 - precision: 0.9557 - recall: 0.9515 - val_loss: 2.5369 - val_accuracy: 0.1651 - val_AUC: 0.5899 - val_precision: 0.1652 - val_recall: 0.1651 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9543 - AUC: 0.9953 - precision: 0.9566 - recall: 0.9523\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00031622778103685084.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.86866\n",
      "End of epoch 10. Learning rate: 0.0003162278\n",
      "237/237 [==============================] - 106s 445ms/step - loss: 0.1224 - accuracy: 0.9543 - AUC: 0.9953 - precision: 0.9566 - recall: 0.9523 - val_loss: 5.1769 - val_accuracy: 0.1605 - val_AUC: 0.4388 - val_precision: 0.1605 - val_recall: 0.1605 - lr: 0.0010\n",
      "Learning rate:  0.0003162278\n",
      "Epoch 12/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9678 - AUC: 0.9977 - precision: 0.9688 - recall: 0.9660\n",
      "Epoch 00012: val_loss did not improve from 0.86866\n",
      "End of epoch 11. Learning rate: 0.0003162278\n",
      "237/237 [==============================] - 106s 446ms/step - loss: 0.0833 - accuracy: 0.9678 - AUC: 0.9977 - precision: 0.9688 - recall: 0.9660 - val_loss: 2.4178 - val_accuracy: 0.2579 - val_AUC: 0.6041 - val_precision: 0.2587 - val_recall: 0.2579 - lr: 3.1623e-04\n",
      "Learning rate:  0.0003162278\n",
      "Epoch 13/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9718 - AUC: 0.9981 - precision: 0.9738 - recall: 0.9711\n",
      "Epoch 00013: val_loss did not improve from 0.86866\n",
      "End of epoch 12. Learning rate: 0.0003162278\n",
      "237/237 [==============================] - 106s 447ms/step - loss: 0.0771 - accuracy: 0.9718 - AUC: 0.9981 - precision: 0.9738 - recall: 0.9711 - val_loss: 2.8731 - val_accuracy: 0.3198 - val_AUC: 0.5827 - val_precision: 0.3191 - val_recall: 0.3179 - lr: 3.1623e-04\n",
      "Learning rate:  0.0003162278\n",
      "Epoch 14/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9715 - AUC: 0.9979 - precision: 0.9726 - recall: 0.9707\n",
      "Epoch 00014: val_loss did not improve from 0.86866\n",
      "End of epoch 13. Learning rate: 0.0003162278\n",
      "237/237 [==============================] - 105s 444ms/step - loss: 0.0759 - accuracy: 0.9715 - AUC: 0.9979 - precision: 0.9726 - recall: 0.9707 - val_loss: 0.9344 - val_accuracy: 0.5822 - val_AUC: 0.8225 - val_precision: 0.5839 - val_recall: 0.5790 - lr: 3.1623e-04\n",
      "Learning rate:  0.0003162278\n",
      "Epoch 15/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9738 - AUC: 0.9985 - precision: 0.9743 - recall: 0.9733\n",
      "Epoch 00015: val_loss did not improve from 0.86866\n",
      "End of epoch 14. Learning rate: 0.0003162278\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 0.0646 - accuracy: 0.9738 - AUC: 0.9985 - precision: 0.9743 - recall: 0.9733 - val_loss: 1.9484 - val_accuracy: 0.3804 - val_AUC: 0.6369 - val_precision: 0.3809 - val_recall: 0.3785 - lr: 3.1623e-04\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "chexnet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")\n",
    "history = chexnet_model.fit(train_generator,\n",
    "                            epochs=15,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            class_weight = class_weights,\n",
    "                            callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014a1b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523771</td>\n",
       "      <td>0.790642</td>\n",
       "      <td>0.930178</td>\n",
       "      <td>0.842201</td>\n",
       "      <td>0.732223</td>\n",
       "      <td>0.868659</td>\n",
       "      <td>0.666022</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>0.700955</td>\n",
       "      <td>0.615087</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.075907</td>\n",
       "      <td>0.971451</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.972586</td>\n",
       "      <td>0.970658</td>\n",
       "      <td>0.934413</td>\n",
       "      <td>0.582205</td>\n",
       "      <td>0.822499</td>\n",
       "      <td>0.583875</td>\n",
       "      <td>0.578981</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264011</td>\n",
       "      <td>0.909992</td>\n",
       "      <td>0.981815</td>\n",
       "      <td>0.917294</td>\n",
       "      <td>0.901533</td>\n",
       "      <td>0.971551</td>\n",
       "      <td>0.609284</td>\n",
       "      <td>0.845036</td>\n",
       "      <td>0.610602</td>\n",
       "      <td>0.601547</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.064580</td>\n",
       "      <td>0.973830</td>\n",
       "      <td>0.998517</td>\n",
       "      <td>0.974332</td>\n",
       "      <td>0.973302</td>\n",
       "      <td>1.948429</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.636936</td>\n",
       "      <td>0.380921</td>\n",
       "      <td>0.378466</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.083259</td>\n",
       "      <td>0.967750</td>\n",
       "      <td>0.997676</td>\n",
       "      <td>0.968849</td>\n",
       "      <td>0.966032</td>\n",
       "      <td>2.417792</td>\n",
       "      <td>0.257898</td>\n",
       "      <td>0.604056</td>\n",
       "      <td>0.258732</td>\n",
       "      <td>0.257898</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.124572</td>\n",
       "      <td>0.953080</td>\n",
       "      <td>0.995451</td>\n",
       "      <td>0.955662</td>\n",
       "      <td>0.951494</td>\n",
       "      <td>2.536873</td>\n",
       "      <td>0.165055</td>\n",
       "      <td>0.589906</td>\n",
       "      <td>0.165161</td>\n",
       "      <td>0.165055</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.167896</td>\n",
       "      <td>0.941449</td>\n",
       "      <td>0.991820</td>\n",
       "      <td>0.944925</td>\n",
       "      <td>0.938805</td>\n",
       "      <td>2.612391</td>\n",
       "      <td>0.278530</td>\n",
       "      <td>0.642250</td>\n",
       "      <td>0.278530</td>\n",
       "      <td>0.278530</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.077071</td>\n",
       "      <td>0.971848</td>\n",
       "      <td>0.998070</td>\n",
       "      <td>0.973757</td>\n",
       "      <td>0.971055</td>\n",
       "      <td>2.873096</td>\n",
       "      <td>0.319794</td>\n",
       "      <td>0.582687</td>\n",
       "      <td>0.319094</td>\n",
       "      <td>0.317859</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.164762</td>\n",
       "      <td>0.941316</td>\n",
       "      <td>0.992582</td>\n",
       "      <td>0.945058</td>\n",
       "      <td>0.938937</td>\n",
       "      <td>2.962256</td>\n",
       "      <td>0.263701</td>\n",
       "      <td>0.574124</td>\n",
       "      <td>0.263871</td>\n",
       "      <td>0.263701</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183213</td>\n",
       "      <td>0.934311</td>\n",
       "      <td>0.990737</td>\n",
       "      <td>0.939075</td>\n",
       "      <td>0.931007</td>\n",
       "      <td>3.021585</td>\n",
       "      <td>0.243069</td>\n",
       "      <td>0.573311</td>\n",
       "      <td>0.242051</td>\n",
       "      <td>0.240490</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205832</td>\n",
       "      <td>0.931139</td>\n",
       "      <td>0.988226</td>\n",
       "      <td>0.935807</td>\n",
       "      <td>0.926778</td>\n",
       "      <td>3.344927</td>\n",
       "      <td>0.187621</td>\n",
       "      <td>0.498778</td>\n",
       "      <td>0.187581</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.147686</td>\n",
       "      <td>0.946603</td>\n",
       "      <td>0.993677</td>\n",
       "      <td>0.948500</td>\n",
       "      <td>0.944489</td>\n",
       "      <td>3.473082</td>\n",
       "      <td>0.166989</td>\n",
       "      <td>0.527888</td>\n",
       "      <td>0.166989</td>\n",
       "      <td>0.166989</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.128058</td>\n",
       "      <td>0.954930</td>\n",
       "      <td>0.994946</td>\n",
       "      <td>0.956464</td>\n",
       "      <td>0.952419</td>\n",
       "      <td>4.147289</td>\n",
       "      <td>0.161186</td>\n",
       "      <td>0.470148</td>\n",
       "      <td>0.161186</td>\n",
       "      <td>0.161186</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.122404</td>\n",
       "      <td>0.954269</td>\n",
       "      <td>0.995348</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.952287</td>\n",
       "      <td>5.176860</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>0.438797</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.137494</td>\n",
       "      <td>0.948586</td>\n",
       "      <td>0.994169</td>\n",
       "      <td>0.951887</td>\n",
       "      <td>0.946603</td>\n",
       "      <td>6.583433</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>0.424211</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy       AUC  precision    recall  val_loss  \\\n",
       "epoch                                                                \n",
       "0      0.523771  0.790642  0.930178   0.842201  0.732223  0.868659   \n",
       "13     0.075907  0.971451  0.997855   0.972586  0.970658  0.934413   \n",
       "1      0.264011  0.909992  0.981815   0.917294  0.901533  0.971551   \n",
       "14     0.064580  0.973830  0.998517   0.974332  0.973302  1.948429   \n",
       "11     0.083259  0.967750  0.997676   0.968849  0.966032  2.417792   \n",
       "9      0.124572  0.953080  0.995451   0.955662  0.951494  2.536873   \n",
       "5      0.167896  0.941449  0.991820   0.944925  0.938805  2.612391   \n",
       "12     0.077071  0.971848  0.998070   0.973757  0.971055  2.873096   \n",
       "4      0.164762  0.941316  0.992582   0.945058  0.938937  2.962256   \n",
       "3      0.183213  0.934311  0.990737   0.939075  0.931007  3.021585   \n",
       "2      0.205832  0.931139  0.988226   0.935807  0.926778  3.344927   \n",
       "6      0.147686  0.946603  0.993677   0.948500  0.944489  3.473082   \n",
       "8      0.128058  0.954930  0.994946   0.956464  0.952419  4.147289   \n",
       "10     0.122404  0.954269  0.995348   0.956585  0.952287  5.176860   \n",
       "7      0.137494  0.948586  0.994169   0.951887  0.946603  6.583433   \n",
       "\n",
       "       val_accuracy   val_AUC  val_precision  val_recall        lr  \n",
       "epoch                                                               \n",
       "0          0.666022  0.823484       0.700955    0.615087  0.001000  \n",
       "13         0.582205  0.822499       0.583875    0.578981  0.000316  \n",
       "1          0.609284  0.845036       0.610602    0.601547  0.001000  \n",
       "14         0.380400  0.636936       0.380921    0.378466  0.000316  \n",
       "11         0.257898  0.604056       0.258732    0.257898  0.000316  \n",
       "9          0.165055  0.589906       0.165161    0.165055  0.001000  \n",
       "5          0.278530  0.642250       0.278530    0.278530  0.001000  \n",
       "12         0.319794  0.582687       0.319094    0.317859  0.000316  \n",
       "4          0.263701  0.574124       0.263871    0.263701  0.001000  \n",
       "3          0.243069  0.573311       0.242051    0.240490  0.001000  \n",
       "2          0.187621  0.498778       0.187581    0.186976  0.001000  \n",
       "6          0.166989  0.527888       0.166989    0.166989  0.001000  \n",
       "8          0.161186  0.470148       0.161186    0.161186  0.001000  \n",
       "10         0.160542  0.438797       0.160542    0.160542  0.001000  \n",
       "7          0.160542  0.424211       0.160542    0.160542  0.001000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ccc136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(8, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.plot(history.epoch, history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training and Validation loss')\n",
    "plt.plot(history.epoch, history.history['loss'], label='Training loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.plot(history.epoch, history.history['AUC'], label='Training AUC')\n",
    "plt.plot(history.epoch, history.history['val_AUC'], label='Validation AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cfed9c",
   "metadata": {},
   "source": [
    "#### Fine-tune ChexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in chexnet_model.layers:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c551b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-04\n",
      "Epoch 15/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9816 - AUC: 0.9990 - precision: 0.9824 - recall: 0.9810\n",
      "Epoch 00015: val_loss improved from 0.86866 to 0.09176, saving model to ./weights/chexnet_3channel_scratch_d4.hdf5\n",
      "End of epoch 14. Learning rate: 1e-04\n",
      "237/237 [==============================] - 118s 455ms/step - loss: 0.0512 - accuracy: 0.9816 - AUC: 0.9990 - precision: 0.9824 - recall: 0.9810 - val_loss: 0.0918 - val_accuracy: 0.9703 - val_AUC: 0.9960 - val_precision: 0.9716 - val_recall: 0.9697 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 16/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9831 - AUC: 0.9991 - precision: 0.9844 - recall: 0.9827\n",
      "Epoch 00016: val_loss did not improve from 0.09176\n",
      "End of epoch 15. Learning rate: 1e-04\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.0460 - accuracy: 0.9831 - AUC: 0.9991 - precision: 0.9844 - recall: 0.9827 - val_loss: 0.1373 - val_accuracy: 0.9562 - val_AUC: 0.9931 - val_precision: 0.9574 - val_recall: 0.9555 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 17/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9830 - AUC: 0.9988 - precision: 0.9836 - recall: 0.9816\n",
      "Epoch 00017: val_loss did not improve from 0.09176\n",
      "End of epoch 16. Learning rate: 1e-04\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 0.0481 - accuracy: 0.9830 - AUC: 0.9988 - precision: 0.9836 - recall: 0.9816 - val_loss: 0.1711 - val_accuracy: 0.9407 - val_AUC: 0.9904 - val_precision: 0.9411 - val_recall: 0.9381 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 18/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9832 - AUC: 0.9987 - precision: 0.9836 - recall: 0.9827\n",
      "Epoch 00018: val_loss did not improve from 0.09176\n",
      "End of epoch 17. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 428ms/step - loss: 0.0479 - accuracy: 0.9832 - AUC: 0.9987 - precision: 0.9836 - recall: 0.9827 - val_loss: 0.1187 - val_accuracy: 0.9574 - val_AUC: 0.9947 - val_precision: 0.9580 - val_recall: 0.9562 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 19/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9841 - AUC: 0.9992 - precision: 0.9854 - recall: 0.9837\n",
      "Epoch 00019: val_loss did not improve from 0.09176\n",
      "End of epoch 18. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 422ms/step - loss: 0.0423 - accuracy: 0.9841 - AUC: 0.9992 - precision: 0.9854 - recall: 0.9837 - val_loss: 0.1748 - val_accuracy: 0.9394 - val_AUC: 0.9901 - val_precision: 0.9424 - val_recall: 0.9387 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 20/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9857 - AUC: 0.9991 - precision: 0.9865 - recall: 0.9851\n",
      "Epoch 00020: val_loss did not improve from 0.09176\n",
      "End of epoch 19. Learning rate: 1e-04\n",
      "237/237 [==============================] - 104s 436ms/step - loss: 0.0423 - accuracy: 0.9857 - AUC: 0.9991 - precision: 0.9865 - recall: 0.9851 - val_loss: 0.1437 - val_accuracy: 0.9555 - val_AUC: 0.9925 - val_precision: 0.9561 - val_recall: 0.9542 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 21/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9878 - AUC: 0.9991 - precision: 0.9881 - recall: 0.9874\n",
      "Epoch 00021: val_loss did not improve from 0.09176\n",
      "End of epoch 20. Learning rate: 1e-04\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 0.0393 - accuracy: 0.9878 - AUC: 0.9991 - precision: 0.9881 - recall: 0.9874 - val_loss: 0.1566 - val_accuracy: 0.9516 - val_AUC: 0.9914 - val_precision: 0.9522 - val_recall: 0.9504 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 22/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9874 - AUC: 0.9995 - precision: 0.9880 - recall: 0.9872\n",
      "Epoch 00022: val_loss did not improve from 0.09176\n",
      "End of epoch 21. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 428ms/step - loss: 0.0380 - accuracy: 0.9874 - AUC: 0.9995 - precision: 0.9880 - recall: 0.9872 - val_loss: 0.3602 - val_accuracy: 0.8756 - val_AUC: 0.9696 - val_precision: 0.8814 - val_recall: 0.8723 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 23/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9855 - AUC: 0.9994 - precision: 0.9862 - recall: 0.9852\n",
      "Epoch 00023: val_loss did not improve from 0.09176\n",
      "End of epoch 22. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0413 - accuracy: 0.9855 - AUC: 0.9994 - precision: 0.9862 - recall: 0.9852 - val_loss: 0.3916 - val_accuracy: 0.8569 - val_AUC: 0.9634 - val_precision: 0.8590 - val_recall: 0.8562 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 24/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9888 - AUC: 0.9995 - precision: 0.9893 - recall: 0.9881\n",
      "Epoch 00024: val_loss did not improve from 0.09176\n",
      "End of epoch 23. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 421ms/step - loss: 0.0333 - accuracy: 0.9888 - AUC: 0.9995 - precision: 0.9893 - recall: 0.9881 - val_loss: 0.1402 - val_accuracy: 0.9555 - val_AUC: 0.9923 - val_precision: 0.9555 - val_recall: 0.9555 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 25/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9865 - AUC: 0.9996 - precision: 0.9872 - recall: 0.9864\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.09176\n",
      "End of epoch 24. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0349 - accuracy: 0.9865 - AUC: 0.9996 - precision: 0.9872 - recall: 0.9864 - val_loss: 0.1655 - val_accuracy: 0.9458 - val_AUC: 0.9904 - val_precision: 0.9463 - val_recall: 0.9439 - lr: 1.0000e-04\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 26/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9890 - AUC: 0.9993 - precision: 0.9895 - recall: 0.9886\n",
      "Epoch 00026: val_loss did not improve from 0.09176\n",
      "End of epoch 25. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.0347 - accuracy: 0.9890 - AUC: 0.9993 - precision: 0.9895 - recall: 0.9886 - val_loss: 0.2623 - val_accuracy: 0.9175 - val_AUC: 0.9815 - val_precision: 0.9184 - val_recall: 0.9149 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 27/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9880 - AUC: 0.9995 - precision: 0.9886 - recall: 0.9877\n",
      "Epoch 00027: val_loss did not improve from 0.09176\n",
      "End of epoch 26. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 105s 442ms/step - loss: 0.0347 - accuracy: 0.9880 - AUC: 0.9995 - precision: 0.9886 - recall: 0.9877 - val_loss: 0.2285 - val_accuracy: 0.9259 - val_AUC: 0.9852 - val_precision: 0.9263 - val_recall: 0.9239 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 28/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9878 - AUC: 0.9996 - precision: 0.9882 - recall: 0.9874\n",
      "Epoch 00028: val_loss did not improve from 0.09176\n",
      "End of epoch 27. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 0.0331 - accuracy: 0.9878 - AUC: 0.9996 - precision: 0.9882 - recall: 0.9874 - val_loss: 0.2203 - val_accuracy: 0.9271 - val_AUC: 0.9858 - val_precision: 0.9289 - val_recall: 0.9271 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 29/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9901 - AUC: 0.9996 - precision: 0.9902 - recall: 0.9898\n",
      "Epoch 00029: val_loss did not improve from 0.09176\n",
      "End of epoch 28. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 104s 439ms/step - loss: 0.0292 - accuracy: 0.9901 - AUC: 0.9996 - precision: 0.9902 - recall: 0.9898 - val_loss: 0.2386 - val_accuracy: 0.9188 - val_AUC: 0.9836 - val_precision: 0.9216 - val_recall: 0.9175 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 30/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9892 - AUC: 0.9995 - precision: 0.9899 - recall: 0.9888\n",
      "Epoch 00030: val_loss did not improve from 0.09176\n",
      "End of epoch 29. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 107s 448ms/step - loss: 0.0314 - accuracy: 0.9892 - AUC: 0.9995 - precision: 0.9899 - recall: 0.9888 - val_loss: 0.1826 - val_accuracy: 0.9387 - val_AUC: 0.9888 - val_precision: 0.9398 - val_recall: 0.9362 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 31/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9872 - AUC: 0.9994 - precision: 0.9877 - recall: 0.9869\n",
      "Epoch 00031: val_loss did not improve from 0.09176\n",
      "End of epoch 30. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 0.0344 - accuracy: 0.9872 - AUC: 0.9994 - precision: 0.9877 - recall: 0.9869 - val_loss: 0.2041 - val_accuracy: 0.9336 - val_AUC: 0.9876 - val_precision: 0.9347 - val_recall: 0.9317 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 32/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9878 - AUC: 0.9992 - precision: 0.9881 - recall: 0.9877\n",
      "Epoch 00032: val_loss did not improve from 0.09176\n",
      "End of epoch 31. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 108s 456ms/step - loss: 0.0358 - accuracy: 0.9878 - AUC: 0.9992 - precision: 0.9881 - recall: 0.9877 - val_loss: 0.1593 - val_accuracy: 0.9497 - val_AUC: 0.9912 - val_precision: 0.9509 - val_recall: 0.9497 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 33/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9893 - AUC: 0.9995 - precision: 0.9894 - recall: 0.9890\n",
      "Epoch 00033: val_loss did not improve from 0.09176\n",
      "End of epoch 32. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 108s 453ms/step - loss: 0.0319 - accuracy: 0.9893 - AUC: 0.9995 - precision: 0.9894 - recall: 0.9890 - val_loss: 0.2302 - val_accuracy: 0.9252 - val_AUC: 0.9843 - val_precision: 0.9293 - val_recall: 0.9239 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 34/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9890 - AUC: 0.9995 - precision: 0.9898 - recall: 0.9888\n",
      "Epoch 00034: val_loss did not improve from 0.09176\n",
      "End of epoch 33. Learning rate: 3.1622774e-05\n",
      "237/237 [==============================] - 108s 455ms/step - loss: 0.0317 - accuracy: 0.9890 - AUC: 0.9995 - precision: 0.9898 - recall: 0.9888 - val_loss: 0.2409 - val_accuracy: 0.9220 - val_AUC: 0.9835 - val_precision: 0.9243 - val_recall: 0.9213 - lr: 3.1623e-05\n",
      "Learning rate:  3.1622774e-05\n",
      "Epoch 35/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9909 - AUC: 0.9998 - precision: 0.9909 - recall: 0.9902\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999259090306e-06.\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.09176\n",
      "End of epoch 34. Learning rate: 9.999999e-06\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 0.0275 - accuracy: 0.9909 - AUC: 0.9998 - precision: 0.9909 - recall: 0.9902 - val_loss: 0.2107 - val_accuracy: 0.9304 - val_AUC: 0.9860 - val_precision: 0.9321 - val_recall: 0.9291 - lr: 3.1623e-05\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "chexnet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")\n",
    "history_finetune = chexnet_model.fit(train_generator,\n",
    "                            epochs=35,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            initial_epoch=history.epoch[-1],\n",
    "                             callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20433787",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "initial_epochs=history.epoch[-1]\n",
    "\n",
    "acc += history_finetune.history['accuracy']\n",
    "val_acc += history_finetune.history['val_accuracy']\n",
    "loss += history_finetune.history['loss']\n",
    "val_loss += history_finetune.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d02ebbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_epochs=history.epoch[-1]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.1, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='LR 1e-4')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 5])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='LR 1e-4')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a37e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.981628</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.982396</td>\n",
       "      <td>0.980967</td>\n",
       "      <td>0.091759</td>\n",
       "      <td>0.970342</td>\n",
       "      <td>0.996017</td>\n",
       "      <td>0.971576</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047896</td>\n",
       "      <td>0.983214</td>\n",
       "      <td>0.998696</td>\n",
       "      <td>0.983596</td>\n",
       "      <td>0.982686</td>\n",
       "      <td>0.118695</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.994698</td>\n",
       "      <td>0.958010</td>\n",
       "      <td>0.956157</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046048</td>\n",
       "      <td>0.983082</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.984377</td>\n",
       "      <td>0.982686</td>\n",
       "      <td>0.137286</td>\n",
       "      <td>0.956157</td>\n",
       "      <td>0.993107</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.033284</td>\n",
       "      <td>0.988766</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.989281</td>\n",
       "      <td>0.988105</td>\n",
       "      <td>0.140156</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>0.992271</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042279</td>\n",
       "      <td>0.985726</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>0.986499</td>\n",
       "      <td>0.985065</td>\n",
       "      <td>0.143732</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>0.992540</td>\n",
       "      <td>0.956072</td>\n",
       "      <td>0.954223</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.039288</td>\n",
       "      <td>0.987840</td>\n",
       "      <td>0.999118</td>\n",
       "      <td>0.988097</td>\n",
       "      <td>0.987444</td>\n",
       "      <td>0.156556</td>\n",
       "      <td>0.951644</td>\n",
       "      <td>0.991399</td>\n",
       "      <td>0.952196</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.987840</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.988100</td>\n",
       "      <td>0.987708</td>\n",
       "      <td>0.159346</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.991179</td>\n",
       "      <td>0.950936</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.034922</td>\n",
       "      <td>0.986519</td>\n",
       "      <td>0.999559</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.165462</td>\n",
       "      <td>0.945841</td>\n",
       "      <td>0.990440</td>\n",
       "      <td>0.946348</td>\n",
       "      <td>0.943907</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048086</td>\n",
       "      <td>0.982950</td>\n",
       "      <td>0.998777</td>\n",
       "      <td>0.983578</td>\n",
       "      <td>0.981628</td>\n",
       "      <td>0.171084</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>0.990440</td>\n",
       "      <td>0.941138</td>\n",
       "      <td>0.938104</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042280</td>\n",
       "      <td>0.984140</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>0.985436</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.174811</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.990093</td>\n",
       "      <td>0.942395</td>\n",
       "      <td>0.938749</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.031372</td>\n",
       "      <td>0.989162</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.989943</td>\n",
       "      <td>0.988766</td>\n",
       "      <td>0.182647</td>\n",
       "      <td>0.938749</td>\n",
       "      <td>0.988799</td>\n",
       "      <td>0.939806</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.987698</td>\n",
       "      <td>0.986915</td>\n",
       "      <td>0.204064</td>\n",
       "      <td>0.933591</td>\n",
       "      <td>0.987589</td>\n",
       "      <td>0.934670</td>\n",
       "      <td>0.931657</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.027521</td>\n",
       "      <td>0.990880</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.990874</td>\n",
       "      <td>0.990219</td>\n",
       "      <td>0.210697</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0.985998</td>\n",
       "      <td>0.932083</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.033122</td>\n",
       "      <td>0.987840</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>0.988227</td>\n",
       "      <td>0.987444</td>\n",
       "      <td>0.220312</td>\n",
       "      <td>0.927144</td>\n",
       "      <td>0.985777</td>\n",
       "      <td>0.928941</td>\n",
       "      <td>0.927144</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.034738</td>\n",
       "      <td>0.987972</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.988623</td>\n",
       "      <td>0.987708</td>\n",
       "      <td>0.228522</td>\n",
       "      <td>0.925854</td>\n",
       "      <td>0.985211</td>\n",
       "      <td>0.926309</td>\n",
       "      <td>0.923920</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.031910</td>\n",
       "      <td>0.989294</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.989422</td>\n",
       "      <td>0.989030</td>\n",
       "      <td>0.230168</td>\n",
       "      <td>0.925210</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.929313</td>\n",
       "      <td>0.923920</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.029171</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.999635</td>\n",
       "      <td>0.990216</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.238583</td>\n",
       "      <td>0.918762</td>\n",
       "      <td>0.983555</td>\n",
       "      <td>0.921632</td>\n",
       "      <td>0.917473</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.989030</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>0.989812</td>\n",
       "      <td>0.988766</td>\n",
       "      <td>0.240874</td>\n",
       "      <td>0.921986</td>\n",
       "      <td>0.983465</td>\n",
       "      <td>0.924321</td>\n",
       "      <td>0.921341</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.034712</td>\n",
       "      <td>0.989030</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.989549</td>\n",
       "      <td>0.988633</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>0.917473</td>\n",
       "      <td>0.981469</td>\n",
       "      <td>0.918447</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.037994</td>\n",
       "      <td>0.987444</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>0.987963</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.360202</td>\n",
       "      <td>0.875564</td>\n",
       "      <td>0.969561</td>\n",
       "      <td>0.881433</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.985461</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>0.986240</td>\n",
       "      <td>0.985197</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.856867</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.858991</td>\n",
       "      <td>0.856222</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy       AUC  precision    recall  val_loss  \\\n",
       "epoch                                                                \n",
       "0      0.051244  0.981628  0.998980   0.982396  0.980967  0.091759   \n",
       "3      0.047896  0.983214  0.998696   0.983596  0.982686  0.118695   \n",
       "1      0.046048  0.983082  0.999115   0.984377  0.982686  0.137286   \n",
       "9      0.033284  0.988766  0.999495   0.989281  0.988105  0.140156   \n",
       "5      0.042279  0.985726  0.999113   0.986499  0.985065  0.143732   \n",
       "6      0.039288  0.987840  0.999118   0.988097  0.987444  0.156556   \n",
       "17     0.035837  0.987840  0.999221   0.988100  0.987708  0.159346   \n",
       "10     0.034922  0.986519  0.999559   0.987169  0.986386  0.165462   \n",
       "2      0.048086  0.982950  0.998777   0.983578  0.981628  0.171084   \n",
       "4      0.042280  0.984140  0.999242   0.985436  0.983743  0.174811   \n",
       "15     0.031372  0.989162  0.999532   0.989943  0.988766  0.182647   \n",
       "16     0.034371  0.987179  0.999366   0.987698  0.986915  0.204064   \n",
       "20     0.027521  0.990880  0.999771   0.990874  0.990219  0.210697   \n",
       "13     0.033122  0.987840  0.999615   0.988227  0.987444  0.220312   \n",
       "12     0.034738  0.987972  0.999490   0.988623  0.987708  0.228522   \n",
       "18     0.031910  0.989294  0.999524   0.989422  0.989030  0.230168   \n",
       "14     0.029171  0.990087  0.999635   0.990216  0.989823  0.238583   \n",
       "19     0.031683  0.989030  0.999510   0.989812  0.988766  0.240874   \n",
       "11     0.034712  0.989030  0.999307   0.989549  0.988633  0.262251   \n",
       "7      0.037994  0.987444  0.999497   0.987963  0.987179  0.360202   \n",
       "8      0.041350  0.985461  0.999369   0.986240  0.985197  0.391608   \n",
       "\n",
       "       val_accuracy   val_AUC  val_precision  val_recall        lr  \n",
       "epoch                                                               \n",
       "0          0.970342  0.996017       0.971576    0.969697  0.000100  \n",
       "3          0.957447  0.994698       0.958010    0.956157  0.000100  \n",
       "1          0.956157  0.993107       0.957364    0.955513  0.000100  \n",
       "9          0.955513  0.992271       0.955513    0.955513  0.000100  \n",
       "5          0.955513  0.992540       0.956072    0.954223  0.000100  \n",
       "6          0.951644  0.991399       0.952196    0.950355  0.000100  \n",
       "17         0.949710  0.991179       0.950936    0.949710  0.000032  \n",
       "10         0.945841  0.990440       0.946348    0.943907  0.000100  \n",
       "2          0.940683  0.990440       0.941138    0.938104  0.000100  \n",
       "4          0.939394  0.990093       0.942395    0.938749  0.000100  \n",
       "15         0.938749  0.988799       0.939806    0.936170  0.000032  \n",
       "16         0.933591  0.987589       0.934670    0.931657  0.000032  \n",
       "20         0.930368  0.985998       0.932083    0.929078  0.000032  \n",
       "13         0.927144  0.985777       0.928941    0.927144  0.000032  \n",
       "12         0.925854  0.985211       0.926309    0.923920  0.000032  \n",
       "18         0.925210  0.984303       0.929313    0.923920  0.000032  \n",
       "14         0.918762  0.983555       0.921632    0.917473  0.000032  \n",
       "19         0.921986  0.983465       0.924321    0.921341  0.000032  \n",
       "11         0.917473  0.981469       0.918447    0.914894  0.000032  \n",
       "7          0.875564  0.969561       0.881433    0.872340  0.000100  \n",
       "8          0.856867  0.963403       0.858991    0.856222  0.000100  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history_finetune.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940539b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-05\n",
      "Epoch 35/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9893 - AUC: 0.9996 - precision: 0.9896 - recall: 0.9890\n",
      "Epoch 00035: val_loss did not improve from 0.09176\n",
      "End of epoch 34. Learning rate: 1e-05\n",
      "237/237 [==============================] - 120s 460ms/step - loss: 0.0306 - accuracy: 0.9893 - AUC: 0.9996 - precision: 0.9896 - recall: 0.9890 - val_loss: 0.1429 - val_accuracy: 0.9568 - val_AUC: 0.9935 - val_precision: 0.9580 - val_recall: 0.9568 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 36/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9893 - AUC: 0.9998 - precision: 0.9894 - recall: 0.9892\n",
      "Epoch 00036: val_loss did not improve from 0.09176\n",
      "End of epoch 35. Learning rate: 1e-05\n",
      "237/237 [==============================] - 107s 452ms/step - loss: 0.0283 - accuracy: 0.9893 - AUC: 0.9998 - precision: 0.9894 - recall: 0.9892 - val_loss: 0.1431 - val_accuracy: 0.9568 - val_AUC: 0.9927 - val_precision: 0.9567 - val_recall: 0.9555 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 37/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9896 - AUC: 0.9998 - precision: 0.9901 - recall: 0.9892\n",
      "Epoch 00037: val_loss did not improve from 0.09176\n",
      "End of epoch 36. Learning rate: 1e-05\n",
      "237/237 [==============================] - 108s 455ms/step - loss: 0.0290 - accuracy: 0.9896 - AUC: 0.9998 - precision: 0.9901 - recall: 0.9892 - val_loss: 0.1449 - val_accuracy: 0.9562 - val_AUC: 0.9929 - val_precision: 0.9562 - val_recall: 0.9562 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 38/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9890 - AUC: 0.9998 - precision: 0.9890 - recall: 0.9885\n",
      "Epoch 00038: val_loss did not improve from 0.09176\n",
      "End of epoch 37. Learning rate: 1e-05\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 0.0279 - accuracy: 0.9890 - AUC: 0.9998 - precision: 0.9890 - recall: 0.9885 - val_loss: 0.1523 - val_accuracy: 0.9516 - val_AUC: 0.9920 - val_precision: 0.9516 - val_recall: 0.9510 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 39/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9892 - AUC: 0.9995 - precision: 0.9894 - recall: 0.9888\n",
      "Epoch 00039: val_loss did not improve from 0.09176\n",
      "End of epoch 38. Learning rate: 1e-05\n",
      "237/237 [==============================] - 108s 455ms/step - loss: 0.0298 - accuracy: 0.9892 - AUC: 0.9995 - precision: 0.9894 - recall: 0.9888 - val_loss: 0.1564 - val_accuracy: 0.9504 - val_AUC: 0.9917 - val_precision: 0.9509 - val_recall: 0.9497 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 40/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9907 - AUC: 0.9996 - precision: 0.9910 - recall: 0.9904\n",
      "Epoch 00040: val_loss did not improve from 0.09176\n",
      "End of epoch 39. Learning rate: 1e-05\n",
      "237/237 [==============================] - 106s 447ms/step - loss: 0.0282 - accuracy: 0.9907 - AUC: 0.9996 - precision: 0.9910 - recall: 0.9904 - val_loss: 0.1630 - val_accuracy: 0.9478 - val_AUC: 0.9914 - val_precision: 0.9484 - val_recall: 0.9471 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 41/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9910 - AUC: 0.9996 - precision: 0.9911 - recall: 0.9910\n",
      "Epoch 00041: val_loss did not improve from 0.09176\n",
      "End of epoch 40. Learning rate: 1e-05\n",
      "237/237 [==============================] - 106s 445ms/step - loss: 0.0263 - accuracy: 0.9910 - AUC: 0.9996 - precision: 0.9911 - recall: 0.9910 - val_loss: 0.1854 - val_accuracy: 0.9407 - val_AUC: 0.9891 - val_precision: 0.9419 - val_recall: 0.9400 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 42/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9902 - AUC: 0.9997 - precision: 0.9905 - recall: 0.9901\n",
      "Epoch 00042: val_loss did not improve from 0.09176\n",
      "End of epoch 41. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 423ms/step - loss: 0.0273 - accuracy: 0.9902 - AUC: 0.9997 - precision: 0.9905 - recall: 0.9901 - val_loss: 0.1964 - val_accuracy: 0.9381 - val_AUC: 0.9886 - val_precision: 0.9381 - val_recall: 0.9375 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 43/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9913 - AUC: 0.9995 - precision: 0.9915 - recall: 0.9910\n",
      "Epoch 00043: val_loss did not improve from 0.09176\n",
      "End of epoch 42. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0268 - accuracy: 0.9913 - AUC: 0.9995 - precision: 0.9915 - recall: 0.9910 - val_loss: 0.1697 - val_accuracy: 0.9420 - val_AUC: 0.9907 - val_precision: 0.9432 - val_recall: 0.9420 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 44/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9882 - AUC: 0.9996 - precision: 0.9889 - recall: 0.9881\n",
      "Epoch 00044: val_loss did not improve from 0.09176\n",
      "End of epoch 43. Learning rate: 1e-05\n",
      "237/237 [==============================] - 100s 422ms/step - loss: 0.0324 - accuracy: 0.9882 - AUC: 0.9996 - precision: 0.9889 - recall: 0.9881 - val_loss: 0.1829 - val_accuracy: 0.9413 - val_AUC: 0.9893 - val_precision: 0.9425 - val_recall: 0.9400 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 45/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9901 - AUC: 0.9997 - precision: 0.9903 - recall: 0.9897\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.09176\n",
      "End of epoch 44. Learning rate: 3.1622776e-06\n",
      "237/237 [==============================] - 104s 437ms/step - loss: 0.0296 - accuracy: 0.9901 - AUC: 0.9997 - precision: 0.9903 - recall: 0.9897 - val_loss: 0.1993 - val_accuracy: 0.9355 - val_AUC: 0.9881 - val_precision: 0.9360 - val_recall: 0.9342 - lr: 1.0000e-05\n",
      "Learning rate:  3.1622776e-06\n",
      "Epoch 46/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9897 - AUC: 0.9997 - precision: 0.9898 - recall: 0.9890\n",
      "Epoch 00046: val_loss did not improve from 0.09176\n",
      "End of epoch 45. Learning rate: 3.1622776e-06\n",
      "237/237 [==============================] - 105s 440ms/step - loss: 0.0281 - accuracy: 0.9897 - AUC: 0.9997 - precision: 0.9898 - recall: 0.9890 - val_loss: 0.1718 - val_accuracy: 0.9446 - val_AUC: 0.9898 - val_precision: 0.9451 - val_recall: 0.9439 - lr: 3.1623e-06\n",
      "Learning rate:  3.1622776e-06\n",
      "Epoch 47/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9898 - AUC: 0.9993 - precision: 0.9905 - recall: 0.9894\n",
      "Epoch 00047: val_loss did not improve from 0.09176\n",
      "End of epoch 46. Learning rate: 3.1622776e-06\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.0308 - accuracy: 0.9898 - AUC: 0.9993 - precision: 0.9905 - recall: 0.9894 - val_loss: 0.1720 - val_accuracy: 0.9446 - val_AUC: 0.9902 - val_precision: 0.9451 - val_recall: 0.9439 - lr: 3.1623e-06\n",
      "Learning rate:  3.1622776e-06\n",
      "Epoch 48/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9898 - AUC: 0.9993 - precision: 0.9905 - recall: 0.9897\n",
      "Epoch 00048: val_loss did not improve from 0.09176\n",
      "End of epoch 47. Learning rate: 3.1622776e-06\n",
      "237/237 [==============================] - 104s 439ms/step - loss: 0.0300 - accuracy: 0.9898 - AUC: 0.9993 - precision: 0.9905 - recall: 0.9897 - val_loss: 0.1718 - val_accuracy: 0.9439 - val_AUC: 0.9902 - val_precision: 0.9444 - val_recall: 0.9426 - lr: 3.1623e-06\n",
      "Learning rate:  3.1622776e-06\n",
      "Epoch 49/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9904 - AUC: 0.9997 - precision: 0.9911 - recall: 0.9902\n",
      "Epoch 00049: val_loss did not improve from 0.09176\n",
      "End of epoch 48. Learning rate: 3.1622776e-06\n",
      "237/237 [==============================] - 105s 442ms/step - loss: 0.0280 - accuracy: 0.9904 - AUC: 0.9997 - precision: 0.9911 - recall: 0.9902 - val_loss: 0.1684 - val_accuracy: 0.9465 - val_AUC: 0.9901 - val_precision: 0.9483 - val_recall: 0.9458 - lr: 3.1623e-06\n",
      "Learning rate:  3.1622776e-06\n",
      "Epoch 50/50\n",
      " 81/237 [=========>....................] - ETA: 1:04 - loss: 0.0232 - accuracy: 0.9938 - AUC: 0.9995 - precision: 0.9938 - recall: 0.9938"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "chexnet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")\n",
    "history_finetune2 = chexnet_model.fit(train_generator,\n",
    "                            epochs=50,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            initial_epoch=history_finetune.epoch[-1],\n",
    "                             callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7db8ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030603</td>\n",
       "      <td>0.989294</td>\n",
       "      <td>0.999550</td>\n",
       "      <td>0.989553</td>\n",
       "      <td>0.989030</td>\n",
       "      <td>0.142898</td>\n",
       "      <td>0.956802</td>\n",
       "      <td>0.993493</td>\n",
       "      <td>0.958037</td>\n",
       "      <td>0.956802</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028339</td>\n",
       "      <td>0.989294</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.989424</td>\n",
       "      <td>0.989162</td>\n",
       "      <td>0.143052</td>\n",
       "      <td>0.956802</td>\n",
       "      <td>0.992728</td>\n",
       "      <td>0.956746</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029029</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.990078</td>\n",
       "      <td>0.989162</td>\n",
       "      <td>0.144924</td>\n",
       "      <td>0.956157</td>\n",
       "      <td>0.992880</td>\n",
       "      <td>0.956157</td>\n",
       "      <td>0.956157</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027928</td>\n",
       "      <td>0.989030</td>\n",
       "      <td>0.999782</td>\n",
       "      <td>0.989024</td>\n",
       "      <td>0.988501</td>\n",
       "      <td>0.152302</td>\n",
       "      <td>0.951644</td>\n",
       "      <td>0.991989</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.950999</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.989162</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>0.989419</td>\n",
       "      <td>0.988766</td>\n",
       "      <td>0.156392</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.991679</td>\n",
       "      <td>0.950936</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028153</td>\n",
       "      <td>0.990748</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990352</td>\n",
       "      <td>0.162957</td>\n",
       "      <td>0.947776</td>\n",
       "      <td>0.991417</td>\n",
       "      <td>0.948354</td>\n",
       "      <td>0.947131</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.027978</td>\n",
       "      <td>0.990352</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>0.991136</td>\n",
       "      <td>0.990219</td>\n",
       "      <td>0.168370</td>\n",
       "      <td>0.946486</td>\n",
       "      <td>0.990145</td>\n",
       "      <td>0.948287</td>\n",
       "      <td>0.945841</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.026825</td>\n",
       "      <td>0.991277</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.991537</td>\n",
       "      <td>0.991012</td>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.941973</td>\n",
       "      <td>0.990652</td>\n",
       "      <td>0.943189</td>\n",
       "      <td>0.941973</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.999313</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.171769</td>\n",
       "      <td>0.943907</td>\n",
       "      <td>0.990175</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.942618</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.028127</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.989815</td>\n",
       "      <td>0.989030</td>\n",
       "      <td>0.171808</td>\n",
       "      <td>0.944552</td>\n",
       "      <td>0.989799</td>\n",
       "      <td>0.945126</td>\n",
       "      <td>0.943907</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.999265</td>\n",
       "      <td>0.990474</td>\n",
       "      <td>0.989426</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.944552</td>\n",
       "      <td>0.990158</td>\n",
       "      <td>0.945126</td>\n",
       "      <td>0.943907</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.990352</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.990480</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.177486</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.989813</td>\n",
       "      <td>0.943798</td>\n",
       "      <td>0.941973</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.988237</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988105</td>\n",
       "      <td>0.182894</td>\n",
       "      <td>0.941328</td>\n",
       "      <td>0.989345</td>\n",
       "      <td>0.942469</td>\n",
       "      <td>0.940039</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026296</td>\n",
       "      <td>0.991012</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.991143</td>\n",
       "      <td>0.991012</td>\n",
       "      <td>0.185397</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>0.989051</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.940039</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.027250</td>\n",
       "      <td>0.990219</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.990480</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.196378</td>\n",
       "      <td>0.938104</td>\n",
       "      <td>0.988618</td>\n",
       "      <td>0.938065</td>\n",
       "      <td>0.937460</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.990345</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.199261</td>\n",
       "      <td>0.935525</td>\n",
       "      <td>0.988124</td>\n",
       "      <td>0.936047</td>\n",
       "      <td>0.934236</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy       AUC  precision    recall  val_loss  \\\n",
       "epoch                                                                \n",
       "0      0.030603  0.989294  0.999550   0.989553  0.989030  0.142898   \n",
       "1      0.028339  0.989294  0.999777   0.989424  0.989162  0.143052   \n",
       "2      0.029029  0.989559  0.999761   0.990078  0.989162  0.144924   \n",
       "3      0.027928  0.989030  0.999782   0.989024  0.988501  0.152302   \n",
       "4      0.029800  0.989162  0.999468   0.989419  0.988766  0.156392   \n",
       "5      0.028153  0.990748  0.999584   0.991006  0.990352  0.162957   \n",
       "14     0.027978  0.990352  0.999713   0.991136  0.990219  0.168370   \n",
       "8      0.026825  0.991277  0.999508   0.991537  0.991012  0.169746   \n",
       "13     0.029984  0.989823  0.999313   0.990476  0.989691  0.171769   \n",
       "11     0.028127  0.989691  0.999683   0.989815  0.989030  0.171808   \n",
       "12     0.030826  0.989823  0.999265   0.990474  0.989426  0.172034   \n",
       "15     0.029275  0.990352  0.999500   0.990480  0.990087  0.177486   \n",
       "9      0.032390  0.988237  0.999609   0.988889  0.988105  0.182894   \n",
       "6      0.026296  0.991012  0.999561   0.991143  0.991012  0.185397   \n",
       "7      0.027250  0.990219  0.999669   0.990480  0.990087  0.196378   \n",
       "10     0.029564  0.990087  0.999663   0.990345  0.989691  0.199261   \n",
       "\n",
       "       val_accuracy   val_AUC  val_precision  val_recall        lr  \n",
       "epoch                                                               \n",
       "0          0.956802  0.993493       0.958037    0.956802  0.000010  \n",
       "1          0.956802  0.992728       0.956746    0.955513  0.000010  \n",
       "2          0.956157  0.992880       0.956157    0.956157  0.000010  \n",
       "3          0.951644  0.991989       0.951613    0.950999  0.000010  \n",
       "4          0.950355  0.991679       0.950936    0.949710  0.000010  \n",
       "5          0.947776  0.991417       0.948354    0.947131  0.000010  \n",
       "14         0.946486  0.990145       0.948287    0.945841  0.000003  \n",
       "8          0.941973  0.990652       0.943189    0.941973  0.000010  \n",
       "13         0.943907  0.990175       0.944444    0.942618  0.000003  \n",
       "11         0.944552  0.989799       0.945126    0.943907  0.000003  \n",
       "12         0.944552  0.990158       0.945126    0.943907  0.000003  \n",
       "15         0.943262  0.989813       0.943798    0.941973  0.000003  \n",
       "9          0.941328  0.989345       0.942469    0.940039  0.000010  \n",
       "6          0.940683  0.989051       0.941860    0.940039  0.000010  \n",
       "7          0.938104  0.988618       0.938065    0.937460  0.000010  \n",
       "10         0.935525  0.988124       0.936047    0.934236  0.000010  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history_finetune2.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842b0f2",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52aff610",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./weights/chexnet_3channel_scratch_d4.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163076f",
   "metadata": {},
   "source": [
    "#### Montgomery County dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a32bb3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/test/Montgomery'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode=CLASS_MODE)\n",
    "res = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7faa01fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.8889    1.0000    0.9412        16\n",
      "          tb     1.0000    0.8333    0.9091        12\n",
      "\n",
      "    accuracy                         0.9286        28\n",
      "   macro avg     0.9444    0.9167    0.9251        28\n",
      "weighted avg     0.9365    0.9286    0.9274        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = np.argmax(res, axis=1)\n",
    "report = classification_report(test_generator.classes, predicted,target_names=['normal','tb'],digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7106bf",
   "metadata": {},
   "source": [
    "#### Shenzhen Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2960a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/test/Shenzhen'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode=CLASS_MODE)\n",
    "\n",
    "res = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afa30c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.8553    0.9848    0.9155        66\n",
      "          tb     0.9828    0.8382    0.9048        68\n",
      "\n",
      "    accuracy                         0.9104       134\n",
      "   macro avg     0.9190    0.9115    0.9101       134\n",
      "weighted avg     0.9200    0.9104    0.9100       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = np.argmax(res, axis=1)\n",
    "report = classification_report(test_generator.classes, predicted,target_names=['normal','tb'],digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f80be",
   "metadata": {},
   "source": [
    "#### TBX11K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9245d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1551 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/val'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode=CLASS_MODE)\n",
    "res = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "072dd29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      health     0.9771    0.9744    0.9757       702\n",
      "        sick     0.9802    0.9883    0.9842       600\n",
      "          tb     0.9268    0.9157    0.9212       249\n",
      "\n",
      "    accuracy                         0.9703      1551\n",
      "   macro avg     0.9614    0.9595    0.9604      1551\n",
      "weighted avg     0.9702    0.9703    0.9703      1551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = np.argmax(res, axis=1)\n",
    "report = classification_report(test_generator.classes, predicted,target_names=['health','sick','tb'],digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533432b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
