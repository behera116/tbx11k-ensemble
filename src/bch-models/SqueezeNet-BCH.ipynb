{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288cf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import cv2\n",
    "import os\n",
    "from skimage import exposure\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seaborn import heatmap\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from ast import literal_eval\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5166d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "TARGET_SIZE = (224,224)\n",
    "INPUT_SHAPE = (224,224,3)\n",
    "EPOCHS = 60\n",
    "\n",
    "CLASS_MODE = 'categorical'\n",
    "LOSS_METRIC = 'categorical_crossentropy'\n",
    "\n",
    "MODEL_SAVED_FILE = './weights/squeezenet_3channel_scratch.hdf5'\n",
    "TRAIN_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/train'\n",
    "VALIDATION_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/val'\n",
    "\n",
    "SEED = 42\n",
    "IMAGE_SHAPE = (224,224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f5197",
   "metadata": {},
   "source": [
    "### SqueezeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6041df5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 20:07:24.536844: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-08-26 20:07:24.536907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5808 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:1d:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 111, 111, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu_conv1 (Activation)        (None, 111, 111, 64  0           ['conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 55, 55, 64)   0           ['relu_conv1[0][0]']             \n",
      "                                                                                                  \n",
      " fire2/squeeze1x1 (Conv2D)      (None, 55, 55, 16)   1040        ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " fire2/relu_squeeze1x1 (Activat  (None, 55, 55, 16)  0           ['fire2/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire2/expand1x1 (Conv2D)       (None, 55, 55, 64)   1088        ['fire2/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire2/expand3x3 (Conv2D)       (None, 55, 55, 64)   9280        ['fire2/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire2/relu_expand1x1 (Activati  (None, 55, 55, 64)  0           ['fire2/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire2/relu_expand3x3 (Activati  (None, 55, 55, 64)  0           ['fire2/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire2/concat (Concatenate)     (None, 55, 55, 128)  0           ['fire2/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire2/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire3/squeeze1x1 (Conv2D)      (None, 55, 55, 16)   2064        ['fire2/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire3/relu_squeeze1x1 (Activat  (None, 55, 55, 16)  0           ['fire3/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire3/expand1x1 (Conv2D)       (None, 55, 55, 64)   1088        ['fire3/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire3/expand3x3 (Conv2D)       (None, 55, 55, 64)   9280        ['fire3/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire3/relu_expand1x1 (Activati  (None, 55, 55, 64)  0           ['fire3/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire3/relu_expand3x3 (Activati  (None, 55, 55, 64)  0           ['fire3/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire3/concat (Concatenate)     (None, 55, 55, 128)  0           ['fire3/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire3/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " pool3 (MaxPooling2D)           (None, 27, 27, 128)  0           ['fire3/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire4/squeeze1x1 (Conv2D)      (None, 27, 27, 32)   4128        ['pool3[0][0]']                  \n",
      "                                                                                                  \n",
      " fire4/relu_squeeze1x1 (Activat  (None, 27, 27, 32)  0           ['fire4/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire4/expand1x1 (Conv2D)       (None, 27, 27, 128)  4224        ['fire4/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire4/expand3x3 (Conv2D)       (None, 27, 27, 128)  36992       ['fire4/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire4/relu_expand1x1 (Activati  (None, 27, 27, 128)  0          ['fire4/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire4/relu_expand3x3 (Activati  (None, 27, 27, 128)  0          ['fire4/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire4/concat (Concatenate)     (None, 27, 27, 256)  0           ['fire4/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire4/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire5/squeeze1x1 (Conv2D)      (None, 27, 27, 32)   8224        ['fire4/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire5/relu_squeeze1x1 (Activat  (None, 27, 27, 32)  0           ['fire5/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire5/expand1x1 (Conv2D)       (None, 27, 27, 128)  4224        ['fire5/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire5/expand3x3 (Conv2D)       (None, 27, 27, 128)  36992       ['fire5/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire5/relu_expand1x1 (Activati  (None, 27, 27, 128)  0          ['fire5/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire5/relu_expand3x3 (Activati  (None, 27, 27, 128)  0          ['fire5/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire5/concat (Concatenate)     (None, 27, 27, 256)  0           ['fire5/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire5/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " pool5 (MaxPooling2D)           (None, 13, 13, 256)  0           ['fire5/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire6/squeeze1x1 (Conv2D)      (None, 13, 13, 48)   12336       ['pool5[0][0]']                  \n",
      "                                                                                                  \n",
      " fire6/relu_squeeze1x1 (Activat  (None, 13, 13, 48)  0           ['fire6/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire6/expand1x1 (Conv2D)       (None, 13, 13, 192)  9408        ['fire6/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire6/expand3x3 (Conv2D)       (None, 13, 13, 192)  83136       ['fire6/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire6/relu_expand1x1 (Activati  (None, 13, 13, 192)  0          ['fire6/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire6/relu_expand3x3 (Activati  (None, 13, 13, 192)  0          ['fire6/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire6/concat (Concatenate)     (None, 13, 13, 384)  0           ['fire6/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire6/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire7/squeeze1x1 (Conv2D)      (None, 13, 13, 48)   18480       ['fire6/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire7/relu_squeeze1x1 (Activat  (None, 13, 13, 48)  0           ['fire7/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire7/expand1x1 (Conv2D)       (None, 13, 13, 192)  9408        ['fire7/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire7/expand3x3 (Conv2D)       (None, 13, 13, 192)  83136       ['fire7/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire7/relu_expand1x1 (Activati  (None, 13, 13, 192)  0          ['fire7/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire7/relu_expand3x3 (Activati  (None, 13, 13, 192)  0          ['fire7/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire7/concat (Concatenate)     (None, 13, 13, 384)  0           ['fire7/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire7/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire8/squeeze1x1 (Conv2D)      (None, 13, 13, 64)   24640       ['fire7/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire8/relu_squeeze1x1 (Activat  (None, 13, 13, 64)  0           ['fire8/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire8/expand1x1 (Conv2D)       (None, 13, 13, 256)  16640       ['fire8/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire8/expand3x3 (Conv2D)       (None, 13, 13, 256)  147712      ['fire8/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire8/relu_expand1x1 (Activati  (None, 13, 13, 256)  0          ['fire8/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire8/relu_expand3x3 (Activati  (None, 13, 13, 256)  0          ['fire8/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire8/concat (Concatenate)     (None, 13, 13, 512)  0           ['fire8/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire8/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " fire9/squeeze1x1 (Conv2D)      (None, 13, 13, 64)   32832       ['fire8/concat[0][0]']           \n",
      "                                                                                                  \n",
      " fire9/relu_squeeze1x1 (Activat  (None, 13, 13, 64)  0           ['fire9/squeeze1x1[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " fire9/expand1x1 (Conv2D)       (None, 13, 13, 256)  16640       ['fire9/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire9/expand3x3 (Conv2D)       (None, 13, 13, 256)  147712      ['fire9/relu_squeeze1x1[0][0]']  \n",
      "                                                                                                  \n",
      " fire9/relu_expand1x1 (Activati  (None, 13, 13, 256)  0          ['fire9/expand1x1[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire9/relu_expand3x3 (Activati  (None, 13, 13, 256)  0          ['fire9/expand3x3[0][0]']        \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " fire9/concat (Concatenate)     (None, 13, 13, 512)  0           ['fire9/relu_expand1x1[0][0]',   \n",
      "                                                                  'fire9/relu_expand3x3[0][0]']   \n",
      "                                                                                                  \n",
      " drop9 (Dropout)                (None, 13, 13, 512)  0           ['fire9/concat[0][0]']           \n",
      "                                                                                                  \n",
      " conv10 (Conv2D)                (None, 13, 13, 1000  513000      ['drop9[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu_conv10 (Activation)       (None, 13, 13, 1000  0           ['conv10[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 1000)        0           ['relu_conv10[0][0]']            \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1000)         0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            3003        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,238,499\n",
      "Trainable params: 3,003\n",
      "Non-trainable params: 1,235,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "\n",
    "base_model = SqueezeNet(input_shape=(224,224,3))\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "snet_extract = base_model.layers[-3].output\n",
    "snet_extract = tf.keras.layers.GlobalAveragePooling2D()(snet_extract)\n",
    "snet_extract = tf.keras.layers.Dropout(0.5)(snet_extract)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(snet_extract)\n",
    "\n",
    "squeezenet_model = Model(base_model.input, output)\n",
    "squeezenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b098988f",
   "metadata": {},
   "source": [
    "#### Keras Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d2d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs-\"+dt.datetime.now().strftime(\"%m%d%Y%H%M%S\"),\n",
    "                            histogram_freq=0,\n",
    "                            write_graph=False,\n",
    "                            update_freq='epoch')\n",
    "\n",
    "def epoch_end(epoch, logs):\n",
    "    message = \"End of epoch \"+str(epoch)+\". Learning rate: \"+str(K.eval(squeezenet_model.optimizer.lr))\n",
    "    os.system('echo '+message)\n",
    "\n",
    "def epoch_begin(epoch, logs):\n",
    "    print(\"Learning rate: \", K.eval(squeezenet_model.optimizer.lr))\n",
    "    \n",
    "def train_begin(logs):\n",
    "    os.system(\"echo Beginning training\")\n",
    "    \n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVED_FILE,\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             save_weights_only=False,\n",
    "                             save_freq='epoch')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta = 1e-4, \n",
    "                          patience=30,\n",
    "                          verbose=1,\n",
    "                          mode='min',\n",
    "                          baseline=None,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                             factor=np.sqrt(.1),\n",
    "                             patience=10,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             min_delta=.0001,\n",
    "                             cooldown=0,\n",
    "                             min_lr=0.0000001)\n",
    "\n",
    "lambdacb = LambdaCallback(on_epoch_begin=epoch_begin,\n",
    "                          on_epoch_end=epoch_end,\n",
    "                          on_batch_begin=None,\n",
    "                          on_batch_end=None,\n",
    "                          on_train_begin=train_begin,\n",
    "                          on_train_end=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022f5c8",
   "metadata": {},
   "source": [
    "#### Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6efa8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7566 images belonging to 3 classes.\n",
      "Found 1551 images belonging to 3 classes.\n",
      "train class indices: {'health': 0, 'sick': 1, 'tb': 2}\n",
      "class weights: {0: 0.7479240806642942, 1: 0.8135483870967742, 2: 2.3053016453382082}\n",
      "samples for train class labels: dict_items([(0, 3372), (1, 3100), (2, 1094)])\n",
      "\n",
      "\n",
      "validation class indices: {'health': 0, 'sick': 1, 'tb': 2}\n",
      "samples for validation class labels: dict_items([(0, 702), (1, 600), (2, 249)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "#train data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.3,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=20,\n",
    "    brightness_range = [0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        class_mode= CLASS_MODE)\n",
    "\n",
    "#validation imagedatagenerator\n",
    "test_datagen = ImageDataGenerator()\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        VALIDATION_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        seed=42,\n",
    "        class_mode=CLASS_MODE)\n",
    "from collections import Counter\n",
    "print('train class indices:',train_generator.class_indices)\n",
    "counter = Counter(train_generator.classes)\n",
    "\n",
    "total_train = 0\n",
    "num_classes = 0\n",
    "for cls_idx,item in counter.items():\n",
    "    total_train += item\n",
    "    num_classes += 1\n",
    "\n",
    "class_weights = {}\n",
    "for cls_idx,weight in counter.items():\n",
    "    cls_weight = total_train/(weight*num_classes)\n",
    "    class_weights[cls_idx] = cls_weight\n",
    "\n",
    "print('class weights:',class_weights)\n",
    "print('samples for train class labels:',counter.items())\n",
    "print('\\n')\n",
    "\n",
    "print('validation class indices:',validation_generator.class_indices)\n",
    "counter = Counter(validation_generator.classes)\n",
    "print('samples for validation class labels:',counter.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ff2b1",
   "metadata": {},
   "source": [
    "#### SqueezeNet Compilation and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c366c645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "squeezenet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8102990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  0.001\n",
      "Epoch 1/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 11.1288 - accuracy: 0.3861 - AUC: 0.5493 - precision: 0.3864 - recall: 0.3855\n",
      "Epoch 00001: val_loss improved from inf to 2.86493, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 0. Learning rate: 0.001\n",
      "237/237 [==============================] - 105s 437ms/step - loss: 11.1288 - accuracy: 0.3861 - AUC: 0.5493 - precision: 0.3864 - recall: 0.3855 - val_loss: 2.8649 - val_accuracy: 0.6738 - val_AUC: 0.8032 - val_precision: 0.6738 - val_recall: 0.6738 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 7.6931 - accuracy: 0.4391 - AUC: 0.5985 - precision: 0.4394 - recall: 0.4383\n",
      "Epoch 00002: val_loss improved from 2.86493 to 1.39793, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 1. Learning rate: 0.001\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 7.6931 - accuracy: 0.4391 - AUC: 0.5985 - precision: 0.4394 - recall: 0.4383 - val_loss: 1.3979 - val_accuracy: 0.7266 - val_AUC: 0.8594 - val_precision: 0.7326 - val_recall: 0.7189 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 5.2008 - accuracy: 0.4872 - AUC: 0.6453 - precision: 0.4882 - recall: 0.4849\n",
      "Epoch 00003: val_loss improved from 1.39793 to 1.04293, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 2. Learning rate: 0.001\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 5.2008 - accuracy: 0.4872 - AUC: 0.6453 - precision: 0.4882 - recall: 0.4849 - val_loss: 1.0429 - val_accuracy: 0.7582 - val_AUC: 0.8856 - val_precision: 0.7668 - val_recall: 0.7524 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.6973 - accuracy: 0.5116 - AUC: 0.6765 - precision: 0.5128 - recall: 0.5087\n",
      "Epoch 00004: val_loss improved from 1.04293 to 0.81140, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 3. Learning rate: 0.001\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 3.6973 - accuracy: 0.5116 - AUC: 0.6765 - precision: 0.5128 - recall: 0.5087 - val_loss: 0.8114 - val_accuracy: 0.7692 - val_AUC: 0.9011 - val_precision: 0.7758 - val_recall: 0.7608 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.9668 - accuracy: 0.5148 - AUC: 0.6851 - precision: 0.5168 - recall: 0.5100\n",
      "Epoch 00005: val_loss did not improve from 0.81140\n",
      "End of epoch 4. Learning rate: 0.001\n",
      "237/237 [==============================] - 100s 422ms/step - loss: 2.9668 - accuracy: 0.5148 - AUC: 0.6851 - precision: 0.5168 - recall: 0.5100 - val_loss: 3.9953 - val_accuracy: 0.2012 - val_AUC: 0.5320 - val_precision: 0.2006 - val_recall: 0.2005 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.6439 - accuracy: 0.5040 - AUC: 0.6830 - precision: 0.5077 - recall: 0.4976\n",
      "Epoch 00006: val_loss did not improve from 0.81140\n",
      "End of epoch 5. Learning rate: 0.001\n",
      "237/237 [==============================] - 101s 427ms/step - loss: 2.6439 - accuracy: 0.5040 - AUC: 0.6830 - precision: 0.5077 - recall: 0.4976 - val_loss: 1.6245 - val_accuracy: 0.4823 - val_AUC: 0.6877 - val_precision: 0.4822 - val_recall: 0.4623 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.3667 - accuracy: 0.5075 - AUC: 0.6912 - precision: 0.5109 - recall: 0.5008\n",
      "Epoch 00007: val_loss did not improve from 0.81140\n",
      "End of epoch 6. Learning rate: 0.001\n",
      "237/237 [==============================] - 103s 433ms/step - loss: 2.3667 - accuracy: 0.5075 - AUC: 0.6912 - precision: 0.5109 - recall: 0.5008 - val_loss: 3.1576 - val_accuracy: 0.1973 - val_AUC: 0.5553 - val_precision: 0.1968 - val_recall: 0.1966 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.4172 - accuracy: 0.4997 - AUC: 0.6735 - precision: 0.5034 - recall: 0.4910\n",
      "Epoch 00008: val_loss did not improve from 0.81140\n",
      "End of epoch 7. Learning rate: 0.001\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 2.4172 - accuracy: 0.4997 - AUC: 0.6735 - precision: 0.5034 - recall: 0.4910 - val_loss: 0.9087 - val_accuracy: 0.6486 - val_AUC: 0.8404 - val_precision: 0.6639 - val_recall: 0.6202 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.2158 - accuracy: 0.4988 - AUC: 0.6761 - precision: 0.5031 - recall: 0.4902\n",
      "Epoch 00009: val_loss improved from 0.81140 to 0.70766, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 8. Learning rate: 0.001\n",
      "237/237 [==============================] - 102s 432ms/step - loss: 2.2158 - accuracy: 0.4988 - AUC: 0.6761 - precision: 0.5031 - recall: 0.4902 - val_loss: 0.7077 - val_accuracy: 0.7653 - val_AUC: 0.8837 - val_precision: 0.7882 - val_recall: 0.7247 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.1334 - accuracy: 0.5025 - AUC: 0.6800 - precision: 0.5096 - recall: 0.4925\n",
      "Epoch 00010: val_loss did not improve from 0.70766\n",
      "End of epoch 9. Learning rate: 0.001\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 2.1334 - accuracy: 0.5025 - AUC: 0.6800 - precision: 0.5096 - recall: 0.4925 - val_loss: 0.9349 - val_accuracy: 0.6834 - val_AUC: 0.8201 - val_precision: 0.7093 - val_recall: 0.6370 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.2237 - accuracy: 0.5081 - AUC: 0.6829 - precision: 0.5126 - recall: 0.4981\n",
      "Epoch 00011: val_loss did not improve from 0.70766\n",
      "End of epoch 10. Learning rate: 0.001\n",
      "237/237 [==============================] - 103s 433ms/step - loss: 2.2237 - accuracy: 0.5081 - AUC: 0.6829 - precision: 0.5126 - recall: 0.4981 - val_loss: 1.1353 - val_accuracy: 0.5758 - val_AUC: 0.7513 - val_precision: 0.5917 - val_recall: 0.5429 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.1927 - accuracy: 0.4943 - AUC: 0.6726 - precision: 0.4988 - recall: 0.4836\n",
      "Epoch 00012: val_loss did not improve from 0.70766\n",
      "End of epoch 11. Learning rate: 0.001\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 2.1927 - accuracy: 0.4943 - AUC: 0.6726 - precision: 0.4988 - recall: 0.4836 - val_loss: 0.8640 - val_accuracy: 0.6647 - val_AUC: 0.8296 - val_precision: 0.6923 - val_recall: 0.6209 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.3775 - accuracy: 0.4886 - AUC: 0.6679 - precision: 0.4925 - recall: 0.4789\n",
      "Epoch 00013: val_loss did not improve from 0.70766\n",
      "End of epoch 12. Learning rate: 0.001\n",
      "237/237 [==============================] - 104s 439ms/step - loss: 2.3775 - accuracy: 0.4886 - AUC: 0.6679 - precision: 0.4925 - recall: 0.4789 - val_loss: 2.1037 - val_accuracy: 0.3469 - val_AUC: 0.5984 - val_precision: 0.3500 - val_recall: 0.3424 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.2109 - accuracy: 0.5044 - AUC: 0.6828 - precision: 0.5077 - recall: 0.4944\n",
      "Epoch 00014: val_loss did not improve from 0.70766\n",
      "End of epoch 13. Learning rate: 0.001\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 2.2109 - accuracy: 0.5044 - AUC: 0.6828 - precision: 0.5077 - recall: 0.4944 - val_loss: 0.8650 - val_accuracy: 0.6512 - val_AUC: 0.8403 - val_precision: 0.6730 - val_recall: 0.6144 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/15\n",
      "237/237 [==============================] - ETA: 0s - loss: 2.0189 - accuracy: 0.5099 - AUC: 0.6915 - precision: 0.5149 - recall: 0.4963"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "epochs = 15\n",
    "history = squeezenet_model.fit(train_generator, \n",
    "                                steps_per_epoch=len(train_generator), \n",
    "                                validation_data=validation_generator, \n",
    "                                epochs=epochs,\n",
    "                                verbose = 1,\n",
    "                                class_weight = class_weights,\n",
    "                                callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6afbfd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(8, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.plot(history.epoch, history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training and Validation loss')\n",
    "plt.plot(history.epoch, history.history['loss'], label='Training loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.plot(history.epoch, history.history['AUC'], label='Training AUC')\n",
    "plt.plot(history.epoch, history.history['val_AUC'], label='Validation AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d167055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.215804</td>\n",
       "      <td>0.498810</td>\n",
       "      <td>0.676070</td>\n",
       "      <td>0.503120</td>\n",
       "      <td>0.490219</td>\n",
       "      <td>0.707659</td>\n",
       "      <td>0.765313</td>\n",
       "      <td>0.883655</td>\n",
       "      <td>0.788219</td>\n",
       "      <td>0.724694</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.697274</td>\n",
       "      <td>0.511631</td>\n",
       "      <td>0.676451</td>\n",
       "      <td>0.512790</td>\n",
       "      <td>0.508723</td>\n",
       "      <td>0.811396</td>\n",
       "      <td>0.769181</td>\n",
       "      <td>0.901139</td>\n",
       "      <td>0.775805</td>\n",
       "      <td>0.760799</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.192656</td>\n",
       "      <td>0.494317</td>\n",
       "      <td>0.672635</td>\n",
       "      <td>0.498773</td>\n",
       "      <td>0.483611</td>\n",
       "      <td>0.864030</td>\n",
       "      <td>0.664732</td>\n",
       "      <td>0.829588</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.620890</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.210919</td>\n",
       "      <td>0.504362</td>\n",
       "      <td>0.682784</td>\n",
       "      <td>0.507667</td>\n",
       "      <td>0.494449</td>\n",
       "      <td>0.865035</td>\n",
       "      <td>0.651193</td>\n",
       "      <td>0.840348</td>\n",
       "      <td>0.673023</td>\n",
       "      <td>0.614442</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.417168</td>\n",
       "      <td>0.499736</td>\n",
       "      <td>0.673515</td>\n",
       "      <td>0.503388</td>\n",
       "      <td>0.491012</td>\n",
       "      <td>0.908738</td>\n",
       "      <td>0.648614</td>\n",
       "      <td>0.840354</td>\n",
       "      <td>0.663906</td>\n",
       "      <td>0.620245</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.133418</td>\n",
       "      <td>0.502511</td>\n",
       "      <td>0.680044</td>\n",
       "      <td>0.509643</td>\n",
       "      <td>0.492466</td>\n",
       "      <td>0.934909</td>\n",
       "      <td>0.683430</td>\n",
       "      <td>0.820055</td>\n",
       "      <td>0.709261</td>\n",
       "      <td>0.637008</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.200765</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.645265</td>\n",
       "      <td>0.488159</td>\n",
       "      <td>0.484933</td>\n",
       "      <td>1.042933</td>\n",
       "      <td>0.758220</td>\n",
       "      <td>0.885643</td>\n",
       "      <td>0.766754</td>\n",
       "      <td>0.752418</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.223684</td>\n",
       "      <td>0.508062</td>\n",
       "      <td>0.682858</td>\n",
       "      <td>0.512650</td>\n",
       "      <td>0.498150</td>\n",
       "      <td>1.135255</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.751345</td>\n",
       "      <td>0.591708</td>\n",
       "      <td>0.542876</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.018909</td>\n",
       "      <td>0.509913</td>\n",
       "      <td>0.691473</td>\n",
       "      <td>0.514877</td>\n",
       "      <td>0.496299</td>\n",
       "      <td>1.193717</td>\n",
       "      <td>0.708575</td>\n",
       "      <td>0.836313</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.708575</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.693104</td>\n",
       "      <td>0.439070</td>\n",
       "      <td>0.598528</td>\n",
       "      <td>0.439380</td>\n",
       "      <td>0.438276</td>\n",
       "      <td>1.397934</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.859405</td>\n",
       "      <td>0.732589</td>\n",
       "      <td>0.718891</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.643925</td>\n",
       "      <td>0.503965</td>\n",
       "      <td>0.682975</td>\n",
       "      <td>0.507686</td>\n",
       "      <td>0.497621</td>\n",
       "      <td>1.624543</td>\n",
       "      <td>0.482269</td>\n",
       "      <td>0.687705</td>\n",
       "      <td>0.482179</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.377475</td>\n",
       "      <td>0.488633</td>\n",
       "      <td>0.667950</td>\n",
       "      <td>0.492523</td>\n",
       "      <td>0.478853</td>\n",
       "      <td>2.103717</td>\n",
       "      <td>0.346873</td>\n",
       "      <td>0.598416</td>\n",
       "      <td>0.350033</td>\n",
       "      <td>0.342360</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.128841</td>\n",
       "      <td>0.386069</td>\n",
       "      <td>0.549275</td>\n",
       "      <td>0.386409</td>\n",
       "      <td>0.385541</td>\n",
       "      <td>2.864925</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.803172</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.366678</td>\n",
       "      <td>0.507534</td>\n",
       "      <td>0.691238</td>\n",
       "      <td>0.510853</td>\n",
       "      <td>0.500793</td>\n",
       "      <td>3.157564</td>\n",
       "      <td>0.197292</td>\n",
       "      <td>0.555301</td>\n",
       "      <td>0.196774</td>\n",
       "      <td>0.196647</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.966826</td>\n",
       "      <td>0.514803</td>\n",
       "      <td>0.685112</td>\n",
       "      <td>0.516807</td>\n",
       "      <td>0.510045</td>\n",
       "      <td>3.995314</td>\n",
       "      <td>0.201161</td>\n",
       "      <td>0.531961</td>\n",
       "      <td>0.200645</td>\n",
       "      <td>0.200516</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  accuracy       AUC  precision    recall  val_loss  \\\n",
       "epoch                                                                 \n",
       "8       2.215804  0.498810  0.676070   0.503120  0.490219  0.707659   \n",
       "3       3.697274  0.511631  0.676451   0.512790  0.508723  0.811396   \n",
       "11      2.192656  0.494317  0.672635   0.498773  0.483611  0.864030   \n",
       "13      2.210919  0.504362  0.682784   0.507667  0.494449  0.865035   \n",
       "7       2.417168  0.499736  0.673515   0.503388  0.491012  0.908738   \n",
       "9       2.133418  0.502511  0.680044   0.509643  0.492466  0.934909   \n",
       "2       5.200765  0.487179  0.645265   0.488159  0.484933  1.042933   \n",
       "10      2.223684  0.508062  0.682858   0.512650  0.498150  1.135255   \n",
       "14      2.018909  0.509913  0.691473   0.514877  0.496299  1.193717   \n",
       "1       7.693104  0.439070  0.598528   0.439380  0.438276  1.397934   \n",
       "5       2.643925  0.503965  0.682975   0.507686  0.497621  1.624543   \n",
       "12      2.377475  0.488633  0.667950   0.492523  0.478853  2.103717   \n",
       "0      11.128841  0.386069  0.549275   0.386409  0.385541  2.864925   \n",
       "6       2.366678  0.507534  0.691238   0.510853  0.500793  3.157564   \n",
       "4       2.966826  0.514803  0.685112   0.516807  0.510045  3.995314   \n",
       "\n",
       "       val_accuracy   val_AUC  val_precision  val_recall     lr  \n",
       "epoch                                                            \n",
       "8          0.765313  0.883655       0.788219    0.724694  0.001  \n",
       "3          0.769181  0.901139       0.775805    0.760799  0.001  \n",
       "11         0.664732  0.829588       0.692308    0.620890  0.001  \n",
       "13         0.651193  0.840348       0.673023    0.614442  0.001  \n",
       "7          0.648614  0.840354       0.663906    0.620245  0.001  \n",
       "9          0.683430  0.820055       0.709261    0.637008  0.001  \n",
       "2          0.758220  0.885643       0.766754    0.752418  0.001  \n",
       "10         0.575758  0.751345       0.591708    0.542876  0.001  \n",
       "14         0.708575  0.836313       0.713636    0.708575  0.001  \n",
       "1          0.726628  0.859405       0.732589    0.718891  0.001  \n",
       "5          0.482269  0.687705       0.482179    0.462282  0.001  \n",
       "12         0.346873  0.598416       0.350033    0.342360  0.001  \n",
       "0          0.673759  0.803172       0.673759    0.673759  0.001  \n",
       "6          0.197292  0.555301       0.196774    0.196647  0.001  \n",
       "4          0.201161  0.531961       0.200645    0.200516  0.001  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3d91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b031f009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-04\n",
      "Epoch 15/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8029 - AUC: 0.9361 - precision: 0.8409 - recall: 0.7635\n",
      "Epoch 00015: val_loss improved from 0.70766 to 0.35086, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 14. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 423ms/step - loss: 0.4936 - accuracy: 0.8029 - AUC: 0.9361 - precision: 0.8409 - recall: 0.7635 - val_loss: 0.3509 - val_accuracy: 0.8588 - val_AUC: 0.9677 - val_precision: 0.8760 - val_recall: 0.8472 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 16/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.8931 - AUC: 0.9768 - precision: 0.9092 - recall: 0.8739\n",
      "Epoch 00016: val_loss did not improve from 0.35086\n",
      "End of epoch 15. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 426ms/step - loss: 0.2932 - accuracy: 0.8931 - AUC: 0.9768 - precision: 0.9092 - recall: 0.8739 - val_loss: 0.7342 - val_accuracy: 0.7453 - val_AUC: 0.8987 - val_precision: 0.7613 - val_recall: 0.7299 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 17/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.9052 - AUC: 0.9826 - precision: 0.9206 - recall: 0.8931\n",
      "Epoch 00017: val_loss did not improve from 0.35086\n",
      "End of epoch 16. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 426ms/step - loss: 0.2506 - accuracy: 0.9052 - AUC: 0.9826 - precision: 0.9206 - recall: 0.8931 - val_loss: 0.5208 - val_accuracy: 0.8137 - val_AUC: 0.9424 - val_precision: 0.8209 - val_recall: 0.8098 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 18/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9194 - AUC: 0.9875 - precision: 0.9285 - recall: 0.9092\n",
      "Epoch 00018: val_loss did not improve from 0.35086\n",
      "End of epoch 17. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 425ms/step - loss: 0.2114 - accuracy: 0.9194 - AUC: 0.9875 - precision: 0.9285 - recall: 0.9092 - val_loss: 0.4511 - val_accuracy: 0.8317 - val_AUC: 0.9503 - val_precision: 0.8437 - val_recall: 0.8214 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 19/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9245 - AUC: 0.9893 - precision: 0.9328 - recall: 0.9151\n",
      "Epoch 00019: val_loss improved from 0.35086 to 0.34590, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 18. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.1950 - accuracy: 0.9245 - AUC: 0.9893 - precision: 0.9328 - recall: 0.9151 - val_loss: 0.3459 - val_accuracy: 0.8678 - val_AUC: 0.9691 - val_precision: 0.8696 - val_recall: 0.8601 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 20/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9297 - AUC: 0.9902 - precision: 0.9372 - recall: 0.9216\n",
      "Epoch 00020: val_loss improved from 0.34590 to 0.25431, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 19. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 423ms/step - loss: 0.1862 - accuracy: 0.9297 - AUC: 0.9902 - precision: 0.9372 - recall: 0.9216 - val_loss: 0.2543 - val_accuracy: 0.9078 - val_AUC: 0.9818 - val_precision: 0.9131 - val_recall: 0.9007 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 21/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.9376 - AUC: 0.9924 - precision: 0.9451 - recall: 0.9333\n",
      "Epoch 00021: val_loss did not improve from 0.25431\n",
      "End of epoch 20. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 422ms/step - loss: 0.1606 - accuracy: 0.9376 - AUC: 0.9924 - precision: 0.9451 - recall: 0.9333 - val_loss: 0.6815 - val_accuracy: 0.7685 - val_AUC: 0.9185 - val_precision: 0.7772 - val_recall: 0.7602 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 22/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.9374 - AUC: 0.9918 - precision: 0.9434 - recall: 0.9302\n",
      "Epoch 00022: val_loss did not improve from 0.25431\n",
      "End of epoch 21. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 417ms/step - loss: 0.1669 - accuracy: 0.9374 - AUC: 0.9918 - precision: 0.9434 - recall: 0.9302 - val_loss: 0.3013 - val_accuracy: 0.8878 - val_AUC: 0.9759 - val_precision: 0.8922 - val_recall: 0.8807 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 23/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9434 - AUC: 0.9931 - precision: 0.9496 - recall: 0.9383\n",
      "Epoch 00023: val_loss did not improve from 0.25431\n",
      "End of epoch 22. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 418ms/step - loss: 0.1526 - accuracy: 0.9434 - AUC: 0.9931 - precision: 0.9496 - recall: 0.9383 - val_loss: 0.5109 - val_accuracy: 0.8414 - val_AUC: 0.9457 - val_precision: 0.8428 - val_recall: 0.8362 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 24/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9437 - AUC: 0.9925 - precision: 0.9501 - recall: 0.9383\n",
      "Epoch 00024: val_loss did not improve from 0.25431\n",
      "End of epoch 23. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 420ms/step - loss: 0.1573 - accuracy: 0.9437 - AUC: 0.9925 - precision: 0.9501 - recall: 0.9383 - val_loss: 0.4409 - val_accuracy: 0.8407 - val_AUC: 0.9557 - val_precision: 0.8470 - val_recall: 0.8317 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 25/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9422 - AUC: 0.9936 - precision: 0.9485 - recall: 0.9389\n",
      "Epoch 00025: val_loss improved from 0.25431 to 0.21337, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 24. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 416ms/step - loss: 0.1481 - accuracy: 0.9422 - AUC: 0.9936 - precision: 0.9485 - recall: 0.9389 - val_loss: 0.2134 - val_accuracy: 0.9130 - val_AUC: 0.9872 - val_precision: 0.9177 - val_recall: 0.9059 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 26/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9458 - AUC: 0.9938 - precision: 0.9531 - recall: 0.9405\n",
      "Epoch 00026: val_loss did not improve from 0.21337\n",
      "End of epoch 25. Learning rate: 1e-04\n",
      "237/237 [==============================] - 98s 415ms/step - loss: 0.1438 - accuracy: 0.9458 - AUC: 0.9938 - precision: 0.9531 - recall: 0.9405 - val_loss: 0.2555 - val_accuracy: 0.8968 - val_AUC: 0.9825 - val_precision: 0.9005 - val_recall: 0.8930 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 27/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9500 - AUC: 0.9943 - precision: 0.9531 - recall: 0.9457\n",
      "Epoch 00027: val_loss did not improve from 0.21337\n",
      "End of epoch 26. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 417ms/step - loss: 0.1353 - accuracy: 0.9500 - AUC: 0.9943 - precision: 0.9531 - recall: 0.9457 - val_loss: 0.3522 - val_accuracy: 0.8801 - val_AUC: 0.9715 - val_precision: 0.8815 - val_recall: 0.8775 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 28/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9433 - AUC: 0.9932 - precision: 0.9503 - recall: 0.9381\n",
      "Epoch 00028: val_loss did not improve from 0.21337\n",
      "End of epoch 27. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 421ms/step - loss: 0.1497 - accuracy: 0.9433 - AUC: 0.9932 - precision: 0.9503 - recall: 0.9381 - val_loss: 0.3961 - val_accuracy: 0.8524 - val_AUC: 0.9606 - val_precision: 0.8562 - val_recall: 0.8446 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 29/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9490 - AUC: 0.9939 - precision: 0.9536 - recall: 0.9442\n",
      "Epoch 00029: val_loss improved from 0.21337 to 0.18461, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 28. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 418ms/step - loss: 0.1384 - accuracy: 0.9490 - AUC: 0.9939 - precision: 0.9536 - recall: 0.9442 - val_loss: 0.1846 - val_accuracy: 0.9336 - val_AUC: 0.9902 - val_precision: 0.9388 - val_recall: 0.9291 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 30/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9523 - AUC: 0.9950 - precision: 0.9562 - recall: 0.9485\n",
      "Epoch 00030: val_loss did not improve from 0.18461\n",
      "End of epoch 29. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 418ms/step - loss: 0.1265 - accuracy: 0.9523 - AUC: 0.9950 - precision: 0.9562 - recall: 0.9485 - val_loss: 0.2009 - val_accuracy: 0.9297 - val_AUC: 0.9872 - val_precision: 0.9325 - val_recall: 0.9259 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 31/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9572 - AUC: 0.9958 - precision: 0.9601 - recall: 0.9537\n",
      "Epoch 00031: val_loss improved from 0.18461 to 0.18261, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 30. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 419ms/step - loss: 0.1154 - accuracy: 0.9572 - AUC: 0.9958 - precision: 0.9601 - recall: 0.9537 - val_loss: 0.1826 - val_accuracy: 0.9304 - val_AUC: 0.9901 - val_precision: 0.9320 - val_recall: 0.9271 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 32/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9540 - AUC: 0.9956 - precision: 0.9574 - recall: 0.9502\n",
      "Epoch 00032: val_loss improved from 0.18261 to 0.18102, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 31. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 424ms/step - loss: 0.1194 - accuracy: 0.9540 - AUC: 0.9956 - precision: 0.9574 - recall: 0.9502 - val_loss: 0.1810 - val_accuracy: 0.9323 - val_AUC: 0.9906 - val_precision: 0.9350 - val_recall: 0.9278 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 33/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9593 - AUC: 0.9960 - precision: 0.9624 - recall: 0.9572\n",
      "Epoch 00033: val_loss did not improve from 0.18102\n",
      "End of epoch 32. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 420ms/step - loss: 0.1102 - accuracy: 0.9593 - AUC: 0.9960 - precision: 0.9624 - recall: 0.9572 - val_loss: 0.2012 - val_accuracy: 0.9207 - val_AUC: 0.9879 - val_precision: 0.9245 - val_recall: 0.9155 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 34/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9547 - AUC: 0.9956 - precision: 0.9585 - recall: 0.9519\n",
      "Epoch 00034: val_loss improved from 0.18102 to 0.15755, saving model to ./weights/squeezenet_3channel_scratch.hdf5\n",
      "End of epoch 33. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 418ms/step - loss: 0.1182 - accuracy: 0.9547 - AUC: 0.9956 - precision: 0.9585 - recall: 0.9519 - val_loss: 0.1576 - val_accuracy: 0.9387 - val_AUC: 0.9927 - val_precision: 0.9393 - val_recall: 0.9375 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 35/35\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9596 - AUC: 0.9963 - precision: 0.9629 - recall: 0.9565\n",
      "Epoch 00035: val_loss did not improve from 0.15755\n",
      "End of epoch 34. Learning rate: 1e-04\n",
      "237/237 [==============================] - 99s 417ms/step - loss: 0.1076 - accuracy: 0.9596 - AUC: 0.9963 - precision: 0.9629 - recall: 0.9565 - val_loss: 0.3363 - val_accuracy: 0.8891 - val_AUC: 0.9733 - val_precision: 0.8903 - val_recall: 0.8846 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "squeezenet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")\n",
    "\n",
    "history_finetune = squeezenet_model.fit(train_generator,\n",
    "                            epochs=35,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            initial_epoch=history.epoch[-1],\n",
    "                            callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e78e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.118161</td>\n",
       "      <td>0.954666</td>\n",
       "      <td>0.995642</td>\n",
       "      <td>0.958477</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>0.157553</td>\n",
       "      <td>0.938749</td>\n",
       "      <td>0.992693</td>\n",
       "      <td>0.939276</td>\n",
       "      <td>0.937460</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.119396</td>\n",
       "      <td>0.954005</td>\n",
       "      <td>0.995639</td>\n",
       "      <td>0.957384</td>\n",
       "      <td>0.950172</td>\n",
       "      <td>0.181021</td>\n",
       "      <td>0.932302</td>\n",
       "      <td>0.990592</td>\n",
       "      <td>0.935023</td>\n",
       "      <td>0.927788</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.115359</td>\n",
       "      <td>0.957177</td>\n",
       "      <td>0.995792</td>\n",
       "      <td>0.960085</td>\n",
       "      <td>0.953740</td>\n",
       "      <td>0.182614</td>\n",
       "      <td>0.930368</td>\n",
       "      <td>0.990066</td>\n",
       "      <td>0.931951</td>\n",
       "      <td>0.927144</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.138437</td>\n",
       "      <td>0.948982</td>\n",
       "      <td>0.993863</td>\n",
       "      <td>0.953550</td>\n",
       "      <td>0.944224</td>\n",
       "      <td>0.184608</td>\n",
       "      <td>0.933591</td>\n",
       "      <td>0.990222</td>\n",
       "      <td>0.938762</td>\n",
       "      <td>0.929078</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.126494</td>\n",
       "      <td>0.952287</td>\n",
       "      <td>0.995016</td>\n",
       "      <td>0.956163</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.200940</td>\n",
       "      <td>0.929723</td>\n",
       "      <td>0.987226</td>\n",
       "      <td>0.932468</td>\n",
       "      <td>0.925854</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.110245</td>\n",
       "      <td>0.959292</td>\n",
       "      <td>0.995999</td>\n",
       "      <td>0.962392</td>\n",
       "      <td>0.957177</td>\n",
       "      <td>0.201198</td>\n",
       "      <td>0.920696</td>\n",
       "      <td>0.987933</td>\n",
       "      <td>0.924479</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.148079</td>\n",
       "      <td>0.942242</td>\n",
       "      <td>0.993591</td>\n",
       "      <td>0.948465</td>\n",
       "      <td>0.938937</td>\n",
       "      <td>0.213368</td>\n",
       "      <td>0.912959</td>\n",
       "      <td>0.987184</td>\n",
       "      <td>0.917701</td>\n",
       "      <td>0.905867</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.186208</td>\n",
       "      <td>0.929685</td>\n",
       "      <td>0.990240</td>\n",
       "      <td>0.937231</td>\n",
       "      <td>0.921623</td>\n",
       "      <td>0.254307</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>0.981812</td>\n",
       "      <td>0.913072</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.143834</td>\n",
       "      <td>0.945810</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>0.953121</td>\n",
       "      <td>0.940523</td>\n",
       "      <td>0.255510</td>\n",
       "      <td>0.896841</td>\n",
       "      <td>0.982501</td>\n",
       "      <td>0.900520</td>\n",
       "      <td>0.892972</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.166922</td>\n",
       "      <td>0.937351</td>\n",
       "      <td>0.991790</td>\n",
       "      <td>0.943432</td>\n",
       "      <td>0.930214</td>\n",
       "      <td>0.301340</td>\n",
       "      <td>0.887814</td>\n",
       "      <td>0.975901</td>\n",
       "      <td>0.892227</td>\n",
       "      <td>0.880722</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.107560</td>\n",
       "      <td>0.959556</td>\n",
       "      <td>0.996314</td>\n",
       "      <td>0.962879</td>\n",
       "      <td>0.956516</td>\n",
       "      <td>0.336313</td>\n",
       "      <td>0.889104</td>\n",
       "      <td>0.973254</td>\n",
       "      <td>0.890331</td>\n",
       "      <td>0.884591</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.195028</td>\n",
       "      <td>0.924531</td>\n",
       "      <td>0.989278</td>\n",
       "      <td>0.932777</td>\n",
       "      <td>0.915147</td>\n",
       "      <td>0.345905</td>\n",
       "      <td>0.867827</td>\n",
       "      <td>0.969071</td>\n",
       "      <td>0.869622</td>\n",
       "      <td>0.860090</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493560</td>\n",
       "      <td>0.802934</td>\n",
       "      <td>0.936102</td>\n",
       "      <td>0.840902</td>\n",
       "      <td>0.763547</td>\n",
       "      <td>0.350865</td>\n",
       "      <td>0.858801</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.847195</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.135297</td>\n",
       "      <td>0.950040</td>\n",
       "      <td>0.994275</td>\n",
       "      <td>0.953110</td>\n",
       "      <td>0.945678</td>\n",
       "      <td>0.352203</td>\n",
       "      <td>0.880077</td>\n",
       "      <td>0.971465</td>\n",
       "      <td>0.881477</td>\n",
       "      <td>0.877498</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.149732</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.993202</td>\n",
       "      <td>0.950328</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.396142</td>\n",
       "      <td>0.852353</td>\n",
       "      <td>0.960606</td>\n",
       "      <td>0.856209</td>\n",
       "      <td>0.844616</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.157339</td>\n",
       "      <td>0.943695</td>\n",
       "      <td>0.992487</td>\n",
       "      <td>0.950080</td>\n",
       "      <td>0.938277</td>\n",
       "      <td>0.440857</td>\n",
       "      <td>0.840748</td>\n",
       "      <td>0.955693</td>\n",
       "      <td>0.847012</td>\n",
       "      <td>0.831721</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211448</td>\n",
       "      <td>0.919376</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.928465</td>\n",
       "      <td>0.909199</td>\n",
       "      <td>0.451119</td>\n",
       "      <td>0.831721</td>\n",
       "      <td>0.950325</td>\n",
       "      <td>0.843709</td>\n",
       "      <td>0.821406</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.152621</td>\n",
       "      <td>0.943431</td>\n",
       "      <td>0.993091</td>\n",
       "      <td>0.949572</td>\n",
       "      <td>0.938277</td>\n",
       "      <td>0.510950</td>\n",
       "      <td>0.841393</td>\n",
       "      <td>0.945733</td>\n",
       "      <td>0.842755</td>\n",
       "      <td>0.836235</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250591</td>\n",
       "      <td>0.905234</td>\n",
       "      <td>0.982572</td>\n",
       "      <td>0.920572</td>\n",
       "      <td>0.893074</td>\n",
       "      <td>0.520771</td>\n",
       "      <td>0.813669</td>\n",
       "      <td>0.942444</td>\n",
       "      <td>0.820915</td>\n",
       "      <td>0.809800</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.160584</td>\n",
       "      <td>0.937616</td>\n",
       "      <td>0.992389</td>\n",
       "      <td>0.945121</td>\n",
       "      <td>0.933254</td>\n",
       "      <td>0.681506</td>\n",
       "      <td>0.768536</td>\n",
       "      <td>0.918520</td>\n",
       "      <td>0.777192</td>\n",
       "      <td>0.760155</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.293166</td>\n",
       "      <td>0.893074</td>\n",
       "      <td>0.976768</td>\n",
       "      <td>0.909241</td>\n",
       "      <td>0.873910</td>\n",
       "      <td>0.734154</td>\n",
       "      <td>0.745326</td>\n",
       "      <td>0.898712</td>\n",
       "      <td>0.761264</td>\n",
       "      <td>0.729852</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy       AUC  precision    recall  val_loss  \\\n",
       "epoch                                                                \n",
       "19     0.118161  0.954666  0.995642   0.958477  0.951890  0.157553   \n",
       "17     0.119396  0.954005  0.995639   0.957384  0.950172  0.181021   \n",
       "16     0.115359  0.957177  0.995792   0.960085  0.953740  0.182614   \n",
       "14     0.138437  0.948982  0.993863   0.953550  0.944224  0.184608   \n",
       "15     0.126494  0.952287  0.995016   0.956163  0.948454  0.200940   \n",
       "18     0.110245  0.959292  0.995999   0.962392  0.957177  0.201198   \n",
       "10     0.148079  0.942242  0.993591   0.948465  0.938937  0.213368   \n",
       "5      0.186208  0.929685  0.990240   0.937231  0.921623  0.254307   \n",
       "11     0.143834  0.945810  0.993800   0.953121  0.940523  0.255510   \n",
       "7      0.166922  0.937351  0.991790   0.943432  0.930214  0.301340   \n",
       "20     0.107560  0.959556  0.996314   0.962879  0.956516  0.336313   \n",
       "4      0.195028  0.924531  0.989278   0.932777  0.915147  0.345905   \n",
       "0      0.493560  0.802934  0.936102   0.840902  0.763547  0.350865   \n",
       "12     0.135297  0.950040  0.994275   0.953110  0.945678  0.352203   \n",
       "13     0.149732  0.943299  0.993202   0.950328  0.938144  0.396142   \n",
       "9      0.157339  0.943695  0.992487   0.950080  0.938277  0.440857   \n",
       "3      0.211448  0.919376  0.987538   0.928465  0.909199  0.451119   \n",
       "8      0.152621  0.943431  0.993091   0.949572  0.938277  0.510950   \n",
       "2      0.250591  0.905234  0.982572   0.920572  0.893074  0.520771   \n",
       "6      0.160584  0.937616  0.992389   0.945121  0.933254  0.681506   \n",
       "1      0.293166  0.893074  0.976768   0.909241  0.873910  0.734154   \n",
       "\n",
       "       val_accuracy   val_AUC  val_precision  val_recall      lr  \n",
       "epoch                                                             \n",
       "19         0.938749  0.992693       0.939276    0.937460  0.0001  \n",
       "17         0.932302  0.990592       0.935023    0.927788  0.0001  \n",
       "16         0.930368  0.990066       0.931951    0.927144  0.0001  \n",
       "14         0.933591  0.990222       0.938762    0.929078  0.0001  \n",
       "15         0.929723  0.987226       0.932468    0.925854  0.0001  \n",
       "18         0.920696  0.987933       0.924479    0.915538  0.0001  \n",
       "10         0.912959  0.987184       0.917701    0.905867  0.0001  \n",
       "5          0.907801  0.981812       0.913072    0.900709  0.0001  \n",
       "11         0.896841  0.982501       0.900520    0.892972  0.0001  \n",
       "7          0.887814  0.975901       0.892227    0.880722  0.0001  \n",
       "20         0.889104  0.973254       0.890331    0.884591  0.0001  \n",
       "4          0.867827  0.969071       0.869622    0.860090  0.0001  \n",
       "0          0.858801  0.967700       0.876000    0.847195  0.0001  \n",
       "12         0.880077  0.971465       0.881477    0.877498  0.0001  \n",
       "13         0.852353  0.960606       0.856209    0.844616  0.0001  \n",
       "9          0.840748  0.955693       0.847012    0.831721  0.0001  \n",
       "3          0.831721  0.950325       0.843709    0.821406  0.0001  \n",
       "8          0.841393  0.945733       0.842755    0.836235  0.0001  \n",
       "2          0.813669  0.942444       0.820915    0.809800  0.0001  \n",
       "6          0.768536  0.918520       0.777192    0.760155  0.0001  \n",
       "1          0.745326  0.898712       0.761264    0.729852  0.0001  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(history_finetune.history) \n",
    "hist_df.index.name='epoch'\n",
    "hist_df.sort_values(by=['val_loss'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cfe0280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-04\n",
      "Epoch 35/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9596 - AUC: 0.9963 - precision: 0.9620 - recall: 0.9561\n",
      "Epoch 00035: val_loss did not improve from 0.15755\n",
      "End of epoch 34. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 421ms/step - loss: 0.1074 - accuracy: 0.9596 - AUC: 0.9963 - precision: 0.9620 - recall: 0.9561 - val_loss: 0.2859 - val_accuracy: 0.9046 - val_AUC: 0.9799 - val_precision: 0.9091 - val_recall: 0.9033 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 36/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9541 - AUC: 0.9958 - precision: 0.9561 - recall: 0.9502\n",
      "Epoch 00036: val_loss did not improve from 0.15755\n",
      "End of epoch 35. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 429ms/step - loss: 0.1189 - accuracy: 0.9541 - AUC: 0.9958 - precision: 0.9561 - recall: 0.9502 - val_loss: 0.2453 - val_accuracy: 0.9104 - val_AUC: 0.9827 - val_precision: 0.9119 - val_recall: 0.9072 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 37/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9592 - AUC: 0.9961 - precision: 0.9613 - recall: 0.9565\n",
      "Epoch 00037: val_loss did not improve from 0.15755\n",
      "End of epoch 36. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 426ms/step - loss: 0.1094 - accuracy: 0.9592 - AUC: 0.9961 - precision: 0.9613 - recall: 0.9565 - val_loss: 0.3080 - val_accuracy: 0.8897 - val_AUC: 0.9748 - val_precision: 0.8932 - val_recall: 0.8839 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 38/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9593 - AUC: 0.9961 - precision: 0.9616 - recall: 0.9564\n",
      "Epoch 00038: val_loss did not improve from 0.15755\n",
      "End of epoch 37. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 422ms/step - loss: 0.1090 - accuracy: 0.9593 - AUC: 0.9961 - precision: 0.9616 - recall: 0.9564 - val_loss: 0.4074 - val_accuracy: 0.8672 - val_AUC: 0.9569 - val_precision: 0.8724 - val_recall: 0.8594 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 39/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9622 - AUC: 0.9964 - precision: 0.9649 - recall: 0.9598\n",
      "Epoch 00039: val_loss did not improve from 0.15755\n",
      "End of epoch 38. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 425ms/step - loss: 0.1040 - accuracy: 0.9622 - AUC: 0.9964 - precision: 0.9649 - recall: 0.9598 - val_loss: 0.3413 - val_accuracy: 0.8827 - val_AUC: 0.9708 - val_precision: 0.8860 - val_recall: 0.8769 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 40/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9606 - AUC: 0.9963 - precision: 0.9627 - recall: 0.9577\n",
      "Epoch 00040: val_loss did not improve from 0.15755\n",
      "End of epoch 39. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 424ms/step - loss: 0.1052 - accuracy: 0.9606 - AUC: 0.9963 - precision: 0.9627 - recall: 0.9577 - val_loss: 0.4986 - val_accuracy: 0.8453 - val_AUC: 0.9505 - val_precision: 0.8503 - val_recall: 0.8388 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 41/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9625 - AUC: 0.9961 - precision: 0.9657 - recall: 0.9593\n",
      "Epoch 00041: val_loss did not improve from 0.15755\n",
      "End of epoch 40. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 422ms/step - loss: 0.1074 - accuracy: 0.9625 - AUC: 0.9961 - precision: 0.9657 - recall: 0.9593 - val_loss: 0.2712 - val_accuracy: 0.9033 - val_AUC: 0.9793 - val_precision: 0.9082 - val_recall: 0.8994 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 42/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9577 - AUC: 0.9960 - precision: 0.9617 - recall: 0.9547\n",
      "Epoch 00042: val_loss did not improve from 0.15755\n",
      "End of epoch 41. Learning rate: 1e-04\n",
      "237/237 [==============================] - 101s 425ms/step - loss: 0.1136 - accuracy: 0.9577 - AUC: 0.9960 - precision: 0.9617 - recall: 0.9547 - val_loss: 0.3211 - val_accuracy: 0.8827 - val_AUC: 0.9732 - val_precision: 0.8879 - val_recall: 0.8781 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 43/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9646 - AUC: 0.9975 - precision: 0.9668 - recall: 0.9626\n",
      "Epoch 00043: val_loss did not improve from 0.15755\n",
      "End of epoch 42. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 421ms/step - loss: 0.0898 - accuracy: 0.9646 - AUC: 0.9975 - precision: 0.9668 - recall: 0.9626 - val_loss: 0.2490 - val_accuracy: 0.9110 - val_AUC: 0.9824 - val_precision: 0.9129 - val_recall: 0.9059 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 44/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9643 - AUC: 0.9971 - precision: 0.9666 - recall: 0.9627\n",
      "Epoch 00044: val_loss did not improve from 0.15755\n",
      "End of epoch 43. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 430ms/step - loss: 0.0941 - accuracy: 0.9643 - AUC: 0.9971 - precision: 0.9666 - recall: 0.9627 - val_loss: 0.2021 - val_accuracy: 0.9246 - val_AUC: 0.9889 - val_precision: 0.9288 - val_recall: 0.9246 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 45/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9683 - AUC: 0.9973 - precision: 0.9703 - recall: 0.9663\n",
      "Epoch 00045: val_loss did not improve from 0.15755\n",
      "End of epoch 44. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 430ms/step - loss: 0.0871 - accuracy: 0.9683 - AUC: 0.9973 - precision: 0.9703 - recall: 0.9663 - val_loss: 0.4654 - val_accuracy: 0.8478 - val_AUC: 0.9557 - val_precision: 0.8531 - val_recall: 0.8427 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 46/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9654 - AUC: 0.9970 - precision: 0.9685 - recall: 0.9625\n",
      "Epoch 00046: val_loss did not improve from 0.15755\n",
      "End of epoch 45. Learning rate: 1e-04\n",
      "237/237 [==============================] - 100s 423ms/step - loss: 0.0958 - accuracy: 0.9654 - AUC: 0.9970 - precision: 0.9685 - recall: 0.9625 - val_loss: 0.2860 - val_accuracy: 0.9104 - val_AUC: 0.9787 - val_precision: 0.9160 - val_recall: 0.9072 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 47/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9655 - AUC: 0.9969 - precision: 0.9672 - recall: 0.9629\n",
      "Epoch 00047: val_loss did not improve from 0.15755\n",
      "End of epoch 46. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 429ms/step - loss: 0.0929 - accuracy: 0.9655 - AUC: 0.9969 - precision: 0.9672 - recall: 0.9629 - val_loss: 0.3696 - val_accuracy: 0.8691 - val_AUC: 0.9642 - val_precision: 0.8794 - val_recall: 0.8607 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 48/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9650 - AUC: 0.9973 - precision: 0.9670 - recall: 0.9635\n",
      "Epoch 00048: val_loss did not improve from 0.15755\n",
      "End of epoch 47. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 428ms/step - loss: 0.0903 - accuracy: 0.9650 - AUC: 0.9973 - precision: 0.9670 - recall: 0.9635 - val_loss: 0.4086 - val_accuracy: 0.8743 - val_AUC: 0.9652 - val_precision: 0.8787 - val_recall: 0.8691 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 49/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9659 - AUC: 0.9974 - precision: 0.9679 - recall: 0.9647\n",
      "Epoch 00049: val_loss did not improve from 0.15755\n",
      "End of epoch 48. Learning rate: 1e-04\n",
      "237/237 [==============================] - 102s 430ms/step - loss: 0.0891 - accuracy: 0.9659 - AUC: 0.9974 - precision: 0.9679 - recall: 0.9647 - val_loss: 0.4262 - val_accuracy: 0.8833 - val_AUC: 0.9692 - val_precision: 0.8836 - val_recall: 0.8814 - lr: 1.0000e-04\n",
      "Learning rate:  1e-04\n",
      "Epoch 50/50\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9672 - AUC: 0.9970 - precision: 0.9690 - recall: 0.9652\n",
      "Epoch 00050: val_loss did not improve from 0.15755\n",
      "End of epoch 49. Learning rate: 1e-04\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 0.0911 - accuracy: 0.9672 - AUC: 0.9970 - precision: 0.9690 - recall: 0.9652 - val_loss: 0.2674 - val_accuracy: 0.9181 - val_AUC: 0.9803 - val_precision: 0.9210 - val_recall: 0.9168 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history_finetune2 = squeezenet_model.fit(train_generator,\n",
    "                            epochs=50,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            initial_epoch=history_finetune.epoch[-1],\n",
    "                            callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cdf9035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Learning rate:  1e-05\n",
      "Epoch 50/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9745 - AUC: 0.9983 - precision: 0.9752 - recall: 0.9733\n",
      "Epoch 00050: val_loss did not improve from 0.15755\n",
      "End of epoch 49. Learning rate: 1e-05\n",
      "237/237 [==============================] - 102s 423ms/step - loss: 0.0682 - accuracy: 0.9745 - AUC: 0.9983 - precision: 0.9752 - recall: 0.9733 - val_loss: 0.3175 - val_accuracy: 0.9033 - val_AUC: 0.9745 - val_precision: 0.9047 - val_recall: 0.8994 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 51/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9779 - AUC: 0.9985 - precision: 0.9791 - recall: 0.9773\n",
      "Epoch 00051: val_loss did not improve from 0.15755\n",
      "End of epoch 50. Learning rate: 1e-05\n",
      "237/237 [==============================] - 100s 424ms/step - loss: 0.0591 - accuracy: 0.9779 - AUC: 0.9985 - precision: 0.9791 - recall: 0.9773 - val_loss: 0.2938 - val_accuracy: 0.9168 - val_AUC: 0.9776 - val_precision: 0.9174 - val_recall: 0.9162 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 52/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9777 - AUC: 0.9984 - precision: 0.9780 - recall: 0.9765\n",
      "Epoch 00052: val_loss did not improve from 0.15755\n",
      "End of epoch 51. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0623 - accuracy: 0.9777 - AUC: 0.9984 - precision: 0.9780 - recall: 0.9765 - val_loss: 0.2825 - val_accuracy: 0.9188 - val_AUC: 0.9789 - val_precision: 0.9203 - val_recall: 0.9162 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 53/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9795 - AUC: 0.9990 - precision: 0.9802 - recall: 0.9794\n",
      "Epoch 00053: val_loss did not improve from 0.15755\n",
      "End of epoch 52. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 426ms/step - loss: 0.0540 - accuracy: 0.9795 - AUC: 0.9990 - precision: 0.9802 - recall: 0.9794 - val_loss: 0.2723 - val_accuracy: 0.9271 - val_AUC: 0.9806 - val_precision: 0.9282 - val_recall: 0.9252 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 54/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9794 - AUC: 0.9986 - precision: 0.9799 - recall: 0.9787\n",
      "Epoch 00054: val_loss did not improve from 0.15755\n",
      "End of epoch 53. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 426ms/step - loss: 0.0547 - accuracy: 0.9794 - AUC: 0.9986 - precision: 0.9799 - recall: 0.9787 - val_loss: 0.2562 - val_accuracy: 0.9284 - val_AUC: 0.9817 - val_precision: 0.9301 - val_recall: 0.9265 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 55/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9773 - AUC: 0.9989 - precision: 0.9784 - recall: 0.9765\n",
      "Epoch 00055: val_loss did not improve from 0.15755\n",
      "End of epoch 54. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 425ms/step - loss: 0.0549 - accuracy: 0.9773 - AUC: 0.9989 - precision: 0.9784 - recall: 0.9765 - val_loss: 0.2738 - val_accuracy: 0.9252 - val_AUC: 0.9805 - val_precision: 0.9257 - val_recall: 0.9233 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 56/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9786 - AUC: 0.9990 - precision: 0.9793 - recall: 0.9778\n",
      "Epoch 00056: val_loss did not improve from 0.15755\n",
      "End of epoch 55. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0547 - accuracy: 0.9786 - AUC: 0.9990 - precision: 0.9793 - recall: 0.9778 - val_loss: 0.2303 - val_accuracy: 0.9355 - val_AUC: 0.9846 - val_precision: 0.9379 - val_recall: 0.9342 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 57/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9783 - AUC: 0.9988 - precision: 0.9790 - recall: 0.9779\n",
      "Epoch 00057: val_loss did not improve from 0.15755\n",
      "End of epoch 56. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0548 - accuracy: 0.9783 - AUC: 0.9988 - precision: 0.9790 - recall: 0.9779 - val_loss: 0.2775 - val_accuracy: 0.9207 - val_AUC: 0.9796 - val_precision: 0.9236 - val_recall: 0.9201 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 58/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9799 - AUC: 0.9991 - precision: 0.9804 - recall: 0.9795\n",
      "Epoch 00058: val_loss did not improve from 0.15755\n",
      "End of epoch 57. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0523 - accuracy: 0.9799 - AUC: 0.9991 - precision: 0.9804 - recall: 0.9795 - val_loss: 0.2908 - val_accuracy: 0.9226 - val_AUC: 0.9778 - val_precision: 0.9241 - val_recall: 0.9181 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 59/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9790 - AUC: 0.9989 - precision: 0.9796 - recall: 0.9778\n",
      "Epoch 00059: val_loss did not improve from 0.15755\n",
      "End of epoch 58. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 425ms/step - loss: 0.0542 - accuracy: 0.9790 - AUC: 0.9989 - precision: 0.9796 - recall: 0.9778 - val_loss: 0.3040 - val_accuracy: 0.9097 - val_AUC: 0.9773 - val_precision: 0.9156 - val_recall: 0.9091 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 60/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9799 - AUC: 0.9989 - precision: 0.9807 - recall: 0.9798\n",
      "Epoch 00060: val_loss did not improve from 0.15755\n",
      "End of epoch 59. Learning rate: 1e-05\n",
      "237/237 [==============================] - 102s 430ms/step - loss: 0.0532 - accuracy: 0.9799 - AUC: 0.9989 - precision: 0.9807 - recall: 0.9798 - val_loss: 0.2712 - val_accuracy: 0.9220 - val_AUC: 0.9797 - val_precision: 0.9236 - val_recall: 0.9201 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 61/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9824 - AUC: 0.9993 - precision: 0.9829 - recall: 0.9815\n",
      "Epoch 00061: val_loss did not improve from 0.15755\n",
      "End of epoch 60. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 424ms/step - loss: 0.0468 - accuracy: 0.9824 - AUC: 0.9993 - precision: 0.9829 - recall: 0.9815 - val_loss: 0.2722 - val_accuracy: 0.9291 - val_AUC: 0.9806 - val_precision: 0.9301 - val_recall: 0.9271 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 62/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9811 - AUC: 0.9992 - precision: 0.9819 - recall: 0.9800\n",
      "Epoch 00062: val_loss did not improve from 0.15755\n",
      "End of epoch 61. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 428ms/step - loss: 0.0497 - accuracy: 0.9811 - AUC: 0.9992 - precision: 0.9819 - recall: 0.9800 - val_loss: 0.2793 - val_accuracy: 0.9284 - val_AUC: 0.9801 - val_precision: 0.9314 - val_recall: 0.9284 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 63/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9823 - AUC: 0.9990 - precision: 0.9833 - recall: 0.9820\n",
      "Epoch 00063: val_loss did not improve from 0.15755\n",
      "End of epoch 62. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 425ms/step - loss: 0.0505 - accuracy: 0.9823 - AUC: 0.9990 - precision: 0.9833 - recall: 0.9820 - val_loss: 0.2615 - val_accuracy: 0.9304 - val_AUC: 0.9814 - val_precision: 0.9321 - val_recall: 0.9291 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 64/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9815 - AUC: 0.9992 - precision: 0.9816 - recall: 0.9811\n",
      "Epoch 00064: val_loss did not improve from 0.15755\n",
      "End of epoch 63. Learning rate: 1e-05\n",
      "237/237 [==============================] - 101s 428ms/step - loss: 0.0497 - accuracy: 0.9815 - AUC: 0.9992 - precision: 0.9816 - recall: 0.9811 - val_loss: 0.3136 - val_accuracy: 0.9168 - val_AUC: 0.9779 - val_precision: 0.9215 - val_recall: 0.9162 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 65/65\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9798 - AUC: 0.9991 - precision: 0.9805 - recall: 0.9790\n",
      "Epoch 00065: val_loss did not improve from 0.15755\n",
      "End of epoch 64. Learning rate: 1e-05\n",
      "237/237 [==============================] - 100s 422ms/step - loss: 0.0509 - accuracy: 0.9798 - AUC: 0.9991 - precision: 0.9805 - recall: 0.9790 - val_loss: 0.2723 - val_accuracy: 0.9297 - val_AUC: 0.9809 - val_precision: 0.9315 - val_recall: 0.9291 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "squeezenet_model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss= LOSS_METRIC,\n",
    "    metrics=[\"accuracy\",\n",
    "             tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')],\n",
    ")\n",
    "\n",
    "history_finetune3 = squeezenet_model.fit(train_generator,\n",
    "                            epochs=65,\n",
    "                            validation_data=validation_generator,\n",
    "                            verbose=1,\n",
    "                            initial_epoch=history_finetune2.epoch[-1],\n",
    "                            callbacks=[reducelr, earlystop,checkpoint,lambdacb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c4fe0",
   "metadata": {},
   "source": [
    "#### Test Image Generation for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279e76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.keras.models.load_model('./weights/squeezenet_3channel_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408db786",
   "metadata": {},
   "source": [
    "#### Shenzhen Dataset Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93a78f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/test/Shenzhen'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode=CLASS_MODE)\n",
    "\n",
    "res = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5084b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.9400    0.7121    0.8103        66\n",
      "          tb     0.7738    0.9559    0.8553        68\n",
      "\n",
      "    accuracy                         0.8358       134\n",
      "   macro avg     0.8569    0.8340    0.8328       134\n",
      "weighted avg     0.8557    0.8358    0.8331       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = np.argmax(res, axis=1)\n",
    "report = classification_report(test_generator.classes, predicted,target_names=['normal','tb'],digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17609f7a",
   "metadata": {},
   "source": [
    "#### Montgomery Countery Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "793c4c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_IMAGE_FOLDER = '/home/TBX11K/MergedBCH/test/Montgomery'\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_IMAGE_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        class_mode=CLASS_MODE)\n",
    "\n",
    "res = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ddabed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.7857    0.6875    0.7333        16\n",
      "          tb     0.6429    0.7500    0.6923        12\n",
      "\n",
      "    accuracy                         0.7143        28\n",
      "   macro avg     0.7143    0.7188    0.7128        28\n",
      "weighted avg     0.7245    0.7143    0.7158        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = np.argmax(res, axis=1)\n",
    "report = classification_report(test_generator.classes, predicted,target_names=['normal','tb'],digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f663d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
